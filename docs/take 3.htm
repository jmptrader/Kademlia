<html>

<head>
<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Implementing the Kademlia Peer-t</title>
</head>

<body>

<p>Implementing the Kademlia Peer-to-Peer Distributed Hash Table</p>
<h2>Introduction</h2>
<p>Kademlia, according to a paper<sup>1</sup> published in 2015 by Xing Shi Cai 
and Luc Devoyre, &quot;is the defacto standard searching algorithm for P2P 
(peer-to-peer) networks on the Internet.&quot;&nbsp; It seemed like a good 
choice for doing a deep dive in P2P DHT implementations, ideally finding a solid 
existing implementation rather than rolling my own.&nbsp; Alas, it was not to 
be.&nbsp; As it turns out, there are two 
different versions of the specification, both having certain contradictions, 
particularly the second one.&nbsp; This results in a variety of implementations, 
and most tend to have a loose interpretation of the contradictory and ambiguous 
aspects of the specification.&nbsp; 
On GitHub, I've found only two that appear both reasonably complete and well 
implemented:</p>
<ol>
	<li>zencoders<sup>2</sup> C# implementation appears to be based on the 
	shorter specification and seems to match Jim Dixon's<sup>3</sup> description 
	of the algorithm.</li>
	<li>Brian Muller<sup>4 </sup>has an excellent implementation in Python based 
	on the longer specification.&nbsp; Note that the Python 3.5 branch should be 
	used, the master branch contains some bugs and is written for Python 2.</li>
</ol>
<p>Rarely do I end up with multiple versions of an article.&nbsp; What started 
off with the intent of &quot;here's the spec, let's find someone that did a decent 
job coding it&quot; quickly became &quot;here's the spec, let's roll our own using the 
spec&quot; to &quot;wait, the spec is contradicting itself here, it's confusing there, and 
ambiguous over there&quot; to &quot;OMG, there's two different versions of the spec!&quot;&nbsp; 
As a result, this is actually my third pass at writing an article on Kademlia 
that makes some kind of sense.&nbsp; Special thanks go to Brian Muller who has 
put up with a lot of my questions about the specification itself.</p>
<h3>What is Kademlia?</h3>
<p>From Wikipedia:</p>
<p><i>Kademlia is a distributed hash table for decentralized peer-to-peer 
computer networks designed by Petar Maymounkov and David Mazières in 2002. It 
specifies the structure of the network and the exchange of information through 
node lookups. Kademlia nodes communicate among themselves using UDP. A virtual 
or overlay network is formed by the participant nodes. Each node is identified 
by a number or node ID. The node ID serves not only as identification, but the 
Kademlia algorithm uses the node ID to locate values (usually file hashes or 
keywords). In fact, the node ID provides a direct map to file hashes and that 
node stores information on where to obtain the file or resource.</i></p>
<h3>Who Uses Kademlia?</h3>
<p>Kademlia is used in file sharing networks.&nbsp; For example,
BitTorrent<sup>8</sup> uses a DHT 
based on an implementation of the Kademlia algorithm.&nbsp;
Kad network<sup>9</sup> uses the Kademlia protocol, with <a href="https://en.wikipedia.org/wiki/EMule">eMule</a> 
being an open source Windows client.</p>
<h3>Why is Kademlia Important?</h3>
<ol>
	<li>The underlying technology of not just cryptocurrency but any blockchain, 
	including those 
	that implements smart 
	contracts<sup>,5</sup> must include a peer-to-peer distributed hash 
	table, at least with regards to how blockchain technology is being discussed 
	and applied (using a blockchain in a centralized scenario is sort of 
	pointless except perhaps for logging purposes.)&nbsp; Understanding how this 
	works is important.</li>
	<li>Centralized data, except for performance reasons, is
	on its way out<sup>6</sup></a>.&nbsp; As that last link states: &quot;The more the data 
	management industry consolidates, the more opposing forces decentralize the 
	market.&quot;&nbsp; And peer-to-peer decentralizing has built in redundancy 
	protecting from single-point data loss and access failures.&nbsp; Not that 
	decentralizing has its own problems -- security will probably be the main 
	one, if it isn't already.&nbsp; As an aside, read this short paper on
	Enigma</a><sup>7</sup>.</li>
</ol>
<p>While this is a personal venture, it is also a recognition that there are 
some interesting and complicated technologies coming down the road that need to 
be properly understood, and protocols like Kademlia are a good starting point 
for looking at a P2P DHT implementation.&nbsp; As to why Kademlia specifically, 
the summary to the spec says it best:</p>
<p><i>&quot;With its novel XOR-based metric topology, Kademlia is the first 
peer-to-peer system to combine provable consistency and performance, 
latency-minimizing routing, and a symmetric, unidirectional topology. Kademlia 
furthermore introduces a concurrency parameter, a, that lets people trade a 
constant factor in bandwidth for asynchronous lowest-latency hop selection and 
delay-free fault recovery. Finally, Kademlia is the first peer-to-peer system to 
exploit the fact that node failures are inversely related to uptime.&quot;</i></p>
<h3>Where did the Name Come From?</h3>
<p>As <a href="http://www.maymounkov.org/kademlia">Petar Maymounkov</a>, one of 
the co-creators of Kademlia says: &quot;it is a Turkish word for a “lucky man” and, 
more importantly, is the name of a mountain peak in Bulgaria.&quot;&nbsp; OK then.</p>
<h3>Concerns with Existing Implementation</h3>
<p>My major issue with zencoders C# implementation is that it is entangled with 
the intended application -- a P2P audio file application.&nbsp; Brian Muller's 
implementation is a straight forward library.&nbsp; In perusing numerous GitHub 
repo's, I found many implementations that were incomplete or clearly buggy, 
simply by inspecting the code.&nbsp; Beware of what's out there!</p>
<h3>Other Languages</h3>
<p>I have not looked carefully at implementations in other languages, those being 
primarily written in Java and Javascript (personal lack of interest in those 
languages) and Go (lack of familiarity with the language makes it difficult to 
read.)&nbsp; Looking briefly at implementations in these other languages, it's 
fairly easy to tell which version of the specification they implement, so again, 
beware that depending on which specification the author worked with, you can 
have very different implementations.&nbsp; For example, an implementation in 
Java makes a very specific (yet seemingly arbitrary) rule about bucket splitting 
(we'll get to that) that isn't found in the spec.</p>
<h3>Requirements</h3>
<p>C# 7 with .NET framework 4.7 is required to build this code.</p>
<h3>Resources Used In This Research</h3>
<p>What I call Version 1 of the Kademlia specification:
<a href="http://www.cs.rice.edu/Conferences/IPTPS02/109.pdf">
http://www.cs.rice.edu/Conferences/IPTPS02/109.pdf</a></p>
<p>What I call Version 2 of the Kademlia specification:
<a href="https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf">
https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf</a></p>
<p>Mike De Boer's description of k-buckets:
<a href="https://github.com/mikedeboer/node-k-bucket">
https://github.com/mikedeboer/node-k-bucket</a></p>
<p>Brian Muller's Python implementation:
<a href="https://github.com/bmuller/kademlia">
https://github.com/bmuller/kademlia</a></p>
<p>zencoders' implementation:
<a href="https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia">
https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia</a></p>
<p>Jim Dixon's post on the two different versions of the specification:
<a href="https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00039.html">
https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00039.html</a></p>
<p>Jim Dixon's description of the shorter specification:
<a href="http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#FIND_NODE">
http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#FIND_NODE</a></p>
<p>Jim Dixon's description of Section 2.4 of the specification:
<a href="https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00042.html">
https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00042.html</a> </p>
<h3>Other Resources To Further This Work</h3>
<p>IPFS - Content Addressed, Versions, P2P File System (Draft 3):
<a href="https://ipfs.io/ipfs/QmR7GSQM93Cx5eAg6a6yRzNde1FQv7uL6X1o4k7zrJa3LX/ipfs.draft3.pdf">
https://ipfs.io/ipfs/QmR7GSQM93Cx5eAg6a6yRzNde1FQv7uL6X1o4k7zrJa3LX/ipfs.draft3.pdf</a></p>
<p>S/Kademlia: A Practicable Approach Towards Secure Key-Based Routing:
<a href="http://www.tm.uka.de/doc/SKademlia_2007.pdf">
http://www.tm.uka.de/doc/SKademlia_2007.pdf</a></p>
<h3>Things Kademlia Doesn't Address</h3>
<p>Some of the things the specification does not address:</p>
<ul>
	<li>key collision.</li>
	<li>encrypting of values.</li>
	<li>privacy of keys - while not practical with today's technology, a 
	malicious peer could query for stored values across the entire 2<sup>160</sup> 
	key space.</li>
	<li>serialization format of packets sent over the wire.</li>
	<li>ability to limit what a peer stores based on value length.</li>
	<li>private peer groups -- joining a public P2P network but creating a 
	private peer group within the network.</li>
</ul>
<h3>What is Accomplished Here</h3>
<p>The goal in this article is to:</p>
<ol>
	<li>Map specification with implementation.</li>
<li>Discover any areas of concern with the specification.</li>
	<li>Abstract key areas of the design so that:<ol>
		<li>Different implementations can be selected.</li>
	<li>Different communication protocols can be used.</li>
		<li>The algorithm can be easily unit tested.</li>
	</ol>
</li>
</ol>
<h2>Key Concepts</h2>
<p>The Kademlia specification essentially consists of several sub-algorithms:</p>
<ol>
	<li>Registering new peers.</li>
	<li>Updating peer lists.</li>
	<li>Obtaining the closest peer to a key.</li>
<li>Storing and retrieving key-values.</li>
	<li>Managing stale key-value pairs and peers</li>
</ol>
<p>The most complex part of the code is in the registration of new peers, as 
this involves some magic numbers based on the authors' research into the 
performance of other networks as Chord<sup>10</sup> and Pasty<sup>11</sup> and 
the behavior of peers in those networks.</p>
<h3>Terminology</h3>
<p>The Kademlia specification uses the following terms:</p>
<h4>Node</h4>
<p>A node (also known as a contact) is a peer in the network.</p>
<h4>Node ID</h4>
<p>This is a 160 bit node identifier, obtained from a SHA1 hash.</p>
<h4>k-Bucket</h4>
<p>A collection of at most <i>k</i> nodes (or contacts.)&nbsp; Also simply 
	called a bucket.&nbsp; Each node handles up to <i>k</i> contacts within a 
range of ID's.&nbsp; Initially, the ID range is the entire spectrum from 0 &lt;= id 
&lt;= 2<sup>160</sup> - 1.</p>
<h4>Key-Value</h4>
<p>Peers store values based on 160 bit SHA1 hashed keys.&nbsp; Each stored entry 
consists of a key-value pair.</p>
<h4>Router</h4>
<p>The router manages the collection of k-buckets and also determines into which 
nodes a key-value should be stored.</p>
<h4>Distance</h4>
<p>The distance between a host and the key is an XOR computation of the host's 
ID with the key.&nbsp; </p>
<h4>Prefix</h4>
<p>A prefix is the term used to describe the <i>n</i> most significant bits (MSB) of an ID.&nbsp; </p>
<h4>Depth</h4>
<p>The depth of a bucket is defined as the shared prefix of a bucket.&nbsp; 
Since buckets are associated with ranges from 2<sup>i</sup> to 2<sup>i+1</sup> - 
1 where 0 &lt;= i &lt; 160, one could say that the depth of a bucket is 160 - i.&nbsp; 
We'll see later that this may not be the case.</p>
<h4>Bucket Split</h4>
<p>A bucket split is something potentially happens when a node's k-bucket is 
full -- meaning it has <i>k</i> contacts -- and a new contact wants to register 
within the bucket's range.&nbsp; At this point, an algorithm kicks in that:</p>
<ol>
	<li>Under one condition, splits the bucket at the range midpoint into two 
	ranges, placing contacts into the appropriate new buckets.</li>
	<li>Under a second condition, splits the bucket when a specific depth 
	qualifier is met.</li>
</ol>
<p>If the bucket can't be split, there is a third fallback that replaces an old 
contact that is no longer responding with the new contact.</p>
<h3>Communication Protocol</h3>
<p><font color="#FF0000">TODO</font></p>
<h2>Node Requirements</h2>
<p>Let's cover some basic implementation requirements for a node first.&nbsp; In this document, <font color="#FF00FF">fuchsia text</font> is used when 
quoting from the Kademlia specification and other documents.</p>
<h3>The BigInteger Class</h3>
<p>We could write our own byte array manipulation and comparison operators, 
which is what zencoders did, or we could use the <code>BigInteger</code> class to handle the 
range of ID's from 0 &lt;= id &lt;= 2<sup>160</sup> - 1.&nbsp; In ended up using 
<code>BigInteger</code> has simply made the code smaller.&nbsp; As a side node, I was 
impressed with Python's ability to handle these values without any special 
classes:</p>
<pre>&gt;&gt;&gt; 2 ** 160
1461501637330902918203684832716283019655932542976L</pre>
<h3>The Node Specification</h3>
<p> <font color="#FF00FF">Participating computers each have a node ID in the 
160-bit key space </font>(Introduction) which is simple enough.&nbsp; </p>
<h4>Ambiguity #1</h4>
<p>But then there's this:&nbsp; <font color="#FF00FF">Kademlia nodes store 
contact information about each other to route query messages. For each 0 &lt; i &lt; 
160, every node keeps a list of [contacts] of distance between 2<sup>i</sup> and 
2<sup>i+1</sup> from itself.&nbsp; We call these lists k-buckets.&nbsp; <i>k</i> 
is chosen such that any given k nodes are very unlikely to fail within an hour 
of each other (for example k = 20). </font>
(Section 2.2)<font color="#FF00FF"> </font>
How is this distance defined?&nbsp; Is this the XOR distance or the integer 
distance?&nbsp; And when the spec says &quot;distance from itself&quot;, what two values 
are being compared?&nbsp; Why even make this comparison?</p>
<h4>Contradiction #1</h4>
<p><font color="#FF00FF">Initially, a node u’s routing tree has a single node— 
one k-bucket covering the entire ID space.</font>&nbsp; (Section 2.4)&nbsp; So 
from Section 2.2, we have each node contain 159 k-buckets (0 &lt; i &lt; 160) covering 
2<sup>i</sup> through 2<sup>i+1</sup>, and from Section 2.4, we have a node 
initialized with one k-bucket.&nbsp; You can see the former specification implemented 
in zencoders code:</p>
<pre>private const int BUCKET_SIZE = 20; // &quot;K&quot; in the spec
private const int NUM_BUCKETS = 8 * ID.ID_LENGTH; // One per bit in an ID

private List&lt;List&lt;Contact&gt;&gt; buckets;
private List&lt;DateTime&gt; accessTimes; // last bucket write or explicit touch
private ID ourID;

/// &lt;summary&gt;
/// Make a new bucket list, for holding node contacts.
/// &lt;/summary&gt;
/// &lt;param name=&quot;ourID&quot;&gt;The ID to center the list on.&lt;/param&gt;
public BucketList(ID ourID)
{
  this.ourID = ourID;
  buckets = new List&lt;List&lt;Contact&gt;&gt;(NUM_BUCKETS);
  accessTimes = new List&lt;DateTime&gt;();

  // Set up each bucket
  for(int i = 0; i &lt; NUM_BUCKETS; i++) 
  {
    buckets.Add(new List&lt;Contact&gt;(BUCKET_SIZE));
    accessTimes.Add(default(DateTime));
  }
}</pre>
<p>Here <code>8 * ID.ID_LENGTH</code> (8 * 20 = 160) buckets are created at the 
get go, each with 20 contacts (the suggested <i>k</i> value.)&nbsp; This is 
hard-wired in the zencoders implementation.</p>
<p>You can see the latter specification in the Brian Muller's Python code:</p>
<pre>def flush(self):
  self.buckets = [KBucket(0, 2 ** 160, self.ksize)]</pre>
<p>Here, a single bucket is created spanning the ID space.&nbsp; The Python code 
is correct because it also implements bucket splitting, which is in the second 
version of the specification.</p>
<h4>Artifact #1</h4>
<p>In the former specification, this limits the total number of contacts that 
your server can handle to 160 * 20, or 3200 contacts.</p>
<h2>Initial ID, Router, Contact, KBucket, BucketList, Node, and Dht Implementations</h2>
<p>After resolving the ambiguity and contradiction, we can implement most of the 
relevant classes.&nbsp; Note that some of the properties in the following 
implementation will be discussed later.</p>
<p>When we're all done with the initial implementation, we have this class 
model:</p>
<ul>
	<li>Blue - classes</li>
	<li>Orangey - interfaces</li>
	<li>Purple - collections</li>
	<li>Green - value type fields</li>
</ul>
<p align="center"><img border="0" src="classmodel.png" width="793" height="673"></p>
<h3>The ID Class</h3>
<pre>using System.Numerics;

namespace Clifton.Kademlia
{
  public class ID
  {
#if DEBUG // For unit testing.
    public BigInteger Value { get { return id; } }
#endif

    protected BigInteger id;

    /// &lt;summary&gt;
    /// Construct the ID from a byte array.
    /// &lt;/summary&gt;
    public ID(byte[] data)
    {
      IDInit(data);
    }

    /// &lt;summary&gt;
    /// Construct the ID from another BigInteger value.
    /// &lt;/summary&gt;
    public ID(BigInteger bi)
    {
      id = bi;
    }

    /// &lt;summary&gt;
    /// Initialize the ID from a byte array, appending a 0 to force unsigned values.
    /// &lt;/summary&gt;
    protected void IDInit(byte[] data)
    {
      Validate.IsTrue(data.Length == Constants.ID_LENGTH_BYTES, &quot;ID must be &quot; + Constants.ID_LENGTH_BYTES + &quot; bytes in length.&quot;);
      id = new BigInteger(data.Append0());    }
  }
}</pre>
<p>Two things of note here.</p>
<ol>
	<li>The most interesting thing here is the appending the byte array with a 0 to 
force unsigned values in the BigInteger.&nbsp; If we don't do this, any byte 
array where the MSB of byte[0] is set will be treated as a negative number, 
which we don't want when comparing the range of a bucket.&nbsp; This is handled 
by a simple extension method:</li>
</ol>
<pre>/// &lt;summary&gt;
/// Append a 0 to the byte array so that when converting to a BigInteger, the value remains positive.
/// &lt;/summary&gt;
public static byte[] Append0(this byte[] b)
{
  return b.Concat(new byte[] { 0 }).ToArray();
}</pre>
<ol>
	<li value="2">The byte array is in little-endian order, meaning that the 
	least significant value is stored first.</li>
</ol>
<h4>Unit Tests</h4>
<pre>[TestMethod]
public void LittleEndianTest()
{
  byte[] test = new byte[20];
  test[0] = 1;
  Assert.IsTrue(new ID(test).Value == new BigInteger(1), &quot;Expected value to be 1.&quot;);
}

[TestMethod]
public void PositiveValueTest()
{
  byte[] test = new byte[20];
  test[19] = 0x80;
  Assert.IsTrue(new ID(test).Value == BigInteger.Pow(new BigInteger(2), 159), &quot;Expected value to be 1.&quot;);
}

[TestMethod, ExpectedException(typeof(IDLengthException))]
public void BadIDTest()
{
  byte[] test = new byte[21];
  new ID(test);
}</pre>
<h3>The Router Class</h3>
<p>At the moment, the router simply manages the host's node:</p>
<pre>namespace Clifton.Kademlia
{
  public class Router
  {
#if DEBUG // for unit testing
    public Node Node { get { return node; } }
#endif

    protected Node node;

    public Router(Node node)
    {
      this.node = node;
    }
  }
}</pre>
<h3>The Contact Class</h3>
<p>The contact class manages the contact's ID, last seen, and network 
connectivity.&nbsp; Because I want to abstract the way network protocols are 
handled, such that it is easy to test nodes in a virtual (in-memory) network, or 
nodes that use different protocols (UDP, TCP/IP, WebSockets, etc.) the network 
protocol is abstracted in an interface.</p>
<pre>using System;

namespace Clifton.Kademlia
{
  public class Contact
  {
    public DateTime LastSeen { get; protected set; }
    public IProtocol Protocol { get; protected set; }
    public ID ContactID { get; protected set; }

    /// &lt;summary&gt;
    /// Initialize a contact with its protocol and ID.
    /// &lt;/summary&gt;
    public Contact(IProtocol protocol, ID contactID)
    {
      Protocol = protocol;
      ContactID = contactID;
      Touch();
    }

    /// &lt;summary&gt;
    /// Update the fact that we've just seen this contact.
    /// &lt;/summary&gt;
    public void Touch()
    {
      LastSeen = DateTime.Now;
    }
  }
}</pre>
<h3>The KBucket Class</h3>
<p>Each k-bucket maintains a list of up to <i>k</i> contacts.</p>
<pre>using System.Collections.Generic;
using System.Numerics;

namespace Clifton.Kademlia
{
  public class KBucket
  {
#if DEBUG // For unit testing.
    public List&lt;Contact&gt; Contacts { get { return contacts; } }
    public BigInteger Low { get { return low; } }
    public BigInteger High { get { return high; } }
#endif

    protected List&lt;Contact&gt; contacts;
    protected BigInteger low;
    protected BigInteger high;

    /// &lt;summary&gt;
    /// Initializes a k-bucket with the default range of 0 - 2^160
    /// &lt;/summary&gt;
    public KBucket()
    {
      contacts = new List&lt;Contact&gt;();
      low = 0;
      high = BigInteger.Pow(new BigInteger(2), 160);
    }

    /// &lt;summary&gt;
    /// Initializes a k-bucket with a specific ID range.
    /// &lt;/summary&gt;
    public KBucket(BigInteger low, BigInteger high)
    {
      contacts = new List&lt;Contact&gt;();
      this.low = low;
      this.high = high;
    }

    /// &lt;summary&gt;
    /// Add a contact to the bucket, at the end, as this is the most recently seen contact.
    /// A full bucket throws an exception.
    /// &lt;/summary&gt;
    public void AddContact(Contact contact)
    {
      Validate.IsTrue&lt;TooManyContactsException&gt;(contacts.Count &lt; Constants.K, &quot;Bucket is full&quot;);
      contacts.Add(contact);
    }
  }
}</pre>
<h4>Unit Test</h4>
<pre>[TestMethod, ExpectedException(typeof(TooManyContactsException))]
public void TooManyContactsTest()
{
  KBucket kbucket = new KBucket();

  // Add max # of contacts.
  Constants.K.ForEach(n =&gt; kbucket.AddContact(new Contact(null, new ID(n))));

  // Add one more.
  kbucket.AddContact(new Contact(null, new ID(21)));
}</pre>
<h3>The BucketList Class</h3>
<p>The bucket list class is a high level singleton container for buckets and operations 
that manipulate buckets.&nbsp; For the moment, most of this is stubbed with 
minimal behavior:</p>
<pre>using System.Collections.Generic;

namespace Clifton.Kademlia
{
  public class BucketList
  {
#if DEBUG // Used for unit testing.
    public List&lt;KBucket&gt; Buckets { get { return buckets; } }
#endif

    protected List&lt;KBucket&gt; buckets;
    protected ID ourID;

    /// &lt;summary&gt;
    /// Initialize the bucket list with our host ID and create a single bucket for the full ID range.
    /// &lt;/summary&gt;
    /// &lt;param name=&quot;ourID&quot;&gt;&lt;/param&gt;
    public BucketList(ID ourID)
    {
      this.ourID = ourID;
      buckets = new List&lt;KBucket&gt;();

      // First kbucket has max range.
      buckets.Add(new KBucket());
    }

    public void AddContact(Contact contact)
    {
      // to be implemented...
    }
  }
}</pre>
<h3>The Node Class</h3>
<p>The node class is another high level singleton container for handling the Kademlia 
commands sent over the wire.&nbsp; This is mostly stubbed for now:</p>
<pre>using System.Collections.Generic;

namespace Clifton.Kademlia
{
  public class Node
  {
#if DEBUG // For unit testing.
    public BucketList BucketList { get { return bucketList; } }
    public IStorage Storage { get; set; }
    public Contact OurContact { get; }
#endif

    protected Contact ourContact;
    protected BucketList bucketList;

    public Node(Contact us, IStorage storage)
    {
      ourContact = us;
      bucketList = new BucketList(us.ContactID);
      this.storage = storage;
    }

    /// &lt;summary&gt;
    /// Someone is pinging us. Register the contact and respond.
    /// &lt;/summary&gt;
    public Contact Ping(Contact sender)
    {
      // TODO...

      return ourContact;
    }

    /// &lt;summary&gt;
    /// Store a key-value pair in our storage space.
    /// &lt;/summary&gt;
    public void Store(Contact sender, ID keyID, string val)
    {
      // TODO...
    }

    /// &lt;summary&gt;
    /// From the spec: FindNode takes a 160-bit ID as an argument. The recipient of the RPC returns (IP address, UDP port, Node ID) triples 
    /// for the k nodes it knows about closest to the target ID. These triples can come from a single k-bucket, or they may come from 
    /// multiple k-buckets if the closest k-bucket is not full. In any case, the RPC recipient must return k items (unless there are 
    /// fewer than k nodes in all its k-buckets combined, in which case it returns every node it knows about).
    /// &lt;/summary&gt;
    /// &lt;returns&gt;&lt;/returns&gt;
    public (List&lt;Contact&gt; contacts, string val) FindNode(Contact sender, ID toFind)
    {
      // TODO...
      return (null, null);
    }

    /// &lt;summary&gt;
    /// Returns either a list of close contacts or a the value, if the node's storage contains the value for the key.
    /// &lt;/summary&gt;
    public (List&lt;Contact&gt; contacts, string val) FindValue(Contact sender, ID keyID)
    {
      // TODO:

      return (null, null);
    }
  }
}</pre>
<p>Of note here is the interface <code>IStorage</code> which abstracts the storage mechanism 
for key-value pairs.</p>
<h3>The Dht Class</h3>
<p>The Dht class is the &quot;server&quot; - the entry point for instantiating our peer.&nbsp; At the moment, the Dht class is simply a container for the Router:</p>
<pre>using System;

namespace Clifton.Kademlia
{
  public class Dht
  {
#if DEBUG // for unit testing
    public Router Router { get { return router; } }
#endif

    protected Router router;
  }
}</pre>
<h2>Adding Contacts - The First Interesting Algorithm</h2>
<p>Version 2, Section 2.2 of the specification initially states this simple 
algorithm for dealing adding contacts:</p>
<p><font color="#FF00FF">When a Kademlia node receives any message (request or 
reply) from another node, it updates the appropriate k-bucket for the sender’s 
node ID. If the sending node already exists in the recipient’s k-bucket, the 
recipient moves it to the tail of the list. If the node is not already in the 
appropriate k-bucket and the bucket has fewer than k entries, then the recipient 
just inserts the new sender at the tail of the list. If the appropriate k-bucket 
is full, however, then the recipient pings the k-bucket’s least-recently seen 
node to decide what to do. If the least recently seen node fails to respond, it 
is evicted from the k-bucket and the new sender inserted at the tail. Otherwise, 
if the least-recently seen node responds, it is moved to the tail of the list, 
and the new sender’s contact is discarded.</font></p>
<p>Let's define a few terms (if you aren't sure, don't know, or just want some 
clarity):</p>
<ul>
	<li>head of the list - the first entry in the list</li>
	<li>tail of the list - the last entry in the list</li>
	<li>&quot;the appropriate k-bucket for the sender's node ID&quot; - this is the 
	k-bucket for which the sender's node ID is in the range of the k-bucket.</li>
</ul>
<p>Here's a flowchart of what the spec says:</p>
<p align="center">
<img border="0" src="addContact1.png" width="520" height="679"></p>
<p>This seems reasonable and the spec goes on to state:</p>
<p><font color="#FF00FF">k-buckets effectively implement a least-recently seen 
eviction policy, except that live nodes are never removed from the list. This 
preference for old contacts is driven by our analysis of Gnutella trace data 
collected by Saroiu et. al. ... The longer a node has been up, the more likely 
it is to remain up another hour. By keeping the oldest live contacts around, 
k-buckets maximize the probability that the nodes they contain will remain 
online.&nbsp; A second benefit of k-buckets is that they provide resistance to 
certain DoS attacks. One cannot flush nodes' routing state by flooding the 
system with new nodes. Kademlia nodes will only insert the new nodes in the 
k-buckets when old nodes leave the system.</font></p>
<p>We also observe that this has nothing to do with binary trees, which is 
something version 2 of the spec introduced.&nbsp; This is basically a hang-over 
from version 1 of the spec.</p>
<h3>Contradiction #2</h3>
<p>Section 2.4 states something slightly different:</p>
<p><font color="#FF00FF">Nodes in the routing tree are allocated dynamically, as 
needed. Initially, a node u’s routing tree has a single node— one k-bucket 
covering the entire ID space. When u learns of a new contact, it attempts to 
insert the contact in the appropriate k-bucket. If that bucket is not full, the 
new contact is simply inserted. Otherwise, if the k-bucket’s range includes u’s 
own node ID, then the bucket is split into two new buckets, the old contents 
divided between the two, and the insertion attempt repeated. If a k-bucket with 
a different range is full, the new contact is simply dropped.</font></p>
<h4>Terminology</h4>
<ul>
	<li>&quot;u's routing tree&quot; - the host's bucket list.</li>
	<li>&quot;if a k-bucket with a different range is full&quot; - meaning, a k-bucket 
	that does not include u's own node ID.</li>
</ul>
<p>The purpose of allowing a bucket to split if it contains the host's node ID 
is so that the host keeps a list of nodes that are &quot;close to it&quot; -- closeness 
defined essentially by the integer difference of the node ID's, not the XOR 
difference (more on this whole XOR thing later.)</p>
<p>So this algorithm looks like this:</p>
<p><img border="0" src="addContact2.png" width="761" height="625"></p>
<p>What happened to pinging the least seen contact and replacing it?&nbsp; </p>
<h3>Contradiction #3</h3>
<p>But the spec then goes on to say:</p>
<p><font color="#FF00FF">One complication arises in highly unbalanced trees.&nbsp; 
Suppose node <i>u</i> joins the system and is the only node whose ID begins 000. 
Suppose further that the system already has more than k nodes with prefix 001. 
Every node with prefix 001 would have an empty k-bucket into which <i>u</i> 
should be inserted, yet <i>u</i>’s bucket refresh would only notify k of the 
nodes.&nbsp; To avoid this problem, Kademlia nodes keep all valid contacts in a 
subtree of size at least k nodes, even if this requires splitting buckets in 
which the node’s own ID does not reside. Figure 5 illustrates these additional 
splits.</font></p>
<h4>Terminology</h4>
<ul>
	<li>&quot;a subtree of size at least k nodes&quot; - ok, we can vaguely see that a 
	subtree contains other subtrees where the total number of contacts is 
	greater than k.</li>
	<li>&quot;even if this requires splitting buckets in which the node's own ID does 
	not reside&quot; - not only is this contradictory, but there's no explanation of 
	what &quot;even if this requires&quot; means.&nbsp; How do you code this?</li>
</ul>
<p>This section of the specification apparently creates much confusion -- I 
found several links with people asking about this section.&nbsp; It's 
unfortunate that the original authors do not themselves answer these questions.&nbsp; 
Jim Dixon has a very interesting response<sup>12</sup> on The Mail Archive which 
I present in full here:</p>
<blockquote>
	<p>&quot;The source of confusion is that the 13-page version of the Kademlia uses<br>
	the same term to refer to two different data structures. The first is<br>
	well-defined: k-bucket i contains zero to k contacts whose XOR distance is<br>
	[2^i..2^(i+1)). It cannot be split. The current node can only be in<br>
	bucket zero, if it is present at all. In fact its presence would be<br>
	pointless or worse.<br>
	<br>
	The second thing referred to as a k-bucket doesn't have the same<br>
	properties. Specifically, the current node must be present, it wanders<br>
	from one k-bucket to another, these k-buckets can be split, and there are<br>
	sometimes ill-defined constraints on the characteristics of subtrees of<br>
	k-buckets, such as the requirement that &quot;Kademlia nodes keep all valid<br>
	contacts in a subtree of size of at least k nodes, even if this requires<br>
	splitting buckets in which the node's own ID does not reside&quot; (section<br>
	2.4, near the end).<br>
	<br>
	In a generous spirit, you might say that the logical content of the two<br>
	descriptions is the same. However, for someone trying to implement<br>
	Kademlia, the confusion of terms causes headaches -- and leads to a<br>
	situation where all sorts of things are described as Kademlia, because<br>
	they can be said to be, if you are of a generous disposition. However,<br>
	not surprisingly, they don't interoperate.&quot;</p>
</blockquote>
<p>So my decision, given the lack of clarity and by the authors of the spec, is 
to ignore this, because, as you will see next, there is yet another version of 
how contacts are added.</p>
<h3>Contradiction #4</h3>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>High Level Architecture</h2>
<p>In this document, <font color="#FF00FF">fuchsia text</font> is used when 
quoting from the Kademlia specification and other documents.</p>
<p>There are four components to the high level architecture necessary to 
implement the Kademlia protocol:</p>
<ol>
	<li>Node: The concept of a node.&nbsp; Each node has a private 160-bit ID (a 
	SHA-1 hash).&nbsp; <font color="#FF00FF">Keys are opaque, 160-bit quantities 
	(e.g., the SHA-1 hash of some larger data). Participating computers each 
	have a node ID in the 160-bit key space. </font>(From the Introduction)</li>
	<li>Storage: Each node stores key-value pairs, where the key is also a 
	160-bit SHA-1 hash.&nbsp;&nbsp; <font color="#FF00FF">(key,value) pairs are 
	stored on nodes with IDs “close” to the key for some notion of closeness.</font>&nbsp; 
	The storage mechanism, whether in-memory, key-value database, file system, 
	or other, is not specified and is a good point for abstraction. (From the 
	Introduction)</li>
	<li>Routing: Nearby servers for a given key are located with an efficient 
	routing algorithm.&nbsp; <font color="#FF00FF">A node- ID-based routing 
	algorithm lets anyone efficiently locate servers near any given target key. </font>
	(From the Introduction)</li>
	<li>Communication protocol: a means of communicating between nodes (usually 
	separate computers) must exist.&nbsp; The original Kademlia specification 
	states that <font color="#FF00FF">every node keeps a list of (IP address, 
	UDP port, Node ID)</font> of nearby nodes.&nbsp; As with storage, this is a 
	good place for abstraction so that different protocols can be easily 
	employed. (Section 2.2 of the spec)</li>
</ol>
<p>This is expressed in the following diagram:</p>
<p><img border="0" src="highlevel.png" width="625" height="271"></p>
<h3>&nbsp;</h3>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>&nbsp;</h2>
<h2>References</h2>
<p><sup>1</sup> -
<a href="http://www.tandfonline.com/doi/abs/10.1080/15427951.2015.1051674?src=recsys&journalCode=uinm20">
http://www.tandfonline.com/doi/abs/10.1080/15427951.2015.1051674?src=recsys&amp;journalCode=uinm20</a>
</p>
<p><sup>2</sup> -
<a href="https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia">
https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia</a></p>
<p><sup>3</sup> -
<a href="http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#FIND_NODE">
http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html</a></p>
<p><sup>4</sup> -
<a href="https://github.com/bmuller/kademlia">
https://github.com/bmuller/kademlia</a></p>

<p><sup>5</sup> - <a href="https://en.wikipedia.org/wiki/Smart_contract">
https://en.wikipedia.org/wiki/Smart_contract</a></p>
<p><sup>6</sup> -
<a href="http://sandhill.com/article/is-data-decentralization-the-new-trend/">
http://sandhill.com/article/is-data-decentralization-the-new-trend/</a></p>
<p><sup>7</sup> - <a href="https://arxiv.org/pdf/1506.03471.pdf">
https://arxiv.org/pdf/1506.03471.pdf</a></p>
<p><sup>8</sup> - <a href="https://en.wikipedia.org/wiki/BitTorrent">
https://en.wikipedia.org/wiki/BitTorrent</a></p>
<p><sup>9</sup> - <a href="https://en.wikipedia.org/wiki/Kad_network">
https://en.wikipedia.org/wiki/Kad_network</a></p>
<p><sup>10</sup> - <a href="https://en.wikipedia.org/wiki/Chord_(peer-to-peer)">https://en.wikipedia.org/wiki/Chord_(peer-to-peer)</a> </p>
<p><sup>11</sup> - <a href="https://en.wikipedia.org/wiki/Pastry_(DHT)">https://en.wikipedia.org/wiki/Pastry_(DHT)</a> </p>
<p><sup>12</sup> -
<a href="https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00042.html">
https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00042.html</a> </p>

</body>

</html>