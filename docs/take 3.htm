<html>

<head>
<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Implementing the Kademlia Peer-t</title>
</head>

<body>

<p>Implementing the Kademlia Peer-to-Peer Distributed Hash Table</p>
<h2>Introduction</h2>
<p>Kademlia, according to a paper<sup>1</sup> published in 2015 by Xing Shi Cai 
and Luc Devoyre, &quot;is the defacto standard searching algorithm for P2P 
(peer-to-peer) networks on the Internet.&quot;&nbsp; It seemed like a good 
choice for doing a deep dive in P2P DHT implementations, ideally finding a solid 
existing implementation rather than rolling my own.&nbsp; Alas, it was not to 
be.&nbsp; As it turns out, there are two 
different versions of the specification, both having certain contradictions, 
particularly the second one.&nbsp; This results in a variety of implementations, 
and most tend to have a loose interpretation of the contradictory and ambiguous 
aspects of the specification.&nbsp; 
On GitHub, I've found only two that appear both reasonably complete and well 
implemented:</p>
<ol>
	<li>zencoders<sup>2</sup> C# implementation appears to be based on the 
	shorter specification and seems to match Jim Dixon's<sup>3</sup> description 
	of the algorithm.</li>
	<li>Brian Muller<sup>4 </sup>has an excellent implementation in Python based 
	on the longer specification.&nbsp; 
	<img border="0" src="note.png" width="24" height="32"> Note that the Python 3.5 branch should be 
	used, the master branch contains some bugs and is written for Python 2.</li>
</ol>
<p>Rarely do I end up with multiple versions of an article.&nbsp; What started 
off with the intent of &quot;here's the spec, let's find someone that did a decent 
job coding it&quot; quickly became &quot;here's the spec, let's roll our own using the 
spec&quot; to &quot;wait, the spec is contradicting itself here, it's confusing there, and 
ambiguous over there&quot; to &quot;OMG, there's two different versions of the spec!&quot;&nbsp; 
As a result, this is actually my third pass at writing an article on Kademlia 
that makes some kind of sense.&nbsp; Special thanks go to Brian Muller who has 
put up with a lot of my questions about the specification itself.</p>
<h3>What is Kademlia?</h3>
<p>From Wikipedia:</p>
<p><i>Kademlia is a distributed hash table for decentralized peer-to-peer 
computer networks designed by Petar Maymounkov and David Mazières in 2002. It 
specifies the structure of the network and the exchange of information through 
node lookups. Kademlia nodes communicate among themselves using UDP. A virtual 
or overlay network is formed by the participant nodes. Each node is identified 
by a number or node ID. The node ID serves not only as identification, but the 
Kademlia algorithm uses the node ID to locate values (usually file hashes or 
keywords). In fact, the node ID provides a direct map to file hashes and that 
node stores information on where to obtain the file or resource.</i></p>
<h3>Who Uses Kademlia?</h3>
<p>Kademlia is used in file sharing networks.&nbsp; For example,
BitTorrent<sup>8</sup> uses a DHT 
based on an implementation of the Kademlia algorithm.&nbsp;
Kad network<sup>9</sup> uses the Kademlia protocol, with <a href="https://en.wikipedia.org/wiki/EMule">eMule</a> 
being an open source Windows client.</p>
<h3>Why is Kademlia Important?</h3>
<ol>
	<li>The underlying technology of not just cryptocurrency but any blockchain, 
	including those 
	that implements smart 
	contracts<sup>,5</sup> must include a peer-to-peer distributed hash 
	table, at least with regards to how blockchain technology is being discussed 
	and applied (using a blockchain in a centralized scenario is sort of 
	pointless except perhaps for logging purposes.)&nbsp; Understanding how this 
	works is important.</li>
	<li>Centralized data, except for performance reasons, is
	on its way out<sup>6</sup></a>.&nbsp; As that last link states: &quot;The more the data 
	management industry consolidates, the more opposing forces decentralize the 
	market.&quot;&nbsp; And peer-to-peer decentralizing has built in redundancy 
	protecting from single-point data loss and access failures.&nbsp; Not that 
	decentralizing has its own problems -- security will probably be the main 
	one, if it isn't already.&nbsp; As an aside, read this short paper on
	Enigma</a><sup>7</sup>.</li>
</ol>
<p>While this is a personal venture, it is also a recognition that there are 
some interesting and complicated technologies coming down the road that need to 
be properly understood, and protocols like Kademlia are a good starting point 
for looking at a P2P DHT implementation.&nbsp; As to why Kademlia specifically, 
the summary to the spec says it best:</p>
<p><i>&quot;With its novel XOR-based metric topology, Kademlia is the first 
peer-to-peer system to combine provable consistency and performance, 
latency-minimizing routing, and a symmetric, unidirectional topology. Kademlia 
furthermore introduces a concurrency parameter, a, that lets people trade a 
constant factor in bandwidth for asynchronous lowest-latency hop selection and 
delay-free fault recovery. Finally, Kademlia is the first peer-to-peer system to 
exploit the fact that node failures are inversely related to uptime.&quot;</i></p>
<h3>Where did the Name Come From?</h3>
<p>As <a href="http://www.maymounkov.org/kademlia">Petar Maymounkov</a>, one of 
the co-creators of Kademlia says: &quot;it is a Turkish word for a “lucky man” and, 
more importantly, is the name of a mountain peak in Bulgaria.&quot;&nbsp; OK then.</p>
<h3>Concerns with Existing Implementation</h3>
<p>My major issue with zencoders C# implementation is that it is entangled with 
the intended application -- a P2P audio file application.&nbsp; Brian Muller's 
implementation is a straight forward library.&nbsp; In perusing numerous GitHub 
repo's, I found many implementations that were incomplete or clearly buggy, 
simply by inspecting the code.&nbsp; Beware of what's out there!</p>
<h3>Other Languages</h3>
<p>I have not looked carefully at implementations in other languages, those being 
primarily written in Java and Javascript (personal lack of interest in those 
languages) and Go (lack of familiarity with the language makes it difficult to 
read.)&nbsp; Looking briefly at implementations in these other languages, it's 
fairly easy to tell which version of the specification they implement, so again, 
beware that depending on which specification the author worked with, you can 
have very different implementations.&nbsp; For example, an implementation in 
Java makes a very specific (yet seemingly arbitrary) rule about bucket splitting 
(we'll get to that) that isn't found in the spec.</p>
<h3>Requirements</h3>
<p>C# 7 with .NET framework 4.7 is required to build this code.</p>
<h3>Resources Used In This Research</h3>
<p>What I call Version 1 of the Kademlia specification:
<a href="http://www.cs.rice.edu/Conferences/IPTPS02/109.pdf">
http://www.cs.rice.edu/Conferences/IPTPS02/109.pdf</a></p>
<p>What I call Version 2 of the Kademlia specification:
<a href="https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf">
https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf</a></p>
<p>Mike De Boer's description of k-buckets:
<a href="https://github.com/mikedeboer/node-k-bucket">
https://github.com/mikedeboer/node-k-bucket</a></p>
<p>Brian Muller's Python implementation:
<a href="https://github.com/bmuller/kademlia">
https://github.com/bmuller/kademlia</a></p>
<p>zencoders' implementation:
<a href="https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia">
https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia</a></p>
<p>Jim Dixon's post on the two different versions of the specification:
<a href="https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00039.html">
https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00039.html</a></p>
<p>Jim Dixon's description of the shorter specification:
<a href="http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#FIND_NODE">
http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#FIND_NODE</a></p>
<p>Jim Dixon's description of Section 2.4 of the specification:
<a href="https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00042.html">
https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00042.html</a> </p>
<p>Implementation of Kademlia Distributed Hash Table, Semester Thesis Writen by 
Bruno Spori, Swiss Federal Institute of Technology Zurich:
<a href="http://pub.tik.ee.ethz.ch/students/2006-So/SA-2006-19.pdf">
http://pub.tik.ee.ethz.ch/students/2006-So/SA-2006-19.pdf</a> </p>
<h3>Other Resources To Further This Work</h3>
<p>IPFS - Content Addressed, Versions, P2P File System (Draft 3):
<a href="https://ipfs.io/ipfs/QmR7GSQM93Cx5eAg6a6yRzNde1FQv7uL6X1o4k7zrJa3LX/ipfs.draft3.pdf">
https://ipfs.io/ipfs/QmR7GSQM93Cx5eAg6a6yRzNde1FQv7uL6X1o4k7zrJa3LX/ipfs.draft3.pdf</a></p>
<p>S/Kademlia: A Practicable Approach Towards Secure Key-Based Routing:
<a href="http://www.tm.uka.de/doc/SKademlia_2007.pdf">
http://www.tm.uka.de/doc/SKademlia_2007.pdf</a></p>
<p>Improving Lookup Performance over a Widely-Deployed DHT:
<a href="http://www.barsoom.org/papers/infocom-2006-kad.pdf">
http://www.barsoom.org/papers/infocom-2006-kad.pdf</a> </p>
<h3>Things Kademlia Doesn't Address</h3>
<p>Some of the things the specification does not address:</p>
<ul>
	<li>Key collisions in key-values.&nbsp; While improbable, the best way to 
	mitigate this is to have your own peer create a random key for you, so we 
	don't all create a key called &quot;Nancy's Number.&quot;</li>
	<li>Peer ID collision - again, the node ID should be created for you, so we 
	don't all create peers called &quot;Marc's Peer.&quot;</li>
	<li>Encrypting of values.</li>
	<li>Privacy of keys - while not practical with today's technology, a 
	malicious peer could query for stored values across the entire 2<sup>160</sup> 
	key space.</li>
	<li>Serialization format of packets sent over the wire.</li>
	<li>Ability to limit what a peer stores based on value length.&nbsp; I 
	certainly don't want to store the value for the key &quot;TheWholeInternet.&quot;</li>
	<li>Private peer groups -- joining a public P2P network but creating a 
	private peer group within the network.</li>
	<li>Partial participation -- What if you want to participate in a peer network for storing / 
	retrieving key-values, but don't want to store key-values yourself?&nbsp; 
	Perhaps you're running an IoT device with limited storage?</li>
	<li>Registering multiple peer ID's from the same network address - this is 
	of particular concern because you can use this to degrade the performance of 
	a peer, as discussed
	<a href="#Breaking_Kademlia">here</a>.</li>
	<li>Our peer tampering with a value when it propagates the value to other 
	peers.&nbsp; This can be remedied by including a public key to ensure the 
	value hasn't been changed.&nbsp; And while it's strange to say &quot;our peer&quot;, 
	it becomes an issue when you download a peer application and you have no 
	idea what's going on inside -- and even if you had the source, would you 
	look, and know where to look?</li>
</ul>
<h3>What is Accomplished Here</h3>
<p>The goal in this article is to:</p>
<ol>
	<li>Map specification with implementation.</li>
<li>Discover any areas of concern with the specification.</li>
	<li>Abstract key areas of the design so that:<ol>
		<li>Different implementations can be selected.</li>
	<li>Different communication protocols can be used.</li>
		<li>The algorithm can be easily unit tested.</li>
	</ol>
</li>
</ol>
<h3>Notation</h3>
<p>In this document, <font color="#FF00FF">fuchsia text</font> is used when 
quoting from the Kademlia specification and other documents.</p>
<h3>A Word About the Unit Tests</h3>
<p>Some of the unit tests set up specific conditions for testing code.&nbsp; 
Others use a randomly generated ID's (node ID's and keys) and verify results 
through a different implementation of the same algorithm.&nbsp; Those tests 
should probably be revised to set up specific conditions.&nbsp; To mitigate 
one's horror at using random values in unit tests, the Random class is seed in 
debug mode with the same value, and is exposed as a public static field so that 
some unit tests can perform their tests with a range of seeds:</p>
<pre>#if DEBUG
public static Random rnd = new Random(1);
#else
private static Random rnd = new Random();
#endif</pre>
<p>At some point I might put more work into improving the unit tests and 
removing the random ID key generation, except for the distribution tests of 
course.</p>
<p>Also, most of these unit tests are really system-level tests, or at least 
partial system tests.&nbsp; Actual unit tests of specific code sections in a 
particular method, well, it gets inane rather quickly.&nbsp; So you'll see a lot 
of setup stuff being done in the higher level tests. </p>
<h2>Key Concepts</h2>
<p>The Kademlia specification essentially consists of several sub-algorithms:</p>
<ol>
	<li>Registering new peers.</li>
	<li>Updating peer lists.</li>
	<li>Obtaining the closest peer to a key.</li>
<li>Storing and retrieving key-values.</li>
	<li>Managing stale key-value pairs and peers</li>
</ol>
<p>The most complex part of the code is in the registration of new peers, as 
this involves some magic numbers based on the authors' research into the 
performance of other networks as Chord<sup>10</sup> and Pasty<sup>11</sup> and 
the behavior of peers in those networks.</p>
<h3>General Terminology</h3>
<p>There are several terms used in general discussions of P2P systems.</p>
<h4>Overlay Network</h4>
<p>An overlay network is one in which each node keeps a (usually partial) list 
of other nodes participating in the network.</p>
<h3>Kademlia Terminology</h3>
<p>Terms used specifically in the Kademlia specification are described here.</p>
<h4>Node</h4>
<p>A node (also known as a contact) is a peer in the network.</p>
<h4>Node ID</h4>
<p>This is a 160 bit node identifier, obtained from a SHA1 hash.</p>
<h4>k-Bucket</h4>
<p>A collection of at most <i>k</i> nodes (or contacts.)&nbsp; Also simply 
	called a bucket.&nbsp; Each node handles up to <i>k</i> contacts within a 
range of ID's.&nbsp; Initially, the ID range is the entire spectrum from 0 &lt;= id 
&lt;= 2<sup>160</sup> - 1.</p>
<h4>Key-Value</h4>
<p>Peers store values based on 160 bit SHA1 hashed keys.&nbsp; Each stored entry 
consists of a key-value pair.</p>
<h4>Router</h4>
<p>The router manages the collection of k-buckets and also determines into which 
nodes a key-value should be stored.</p>
<h4>Distance / &quot;Closeness&quot;</h4>
<p>The distance between a host and the key is an XOR computation of the host's 
ID with the key.&nbsp; </p>
<h4>Prefix</h4>
<p>A prefix is the term used to describe the <i>n</i> most significant bits (MSB) of an ID.&nbsp; </p>
<h4>Depth</h4>
<p>The depth of a bucket is defined as the shared prefix of a bucket.&nbsp; 
Since buckets are associated with ranges from 2<sup>i</sup> to 2<sup>i+1</sup> - 
1 where 0 &lt;= i &lt; 160, one could say that the depth of a bucket is 160 - i.&nbsp; 
We'll see later that this may not be the case.</p>
<h4>Bucket Split</h4>
<p>A bucket split is something potentially happens when a node's k-bucket is 
full -- meaning it has <i>k</i> contacts -- and a new contact wants to register 
within the bucket's range.&nbsp; At this point, an algorithm kicks in that:</p>
<ol>
	<li>Under one condition, splits the bucket at the range midpoint into two 
	ranges, placing contacts into the appropriate new buckets.</li>
	<li>Under a second condition, splits the bucket when a specific depth 
	qualifier is met.</li>
</ol>
<p>If the bucket can't be split, there is a third fallback that replaces an old 
contact that is no longer responding with the new contact.</p>
<h3>Communication Protocol</h3>
<p>The Kademlia protocol consists of four Remote Procedure Calls (RPC's).&nbsp; 
All RPC's require that the sender provides a random RPC ID which must be echoed 
by the recipient: <font color="#FF00FF">In all RPCs, the recipient must echo a 
160-bit random RPC ID, which provides some resistance to address forgery, PINGS 
can also be piggy-backed on RPC replies for the RPC recipient to obtain 
additional assurance of the sender’s network address.</font></p>
<p>Any time a peer is contacted with any of the four RPC's, it goes through the 
process of adding/updating the contact in its own list.&nbsp; In the description 
below, the concept of &quot;closeness&quot; will be discussed in detail later.</p>
<h4>Ping</h4>
<p><font color="#FF00FF">The PING RPC probes a node to see if it is online.</font>&nbsp; 
This is considered a &quot;primitive&quot; function, in that it just returns the random 
RPC ID that accompanied the Ping request.</p>
<h4>Store</h4>
<p>STORE instructs a node to store a (key, value) pair for later retrieval.&nbsp; 
This is also considered a &quot;primitive&quot; function, as it again just returns the 
random RPC ID that accompanied the Store request.&nbsp; <font color="#FF00FF">To 
store a (key,value) pair, a participant locates the k closest nodes to the key 
and sends them STORE RPCS.</font>&nbsp; The participant does this by inspecting 
its own k closest nodes to the key.</p>
<h4>Find Node</h4>
<p><font color="#FF00FF">FIND_NODE takes a 160-bit ID as an argument. The 
recipient of a the RPC returns (IP address, UDP port, Node ID) triples for the k 
nodes it knows about closest to the target ID. These triples can come from a 
single k-bucket, or they may come from multiple k-buckets if the closest 
k-bucket is not full. In any case, the RPC recipient must return k items (unless 
there are fewer than k nodes in all its k-buckets combined, in which case it 
returns every node it knows about).</font></p>
<p>In an abstracted communication protocol, the recipient needs to return 
information about the protocol -- the kind of protocol and whatever is required 
to contact a peer using that protocol.&nbsp; If multiple protocols are 
supported, we can consider two options:</p>
<ol>
	<li>Return node information only for the protocols that the requester says 
	it supports.</li>
	<li>Alternatively (and not as good an option) is for the requester to filter 
	out returned nodes whose protocols aren't supported.</li>
</ol>
<p>Other considerations when supporting multiple protocols are:</p>
<ul>
	<li>The peer itself may support multiple protocols, so it should probably 
	indicate what those are when it registers with another peer.</li>
	<li>The peer may have a preferred protocol.</li>
</ul>
<p>None of the issues of different protocols is discussed in the spec, this is 
purely my own enhancement.</p>
<p>The Find Node protocol has several purposes:</p>
<ul>
	<li>A peer can issue this RPC on contacts it knows about, updating its own 
	list of &quot;close&quot; peers.</li>
<li>A peer may issue this RPC to discover other peers on the network.</li>
</ul>
<h4>Find Value</h4>
<p><font color="#FF00FF">FIND_VALUE behaves like FIND_NODE - returning (IP 
address, UDP port, Node ID) triples - with one exception. If the RPC recipient 
has received a STORE RPC for the key, it just returns the stored value.</font></p>
<p>If the Find Value RPC returns a list of other peers, it is up to the 
requester to continue searching for the desired value from that list.&nbsp; 
Also, note this technique for caching key-values:</p>
<p><font color="#FF00FF">To find a (key,value) pair, a node starts by performing 
a lookup to find the k nodes with IDs closest to the key. However, value lookups 
use FIND_VALUE rather than FIND_NODE RPCS. Moreover, the procedure halts 
immediately when any node returns the value. For caching purposes, once a lookup 
succeeds, the requesting node stores the (key,value) pair at the closest node it 
observed to the key that did not return the value.</font></p>
<h3>Other Considerations</h3>
<h4>Expiration Time</h4>
<p><font color="#FF00FF">Additionally, each node re-publishes (key,value) pairs 
as necessary to keep them alive, as described later in Section 2.5. This ensures 
persistence (as we show in our proof sketch) of the (key,value) pair with very 
high probability. For Kademlia’s current application (file sharing), we also 
require the original publisher of a (key,value) pair to republish it every 24 
hours. Otherwise, (key,value) pairs expire 24 hours after publication, so as to 
limit stale index information in the system. For other applications, such as 
digital certificates or cryptographic hash to value mappings, longer expiration 
times may be appropriate.</font></p>
<p>If we want to consider using Kademlia in a distributed blockchain 
implementation, it would seem necessary that key-values never expire, otherwise 
this would result in an integrity loss of the blockchain data.</p>
<h4>Over-caching</h4>
<p><font color="#FF00FF">Because of the uni-directionality of the topology, 
future searches for the same key are likely to hit cached entries before 
querying the closest node. During times of high popularity for a certain key, 
the system might end up caching it at many nodes. To avoid “over-caching,” we 
make the expiration time of a (key,value) pair in any node’s database 
exponentially inversely proportional to the number of nodes between the current 
node and the node whose ID is closest to the key ID. While simple LRU eviction 
would result in a similar lifetime distribution, there is no natural way of 
choosing the cache size, since nodes have no a priori knowledge of how many 
values the system will store.</font></p>
<h4>Bucket Refreshes</h4>
<p><font color="#FF00FF">Buckets are generally kept fresh by the traffic of 
requests traveling through nodes. To handle pathological cases in which there 
are no lookups for a particular ID range, each node refreshes any bucket to 
which it has not performed a node lookup in the past hour. Refreshing means 
picking a random ID in the bucket’s range and performing a node search for that 
ID.</font></p>
<h4>Joining a Network</h4>
<p><font color="#FF00FF">To join the network, a node <i>u</i> must have a 
contact to an already participating node <i>w</i>. <i>u</i> inserts <i>w</i> 
into the appropriate k-bucket. <i>u</i> then performs a node lookup for its own 
node ID. Finally, <i>u</i> refreshes all k-buckets further away than its closest 
neighbor. During the refreshes, <i>u</i> both populates its own k-buckets and 
inserts itself into other nodes’ k-buckets as necessary.</font></p>
<h2>Node Requirements</h2>
<p>Let's cover some basic implementation requirements for a node first.&nbsp; </p>
<h3>The BigInteger Class</h3>
<p>We could write our own byte array manipulation and comparison operators, 
which is what zencoders did, or we could use the <code>BigInteger</code> class to handle the 
range of ID's from 0 &lt;= id &lt;= 2<sup>160</sup> - 1.&nbsp; In ended up using 
<code>BigInteger</code> has simply made the code smaller.&nbsp; As a side node, I was 
impressed with Python's ability to handle these values without any special 
classes:</p>
<pre>&gt;&gt;&gt; 2 ** 160
1461501637330902918203684832716283019655932542976L</pre>
<h3>The Node Specification</h3>
<p> <font color="#FF00FF">Participating computers each have a node ID in the 
160-bit key space </font>(Introduction) which is simple enough.&nbsp; </p>
<h4>Ambiguity #1</h4>
<p>But then there's this:&nbsp; <font color="#FF00FF">Kademlia nodes store 
contact information about each other to route query messages. For each 0 &lt; i &lt; 
160, every node keeps a list of [contacts] of distance between 2<sup>i</sup> and 
2<sup>i+1</sup> from itself.&nbsp; We call these lists k-buckets.&nbsp; <i>k</i> 
is chosen such that any given k nodes are very unlikely to fail within an hour 
of each other (for example k = 20). </font>
(Section 2.2)<font color="#FF00FF"> </font>
How is this distance defined?&nbsp; Is this the XOR distance or the integer 
distance?&nbsp; And when the spec says &quot;distance from itself&quot;, what two values 
are being compared?&nbsp; Why even make this comparison?</p>
<h4>Contradiction #1</h4>
<p><font color="#FF00FF">Initially, a node u’s routing tree has a single node— 
one k-bucket covering the entire ID space.</font>&nbsp; (Section 2.4)&nbsp; So 
from Section 2.2, we have each node contain 159 k-buckets (0 &lt; i &lt; 160) covering 
2<sup>i</sup> through 2<sup>i+1</sup>, and from Section 2.4, we have a node 
initialized with one k-bucket.&nbsp; You can see the former specification implemented 
in zencoders code:</p>
<pre>private const int BUCKET_SIZE = 20; // &quot;K&quot; in the spec
private const int NUM_BUCKETS = 8 * ID.ID_LENGTH; // One per bit in an ID

private List&lt;List&lt;Contact&gt;&gt; buckets;
private List&lt;DateTime&gt; accessTimes; // last bucket write or explicit touch
private ID ourID;

/// &lt;summary&gt;
/// Make a new bucket list, for holding node contacts.
/// &lt;/summary&gt;
/// &lt;param name=&quot;ourID&quot;&gt;The ID to center the list on.&lt;/param&gt;
public BucketList(ID ourID)
{
  this.ourID = ourID;
  buckets = new List&lt;List&lt;Contact&gt;&gt;(NUM_BUCKETS);
  accessTimes = new List&lt;DateTime&gt;();

  // Set up each bucket
  for(int i = 0; i &lt; NUM_BUCKETS; i++) 
  {
    buckets.Add(new List&lt;Contact&gt;(BUCKET_SIZE));
    accessTimes.Add(default(DateTime));
  }
}</pre>
<p>Here <code>8 * ID.ID_LENGTH</code> (8 * 20 = 160) buckets are created at the 
get go, each with 20 contacts (the suggested <i>k</i> value.)&nbsp; This is 
hard-wired in the zencoders implementation.</p>
<p>You can see the latter specification in the Brian Muller's Python code:</p>
<pre>def flush(self):
  self.buckets = [KBucket(0, 2 ** 160, self.ksize)]</pre>
<p>Here, a single bucket is created spanning the ID space.&nbsp; The Python code 
is correct because it also implements bucket splitting, which is in the second 
version of the specification.</p>
<h4>Artifact #1</h4>
<p>In the former specification, this limits the total number of contacts that 
your server can handle to 160 * 20, or 3200 contacts.</p>
<h2>Initial ID, Router, Contact, KBucket, BucketList, Node, and Dht Implementations</h2>
<p>After resolving the ambiguity and contradiction, we can implement most of the 
relevant classes.&nbsp; Note that some of the properties in the following 
implementation will be discussed later.</p>
<p>When we're all done with the initial implementation, we have this class 
model:</p>
<ul>
	<li>Blue - classes</li>
	<li>Orangey - interfaces</li>
	<li>Purple - collections</li>
	<li>Green - value type fields</li>
</ul>
<p align="center"><img border="0" src="classmodel.png" width="793" height="673"></p>
<h3>The ID Class</h3>
<pre>using System.Numerics;

namespace Clifton.Kademlia
{
  public class ID
  {
#if DEBUG // For unit testing.
    public BigInteger Value { get { return id; } }
#endif

    protected BigInteger id;

    /// &lt;summary&gt;
    /// Construct the ID from a byte array.
    /// &lt;/summary&gt;
    public ID(byte[] data)
    {
      IDInit(data);
    }

    /// &lt;summary&gt;
    /// Construct the ID from another BigInteger value.
    /// &lt;/summary&gt;
    public ID(BigInteger bi)
    {
      id = bi;
    }

    /// &lt;summary&gt;
    /// Initialize the ID from a byte array, appending a 0 to force unsigned values.
    /// &lt;/summary&gt;
    protected void IDInit(byte[] data)
    {
      Validate.IsTrue(data.Length == Constants.ID_LENGTH_BYTES, &quot;ID must be &quot; + Constants.ID_LENGTH_BYTES + &quot; bytes in length.&quot;);
      id = new BigInteger(data.Append0());    }
  }
}</pre>
<p><img border="0" src="note.png" width="24" height="32"> Two things of note here.</p>
<ol>
	<li>The most interesting thing here is the appending the byte array with a 0 to 
force unsigned values in the BigInteger.&nbsp; If we don't do this, any byte 
array where the MSB of byte[0] is set will be treated as a negative number, 
which we don't want when comparing the range of a bucket.&nbsp; This is handled 
by a simple extension method:</li>
</ol>
<pre>/// &lt;summary&gt;
/// Append a 0 to the byte array so that when converting to a BigInteger, the value remains positive.
/// &lt;/summary&gt;
public static byte[] Append0(this byte[] b)
{
  return b.Concat(new byte[] { 0 }).ToArray();
}</pre>
<ol>
	<li value="2">The byte array is in little-endian order, meaning that the 
	least significant value is stored first.</li>
</ol>
<h4>Unit Tests</h4>
<p><img border="0" src="unittest.png" width="14" height="32"></p>
<pre>[TestMethod]
public void LittleEndianTest()
{
  byte[] test = new byte[20];
  test[0] = 1;
  Assert.IsTrue(new ID(test).Value == new BigInteger(1), &quot;Expected value to be 1.&quot;);
}

[TestMethod]
public void PositiveValueTest()
{
  byte[] test = new byte[20];
  test[19] = 0x80;
  Assert.IsTrue(new ID(test).Value == BigInteger.Pow(new BigInteger(2), 159), &quot;Expected value to be 1.&quot;);
}

[TestMethod, ExpectedException(typeof(IDLengthException))]
public void BadIDTest()
{
  byte[] test = new byte[21];
  new ID(test);
}</pre>
<h3>The Router Class</h3>
<p>At the moment, the router simply manages the host's node:</p>
<pre>namespace Clifton.Kademlia
{
  public class Router
  {
#if DEBUG // for unit testing
    public Node Node { get { return node; } }
#endif

    protected Node node;

    public Router(Node node)
    {
      this.node = node;
    }
  }
}</pre>
<h3>The Contact Class</h3>
<p>The contact class manages the contact's ID, last seen, and network 
connectivity.&nbsp; Because I want to abstract the way network protocols are 
handled, such that it is easy to test nodes in a virtual (in-memory) network, or 
nodes that use different protocols (UDP, TCP/IP, WebSockets, etc.) the network 
protocol is abstracted in an interface.</p>
<pre>using System;

namespace Clifton.Kademlia
{
  public class Contact
  {
#if DEBUG // For unit testing
    public IProtocol Protocol { get; set; }
#else
    public IProtocol Protocol { get; protected set; }
#endif

    public DateTime LastSeen { get; protected set; }
    public ID ID { get; protected set; }

    /// &lt;summary&gt;
    /// Initialize a contact with its protocol and ID.
    /// &lt;/summary&gt;
    public Contact(IProtocol protocol, ID contactID)
    {
      Protocol = protocol;
      ID = contactID;
      Touch();
    }

    /// &lt;summary&gt;
    /// Update the fact that we've just seen this contact.
    /// &lt;/summary&gt;
    public void Touch()
    {
      LastSeen = DateTime.Now;
    }
  }
}</pre>
<h3>The KBucket Class</h3>
<p>Each k-bucket maintains a list of up to <i>k</i> contacts.</p>
<pre>using System.Collections.Generic;
using System.Numerics;

namespace Clifton.Kademlia
{
  public class KBucket
  {
#if DEBUG // For unit testing.
    public List&lt;Contact&gt; Contacts { get { return contacts; } }
    public BigInteger Low { get { return low; } }
    public BigInteger High { get { return high; } }
#endif

    protected List&lt;Contact&gt; contacts;
    protected BigInteger low;
    protected BigInteger high;

    /// &lt;summary&gt;
    /// Initializes a k-bucket with the default range of 0 - 2^160
    /// &lt;/summary&gt;
    public KBucket()
    {
      contacts = new List&lt;Contact&gt;();
      low = 0;
      high = BigInteger.Pow(new BigInteger(2), 160);
    }

    /// &lt;summary&gt;
    /// Initializes a k-bucket with a specific ID range.
    /// &lt;/summary&gt;
    public KBucket(BigInteger low, BigInteger high)
    {
      contacts = new List&lt;Contact&gt;();
      this.low = low;
      this.high = high;
    }

    /// &lt;summary&gt;
    /// Add a contact to the bucket, at the end, as this is the most recently seen contact.
    /// A full bucket throws an exception.
    /// &lt;/summary&gt;
    public void AddContact(Contact contact)
    {
      Validate.IsTrue&lt;TooManyContactsException&gt;(contacts.Count &lt; Constants.K, &quot;Bucket is full&quot;);
      contacts.Add(contact);
    }
  }
}</pre>
<h4>Unit Test</h4>
<p><img border="0" src="unittest.png" width="14" height="32"></p>
<pre>[TestMethod, ExpectedException(typeof(TooManyContactsException))]
public void TooManyContactsTest()
{
  KBucket kbucket = new KBucket();

  // Add max # of contacts.
  Constants.K.ForEach(n =&gt; kbucket.AddContact(new Contact(null, new ID(n))));

  // Add one more.
  kbucket.AddContact(new Contact(null, new ID(21)));
}</pre>
<h3>The BucketList Class</h3>
<p>The bucket list class is a high level singleton container for buckets and operations 
that manipulate buckets.&nbsp; For the moment, most of this is stubbed with 
minimal behavior:</p>
<pre>using System.Collections.Generic;

namespace Clifton.Kademlia
{
  public class BucketList
  {
#if DEBUG // Used for unit testing.
    public List&lt;KBucket&gt; Buckets { get { return buckets; } }
#endif

    protected List&lt;KBucket&gt; buckets;
    protected ID ourID;

    /// &lt;summary&gt;
    /// Initialize the bucket list with our host ID and create a single bucket for the full ID range.
    /// &lt;/summary&gt;
    /// &lt;param name=&quot;ourID&quot;&gt;&lt;/param&gt;
    public BucketList(ID ourID)
    {
      this.ourID = ourID;
      buckets = new List&lt;KBucket&gt;();

      // First kbucket has max range.
      buckets.Add(new KBucket());
    }

    public void AddContact(Contact contact)
    {
      // to be implemented...
    }
  }
}</pre>
<h3>The Node Class</h3>
<p>The node class is another high level singleton container for handling the Kademlia 
commands sent over the wire.&nbsp; This is mostly stubbed for now:</p>
<pre>using System.Collections.Generic;

namespace Clifton.Kademlia
{
  public class Node
  {
#if DEBUG // For unit testing.
    public BucketList BucketList { get { return bucketList; } }
    public IStorage Storage { get { return storage; } }
    public Contact OurContact { get { return ourContact; } }
#endif

    protected Contact ourContact;
    protected BucketList bucketList;

    public Node(Contact us, IStorage storage)
    {
      ourContact = us;
      bucketList = new BucketList(us.ContactID);
      this.storage = storage;
    }

    /// &lt;summary&gt;
    /// Someone is pinging us. Register the contact and respond.
    /// &lt;/summary&gt;
    public Contact Ping(Contact sender)
    {
      // TODO...

      return ourContact;
    }

    /// &lt;summary&gt;
    /// Store a key-value pair in our storage space.
    /// &lt;/summary&gt;
    public void Store(Contact sender, ID keyID, string val)
    {
      // TODO...
    }

    /// &lt;summary&gt;
    /// From the spec: FindNode takes a 160-bit ID as an argument. The recipient of the RPC returns (IP address, UDP port, Node ID) triples 
    /// for the k nodes it knows about closest to the target ID. These triples can come from a single k-bucket, or they may come from 
    /// multiple k-buckets if the closest k-bucket is not full. In any case, the RPC recipient must return k items (unless there are 
    /// fewer than k nodes in all its k-buckets combined, in which case it returns every node it knows about).
    /// &lt;/summary&gt;
    /// &lt;returns&gt;&lt;/returns&gt;
    public (List&lt;Contact&gt; contacts, string val) FindNode(Contact sender, ID toFind)
    {
      // TODO...
      return (null, null);
    }

    /// &lt;summary&gt;
    /// Returns either a list of close contacts or a the value, if the node's storage contains the value for the key.
    /// &lt;/summary&gt;
    public (List&lt;Contact&gt; contacts, string val) FindValue(Contact sender, ID keyID)
    {
      // TODO:

      return (null, null);
    }
  }
}</pre>
<p><img border="0" src="note.png" width="24" height="32"> Of note here is the interface <code>IStorage</code> which abstracts the storage mechanism 
for key-value pairs.</p>
<h3>The Dht Class</h3>
<p>The Dht class is the &quot;server&quot; - the entry point for instantiating our peer.&nbsp; At the moment, the Dht class is simply a container for the Router:</p>
<pre>using System;

namespace Clifton.Kademlia
{
  public class Dht
  {
#if DEBUG // for unit testing
    public Router Router { get { return router; } }
#endif

    protected Router router;
  }
}</pre>
<h2>Adding Contacts - Discussion</h2>
<p>Version 2, Section 2.2 of the specification initially states this simple 
algorithm for dealing adding contacts:</p>
<p><font color="#FF00FF">When a Kademlia node receives any message (request or 
reply) from another node, it updates the appropriate k-bucket for the sender’s 
node ID. If the sending node already exists in the recipient’s k-bucket, the 
recipient moves it to the tail of the list. If the node is not already in the 
appropriate k-bucket and the bucket has fewer than k entries, then the recipient 
just inserts the new sender at the tail of the list. If the appropriate k-bucket 
is full, however, then the recipient pings the k-bucket’s least-recently seen 
node to decide what to do. If the least recently seen node fails to respond, it 
is evicted from the k-bucket and the new sender inserted at the tail. Otherwise, 
if the least-recently seen node responds, it is moved to the tail of the list, 
and the new sender’s contact is discarded.</font></p>
<p>Let's define a few terms (if you aren't sure, don't know, or just want some 
clarity):</p>
<ul>
	<li>head of the list - the first entry in the list</li>
	<li>tail of the list - the last entry in the list</li>
	<li>&quot;the appropriate k-bucket for the sender's node ID&quot; - this is the 
	k-bucket for which the sender's node ID is in the range of the k-bucket.</li>
</ul>
<p>Here's a flowchart of what the spec says:</p>
<p align="center">
<img border="0" src="addContact1.png" width="520" height="679"></p>
<p>This seems reasonable and the spec goes on to state:</p>
<p><font color="#FF00FF">k-buckets effectively implement a least-recently seen 
eviction policy, except that live nodes are never removed from the list. This 
preference for old contacts is driven by our analysis of Gnutella trace data 
collected by Saroiu et. al. ... The longer a node has been up, the more likely 
it is to remain up another hour. By keeping the oldest live contacts around, 
k-buckets maximize the probability that the nodes they contain will remain 
online.&nbsp; A second benefit of k-buckets is that they provide resistance to 
certain DoS attacks. One cannot flush nodes' routing state by flooding the 
system with new nodes. Kademlia nodes will only insert the new nodes in the 
k-buckets when old nodes leave the system.</font></p>
<p>We also observe that this has nothing to do with binary trees, which is 
something version 2 of the spec introduced.&nbsp; This is basically a hang-over 
from version 1 of the spec.</p>
<h3>Contradiction #2</h3>
<p>Section 2.4 states something slightly different:</p>
<p><font color="#FF00FF">Nodes in the routing tree are allocated dynamically, as 
needed. Initially, a node u’s routing tree has a single node— one k-bucket 
covering the entire ID space. When u learns of a new contact, it attempts to 
insert the contact in the appropriate k-bucket. If that bucket is not full, the 
new contact is simply inserted. Otherwise, if the k-bucket’s range includes u’s 
own node ID, then the bucket is split into two new buckets, the old contents 
divided between the two, and the insertion attempt repeated. If a k-bucket with 
a different range is full, the new contact is simply dropped.</font></p>
<h4>Terminology</h4>
<ul>
	<li>&quot;u's routing tree&quot; - the host's bucket list.</li>
	<li>&quot;if a k-bucket with a different range is full&quot; - meaning, a k-bucket 
	that does not include u's own node ID.</li>
</ul>
<p>The purpose of allowing a bucket to split if it contains the host's node ID 
is so that the host keeps a list of nodes that are &quot;close to it&quot; -- closeness 
defined essentially by the integer difference of the node ID's, not the XOR 
difference (more on this whole XOR thing later.)</p>
<p>So this algorithm looks like this:</p>
<p align="center"><img border="0" src="addContact2.png" width="761" height="625"></p>
<p>What happened to pinging the least seen contact and replacing it?&nbsp; </p>
<h3>Contradiction #3</h3>
<p>But the spec then goes on to say:</p>
<p><font color="#FF00FF">One complication arises in highly unbalanced trees.&nbsp; 
Suppose node <i>u</i> joins the system and is the only node whose ID begins 000. 
Suppose further that the system already has more than k nodes with prefix 001. 
Every node with prefix 001 would have an empty k-bucket into which <i>u</i> 
should be inserted, yet <i>u</i>’s bucket refresh would only notify k of the 
nodes.&nbsp; To avoid this problem, Kademlia nodes keep all valid contacts in a 
subtree of size at least k nodes, even if this requires splitting buckets in 
which the node’s own ID does not reside. Figure 5 illustrates these additional 
splits.</font></p>
<h4>Terminology</h4>
<ul>
	<li>&quot;a subtree of size at least k nodes&quot; - ok, we can vaguely see that a 
	subtree contains other subtrees where the total number of contacts is 
	greater than k.</li>
	<li>&quot;even if this requires splitting buckets in which the node's own ID does 
	not reside&quot; - not only is this contradictory, but there's no explanation of 
	what &quot;even if this requires&quot; means.&nbsp; How do you code this?</li>
</ul>
<p>This section of the specification apparently creates much confusion -- I 
found several links with people asking about this section.&nbsp; It's 
unfortunate that the original authors do not themselves answer these questions.&nbsp; 
Jim Dixon has a very interesting response<sup>12</sup> on The Mail Archive which 
I present in full here:</p>
<blockquote>
	<p>&quot;The source of confusion is that the 13-page version of the Kademlia uses<br>
	the same term to refer to two different data structures. The first is<br>
	well-defined: k-bucket i contains zero to k contacts whose XOR distance is<br>
	[2^i..2^(i+1)). It cannot be split. The current node can only be in<br>
	bucket zero, if it is present at all. In fact its presence would be<br>
	pointless or worse.<br>
	<br>
	The second thing referred to as a k-bucket doesn't have the same<br>
	properties. Specifically, the current node must be present, it wanders<br>
	from one k-bucket to another, these k-buckets can be split, and there are<br>
	sometimes ill-defined constraints on the characteristics of subtrees of<br>
	k-buckets, such as the requirement that &quot;Kademlia nodes keep all valid<br>
	contacts in a subtree of size of at least k nodes, even if this requires<br>
	splitting buckets in which the node's own ID does not reside&quot; (section<br>
	2.4, near the end).<br>
	<br>
	In a generous spirit, you might say that the logical content of the two<br>
	descriptions is the same. However, for someone trying to implement<br>
	Kademlia, the confusion of terms causes headaches -- and leads to a<br>
	situation where all sorts of things are described as Kademlia, because<br>
	they can be said to be, if you are of a generous disposition. However,<br>
	not surprisingly, they don't interoperate.&quot;</p>
</blockquote>
<p>So my decision, given the lack of clarity and by the authors of the spec, is 
to ignore this, because, as you will see next, there is yet another version of 
how contacts are added.</p>
<h3>Contradiction #4</h3>
<p>In Section 4.2, on Accelerated Lookups, we have a different specification for 
how contacts are added:</p>
<p><font color="#FF00FF">Section 2.4 describes how a Kademlia node splits a 
k-bucket when the bucket is full and its range includes the node’s own ID. The 
implementation, however, also splits ranges not containing the node’s ID, up to 
b - 1 levels. If b = 2, for instance, the half of the ID space not containing 
the node’s ID gets split once (into two ranges); if b = 3, it gets split at two 
levels into a maximum of four ranges, etc. The general splitting rule is that a 
node splits a full k-bucket if the bucket’s range contains the node’s own ID or 
the depth d of the k-bucket in the routing tree satisfies d&nbsp; (mod b) != 0.</font></p>
<h4>Terminology</h4>
<ul>
	<li>depth - According to the spec: <font color="#FF00FF">The depth is just 
	the length of the prefix shared by all nodes in the k-bucket’s range. </font>
	Do not confuse that with this statement: <font color="#FF00FF">Define the 
	depth, h, of a node to be 160 - <i>i</i>, where <i>i</i> is the smallest 
	index of a non-empty bucket.</font>&nbsp; The former is referring to the 
	depth of <i>a k-bucket</i>, the 
	latter the depth of <i>the node</i>.</li>
</ul>
<h3>Ambiguity #2</h3>
<p>With regards to the definition of depth, does this mean &quot;the length of prefix 
shared by <i>any</i> node that would <i>reside in the k-bucket's range</i>&quot; or 
does it mean &quot;the length of a prefix shared by <i>all</i> nodes <i>currently in the k-bucket</i>?&quot;</p>
<p>If we look at Brian Muller's implementation, we see the latter case:</p>
<pre>def depth(self):
  <span style="color: rgb(36, 41, 46); font-family: SFMono-Regular, Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;">sp </span><span class="pl-k" style="box-sizing: border-box; color: rgb(215, 58, 73); font-family: SFMono-Regular, Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial;">=</span><span style="color: rgb(36, 41, 46); font-family: SFMono-Regular, Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;"> sharedPrefix([bytesToBitString(n.id) </span><span class="pl-k" style="box-sizing: border-box; color: rgb(215, 58, 73); font-family: SFMono-Regular, Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial;">for</span><span style="color: rgb(36, 41, 46); font-family: SFMono-Regular, Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;"> n </span><span class="pl-k" style="box-sizing: border-box; color: rgb(215, 58, 73); font-family: SFMono-Regular, Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial;">in</span><span style="color: rgb(36, 41, 46); font-family: SFMono-Regular, Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;"> </span><span class="pl-c1" style="box-sizing: border-box; color: rgb(0, 92, 197); font-family: SFMono-Regular, Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial;">self</span><span style="color: rgb(36, 41, 46); font-family: SFMono-Regular, Consolas, &quot;Liberation Mono&quot;, Menlo, Courier, monospace; font-size: 12px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: pre; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgb(255, 255, 255); text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;">.nodes.values()])</span>
  return len(sp)

def sharedPrefix(args):
  i = 0
  while i &lt; min(map(len, args)):
   if len(set(map(operator.itemgetter(i), args))) != 1:
     break
    i += 1
  return args[0][:i]</pre>
<p>Here, the depth is determined by the shared prefixes in the nodes.</p>
<h3>What is the Bucket Splitting Algorithm Actually Doing?</h3>
<p>So, when we use the following algorithm to determine whether a bucket can be 
split:</p>
<pre>kbucket.HasInRange(ourID) || ((kbucket.Depth() % Constants.B) != 0)</pre>
<p>What is this actually doing?</p>
<ol>
	<li>First, the HasInRange is testing whether our node ID is close to the 
	contact's node ID.&nbsp; If our node ID is in the range of the bucket 
	associated with the contact's node ID, then we know the two nodes are 
	&quot;close&quot; in terms of the integer difference.&nbsp; Initially, the range spans 
	the entire 2<sup>160</sup> ID space, so everybody is &quot;close.&quot;&nbsp; This 
	test of &quot;closeness&quot; is refined as new contacts are added.</li>
	<li>Regarding the depth mod 5 computation, I asked Brian Muller this 
	question: &quot;is the purpose of the depth to limit the number of &quot;new&quot; nodes 
	that a host will maintain (ignoring for the moment the issue of pinging an 
	old contact to see if can be replaced)?&quot; to which he replied: &quot;Yep! The idea 
	is that a node should know about nodes spread across the network - though 
	definitely not all of them. The depth is used as a way to control how &quot;deep&quot; 
	a nodes' understanding of the network is (and the number of nodes it knows 
	about).&quot;</li>
</ol>
<p>As buckets split, eventually buckets will become full that do not contain the 
node ID.&nbsp; The depth to which the bucket has split is based on the number of 
bits shared in the prefix of the contacts in the bucket.&nbsp; With random ID's, 
this number will initially be small, but as bucket ranges become more narrow 
from subsequent splits, more contacts will begin the share the same prefix and 
the bucket when split, will result in less &quot;room&quot; for new contacts.&nbsp; 
Eventually, when the bucket range becomes narrow enough, the number of bits 
shared in the prefix of the contacts in the bucket reaches the threshold <i>b</i> 
which the spec says should be 5.</p>
<h3>Failing to add Yourself to a Peer - Self Correcting</h3>
<p>Let's say your a new node and you want to register yourself with a known 
peer, but that peer is basically maxed out for the number of contacts that it 
can hold in the particular bucket for your ID -- the depth is <i>b</i>.&nbsp; In 
this case, you will not be added to the peer's contact list.&nbsp; The Kademlia 
spec does not indicate in its protocol how this condition should be handled.&nbsp; 
Interestingly, this is not an issue.&nbsp; Whether you are successfully added as 
a contact or not, you will receive back &quot;nearby&quot; peers.&nbsp; Any time you 
contact those peers (to store a value, for example) all the peers that you 
contact will try to add your contact.&nbsp; When one succeeds, your contact ID 
will be disseminated slowly through the network. </p>
<h3><a name="Breaking_Kademlia">Degrading a Kademlia</a> Peer</h3>
<p>Given a peer with both an ID and a single contact ID of less than 2<sup>159</sup>, 
it 
will initially split once for 20 contacts that are added having ID's greater than 2<sup>159</sup>.&nbsp; 
</p>
<p>All of those 20 contacts having ID's greater than 2<sup>159</sup> will go in the second 
bucket.&nbsp; The peer ID will not be in this second bucket range.&nbsp; If those contacts 
in the second bucket have ID's where the number of shared bits is <i>b</i>, 
therefore <i>b</i> mod <i>b</i> 
== 0, any new contact in the range of the second bucket will not be added.&nbsp; </p>
<p align="center"><img border="0" src="degrade1.png" width="651" height="449"></p>
<p><img border="0" src="unittest.png" width="14" height="32"> We can 
verify this with a unit test:</p>
<pre>/// &lt;summary&gt;
/// Force a failed add by choosing node ID's that cause depth mod 5 != 0 to be false.
/// &lt;/summary&gt;
[TestMethod]
public void ForceFailedAddTest()
{
  // force host node ID to &lt; 2^159 so the node ID is not in the 2^159 ... 2^160 range
  byte[] hostID = new byte[20];
  hostID[19] = 0x7F;
  BucketList bucketList = new BucketList(new ID(hostID));

  // Also add a contact in this 0 - 2^159 range, arbitrarily something not our host ID.
  // This ensures that only one bucket split will occur after 20 nodes with ID &gt;= 2^159 are added,
  // otherwise, buckets will in the 2^159 ... 2^160 space.
  byte[] id = new byte[20];
  id[0] = 1;
  bucketList.AddContact(new Contact(null, new ID(id)));

  Assert.IsTrue(bucketList.Buckets.Count == 1, &quot;Bucket split should not have occurred.&quot;);
  Assert.IsTrue(bucketList.Buckets[0].Contacts.Count == 1, &quot;Expected 1 contact in bucket 0.&quot;);

  // make sure contact ID's all have the same 5 bit prefix and are in the 2^159 ... 2^160 - 1 space
  byte[] contactID = new byte[20];
  contactID[19] = 0x80;
  // 1000 xxxx prefix, xxxx starts at 1000 (8)
  // this ensures that all the contacts in a bucket match only the prefix as only the first 5 bits are shared.
  // |----| shared range
  // 1000 1000 ...
  // 1000 1100 ...
  // 1000 1110 ...
  byte shifter = 0x08;
  int pos = 19;

  Constants.K.ForEach(() =&gt;
  {
    contactID[pos] |= shifter;
    bucketList.AddContact(new Contact(null, new ID(contactID)));
    shifter &gt;&gt;= 1;

    if (shifter == 0)
    {
      shifter = 0x80;
      --pos;
    }
  });

  Assert.IsTrue(bucketList.Buckets.Count == 2, &quot;Bucket split should have occurred.&quot;);
  Assert.IsTrue(bucketList.Buckets[0].Contacts.Count == 1, &quot;Expected 1 contact in bucket 0.&quot;);
  Assert.IsTrue(bucketList.Buckets[1].Contacts.Count == 20, &quot;Expected 20 contacts in bucket 1.&quot;);

  // This next contact should not split the bucket as depth == 5 and therefore adding the contact will fail.
  // Any unique ID &gt;= 2^159 will do.
  id = new byte[20];
  id[19] = 0x80;
  bucketList.AddContact(new Contact(null, new ID(id)));

  Assert.IsTrue(bucketList.Buckets.Count == 2, &quot;Bucket split should not have occurred.&quot;);
  Assert.IsTrue(bucketList.Buckets[0].Contacts.Count == 1, &quot;Expected 1 contact in bucket 0.&quot;);
  Assert.IsTrue(bucketList.Buckets[1].Contacts.Count == 20, &quot;Expected 20 contacts in bucket 1.&quot;);
}</pre>
<p>What we've effectively done is break Kademlia, as the peer will no longer 
accept half of the possible ID range.&nbsp; As long as the peer ID is outside 
the range of a bucket whose shared prefix mod <i>b</i> is 0, we can continue 
this process by adding contacts with a shared prefixes (assume <i>b</i>==5)&nbsp; 
01xxx, 001xx, 0001x, and 00001 and again for every multiple of <i>b</i> bits.&nbsp; 
If a peer has a &quot;small&quot; ID, you can easily prevent it from accepting new 
contacts within half of its bucket ranges.</p>
<p>There are several ways to mitigate this:</p>
<ol>
	<li>ID's should not be created by the user, they should be assigned by the 
	library.&nbsp; Of course, given the open source nature of all these 
	implementations, enforcing this is impossible.</li>
<li>A contact's ID should be unique for its network address -- in other words, a 
malicious peer should not be able to create multiple contacts simply by 
providing a unique ID in its contact request.</li>
	<li>One might consider increasing <i>b</i> as <i>i</i> in 2<sup><i>i</i></sup> 
	increases.&nbsp; There might be some justification for this, as the range 2<sup>159</sup> 
	through 2<sup>160</sup> - 1 contains half the possible contacts, one might 
	allow the depth for bucket splitting to be greater than the recommended <i>b</i> 
	= 5.</li>
</ol>
<h2>Adding Contacts - Implementation</h2>
<p>This is the flowchart of what we're implementing:</p>
<p align="center">
<img border="0" src="addContact3.png" width="664" height="838"></p>
<p>As I'm using Brian Muller's implementation as the authority with regards to 
the spec, we'll go with how he coded the algorithm and (eventually) 
incorporating the fallback where we discard nodes in a full k-bucket that don't 
respond to a ping -- but that's later.</p>
<p>The <code>BucketList</code> class implements the algorithm to add a contact:</p>
<pre>	/// &lt;summary&gt;
/// Add a contact if possible, based on the algorithm described
/// in sections 2.2, 2.4 and 4.2
/// &lt;/summary&gt;
public void AddContact(Contact contact)
{
  Validate.IsFalse&lt;OurNodeCannotBeAContactException&gt;(ourID == contact.ID, &quot;Cannot add ourselves as a contact!&quot;);

  contact.Touch(); // Update the LastSeen to now.
  KBucket kbucket = GetKBucket(contact.ID);

  if (kbucket.Contains(contact.ID))
  {
    // Replace the existing contact, updating the network info and LastSeen timestamp.
    kbucket.Replace(contact);
  }
  else if (kbucket.IsBucketFull)
  {
    if (CanSplit(kbucket))
    {
      // Split the bucket and try again.
      (KBucket k1, KBucket k2) = kbucket.Split();
      int idx = GetKBucketIndex(contact.ID);
      buckets[idx] = k1;
      buckets.Insert(idx + 1, k2);
      AddContact(contact);
    }
    else
    {
      // TODO: Ping the oldest contact to see if it's still 
      // around and replace it if not.
    }
  }
  else
  {
    // Bucket isn't full, so just add the contact.
    kbucket.AddContact(contact);
  }
}</pre>
<p>We have a few helper methods in this class as well:</p>
<pre>protected virtual bool CanSplit(KBucket kbucket)
{
  return kbucket.HasInRange(ourID) || ((kbucket.Depth() % Constants.B) != 0);
}

#if DEBUG
public KBucket GetKBucket(ID otherID)
#else
protected KBucket GetKBucket(ID otherID)
#endif
{
  return buckets[buckets.FindIndex(b =&gt; b.HasInRange(otherID))];
}

protected int GetKBucketIndex(ID otherID)
{
  return buckets.FindIndex(b =&gt; b.HasInRange(otherID));
}</pre>
<p>The method <code>CanSplit</code> is <code>virtual</code> so you can provide a different implementation.</p>
<p>The majority of the remaining work is done in the <code>KBucket</code> class:</p>
<pre>/// &lt;summary&gt;
/// Splits the kbucket into returning two new kbuckets filled with contacts separated by the new midpoint
/// &lt;/summary&gt;
public (KBucket, KBucket) Split()
{
  BigInteger midpoint = (Low + High) / 2;
  KBucket k1 = new KBucket(Low, midpoint);
  KBucket k2 = new KBucket(midpoint, High);

  Contacts.ForEach(c =&gt;
  {
    // &lt;, because the High value is exclusive in the HasInRange test.
    KBucket k = c.ID.Value &lt; midpoint ? k1 : k2;
    k.AddContact(c);
  });

  return (k1, k2);
}

/// &lt;summary&gt;
/// Returns number of bits that are in common across all contacts.
/// If there are no contacts, or no shared bits, the return is 0.
/// &lt;/summary&gt;
public int Depth()
{
  bool[] bits = new bool[0];

  if (contacts.Count &gt; 0)
  {
    // Start with the first contact.
    bits = contacts[0].ID.Bytes.Bits().ToArray();

    contacts.Skip(1).ForEach(c =&gt; bits = SharedBits(bits, c.ID));
  }

  return bits.Length;
}

/// &lt;summary&gt;
/// Returns a new bit array of just the shared bits.
/// &lt;/summary&gt;
protected bool[] SharedBits(bool[] bits, ID id)
{
  bool[] idbits = id.Bytes.Bits().ToArray();

  // Useful for viewing the bit arrays.
  //string sbits1 = System.String.Join(&quot;&quot;, bits.Select(b =&gt; b ? &quot;1&quot; : &quot;0&quot;));
  //string sbits2 = System.String.Join(&quot;&quot;, idbits.Select(b =&gt; b ? &quot;1&quot; : &quot;0&quot;));

  int q = Constances.ID_LENGTH_BITS - 1;
  int n = bits.Length - 1;
  List&lt;bool&gt; sharedBits = new List&lt;bool&gt;();

  while (n &gt;= 0 &amp;&amp; bits[n] == idbits[q])
  {
    sharedBits.Insert(0, (bits[n]));
    --n;
    --q;
  }

  return sharedBits.ToArray();
}</pre>
<p>Recall that the ID is stored as a little-endian value, and the prefix is most 
significant bits, so we have to work the ID backwards n-1 to 0.&nbsp; 
<img border="0" src="note.png" width="24" height="32"> Also note 
the implementation of the <code>Bytes</code> property in the <code>ID</code> class:</p>
<pre>// Zero-pad msb's if ToByteArray length != Constants.LENGTH_BYTES
// The array returned is in little-endian order (lsb at index 0)
public byte[] Bytes
{
  get
  {
    byte[] bytes = new byte[Constants.ID_LENGTH_BYTES];
    byte[] partial = id.ToByteArray().Take(Constants.ID_LENGTH_BYTES).ToArray(); // remove msb 0 at index 20.
    partial.CopyTo(bytes, 0);

    return bytes;
  }
}</pre>
<p>and the <code>Bits</code> extension method:</p>
<pre>/// &lt;summary&gt;
/// Little endian conversion of bytes to bits.
/// &lt;/summary&gt;
public static IEnumerable&lt;bool&gt; Bits(this byte[] bytes)
{
  IEnumerable&lt;bool&gt; GetBits(byte b)
  {
    byte shifter = 0x01;

    for (int i = 0; i &lt; 8; i++)
    {
      yield return (b &amp; shifter) != 0;
      shifter &lt;&lt;= 1;
    }
  }

  return bytes.SelectMany(GetBits);
}</pre>
<h3>Basic Unit Tests</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> A few basic unit tests:</p>
<pre>[TestMethod]
public void UniqueIDAddTest()
{
  BucketList bucketList = new BucketList(ID.RandomID);
  Constants.K.ForEach(() =&gt; bucketList.AddContact(new Contact(null, ID.RandomID)));
  Assert.IsTrue(bucketList.Buckets.Count == 1, &quot;No split should have taken place.&quot;);
  Assert.IsTrue(bucketList.Buckets[0].Contacts.Count == Constants.K, &quot;K contacts should have been added.&quot;); 
}

[TestMethod]
public void DuplicateIDTest()
{
  BucketList bucketList = new BucketList(ID.RandomID);
  ID id = ID.RandomID;
  bucketList.AddContact(new Contact(null, id));
  bucketList.AddContact(new Contact(null, id));
  Assert.IsTrue(bucketList.Buckets.Count == 1, &quot;No split should have taken place.&quot;);
  Assert.IsTrue(bucketList.Buckets[0].Contacts.Count == 1, &quot;Bucket should have one contact.&quot;);
}

[TestMethod]
public void BucketSplitTest()
{
  BucketList bucketList = new BucketList(ID.RandomID);
  Constants.K.ForEach(() =&gt; bucketList.AddContact(new Contact(null, ID.RandomID)));
  bucketList.AddContact(new Contact(null, ID.RandomID));
  Assert.IsTrue(bucketList.Buckets.Count &gt; 1, &quot;Bucket should have split into two or more buckets.&quot;);
}</pre>
<h2>Adding Contacts - Distribution Tests Reveal Importance of Randomness</h2>
<p>Some very interesting things are revealed with the above implementation.&nbsp; 
Let's write a unit test that runs the process of adding 3200 contacts, and we do 
this 100 times, to get some results about the number of contacts that are 
actually added:</p>
<h3>Distribution Tests</h3>
<p><img border="0" src="unittest.png" width="14" height="32"></p>
<pre>[TestMethod]
public void RandomIDDistributionTest()
{
  Random rnd = new Random();
  byte[] buffer = new byte[20];
  List&lt;int&gt; contactsAdded = new List&lt;int&gt;();

  100.ForEach(() =&gt;
  {
    rnd.NextBytes(buffer);
    BucketList bucketList = new BucketList(new ID(buffer));

    3200.ForEach(() =&gt;
    {
      rnd.NextBytes(buffer);
      bucketList.AddContact(new Contact(null, new ID(buffer)));
    });

    int contacts = bucketList.Buckets.Sum(b =&gt; b.Contacts.Count);
    contactsAdded.Add(contacts);
  });

  Assert.IsTrue(contactsAdded.Average().ApproximatelyEquals(720, 20), &quot;Unexpected distribution.&quot;);
  Assert.IsTrue(contactsAdded.Select(n=&gt;(double)n).StdDev().ApproximatelyEquals(10, 2), &quot;Bad distribution&quot;);
}</pre>
<p><img border="0" src="note.png" width="24" height="32"> Things to note:</p>
<ol>
	<li>The ID is determined by a random value of 0-255 for each byte in the 20 
	byte ID space.&nbsp; This biases the buckets that an ID can go into because 
	a linear random ID results in very unbalanced bucket trees.&nbsp; More on 
	this later.</li>
<li>Of the 3200 contacts attempted to be added, on average we only 
succeed at adding around 720 contacts.</li>
	<li>If we increase <i>b </i>we can affect this number.&nbsp; For example, 
	increasing b to 6 (from 5) doubles the number of contacts that are added.</li>
</ol>
<h4>The Question of Randomness</h4>
<p>As noted above, the ID was determined by a random value of 0-255 for each 
byte in the 20 bytes ID space.&nbsp; What happens instead if we randomize the ID 
based instead on its prefix?&nbsp; Meaning that the distribution of ID's, based 
on their prefix, is randomly distributed?&nbsp; Some helper methods:</p>
<pre>protected ID RandomizeBeyond(int bit)
{
  byte[] randomized = Bytes;

  ID newid = new ID(randomized);

  // TODO: Optimize
  for (int i = bit + 1; i &lt; Constants.ID_LENGTH_BITS; i++)
  {
    newid.ClearBit(i);
  }

  // TODO: Optimize
  for (int i = 0; i &lt; bit; i++)
  {
    if (rnd.NextDouble() &lt; 0.5)
    {
      newid.SetBit(i);
    }
  }

  return newid;
}

/// &lt;summary&gt;
/// Clears the bit n, from the LSB.
/// &lt;/summary&gt;
public void ClearBit(int n)
{
  byte[] bytes = Bytes;
  bytes[n / 8] &amp;= (byte)((1 &lt;&lt; (n % 8)) ^ 0xFF);
  id = new BigInteger(bytes.Append0());
}

/// &lt;summary&gt;
/// Sets the bit n, from the LSB.
/// &lt;/summary&gt;
public void SetBit(int n)
{
  byte[] bytes = Bytes;
  bytes[n / 8] |= (byte)(1 &lt;&lt; (n % 8));
  id = new BigInteger(bytes.Append0());
}</pre>
<p>Also, a random ID generator:</p>
<pre>/// &lt;summary&gt;
/// Produce a random ID distributed evenly across the 160 bit space.
/// &lt;/summary&gt;
public static ID RandomID
{
  get
  {
    byte[] data = new byte[Constants.ID_LENGTH_BYTES];
    ID id = new ID(data);
    // Uniform random bucket index.
    int idx = rnd.Next(Constants.ID_LENGTH_BITS);
    // 0 &lt;= idx &lt;= 159
    // Remaining bits are randomized to get unique ID.
    id.SetBit(idx);
    id = id.RandomizeBeyond(idx);

    return id;
  }
}</pre>
<p><img border="0" src="unittest.png" width="14" height="32"> This affects the bucket splitting algorithm.&nbsp; Notice with this unit 
test:</p>
<pre>[TestMethod]
public void RandomPrefixDistributionTest()
{
  List&lt;int&gt; contactsAdded = new List&lt;int&gt;();

  100.ForEach(() =&gt;
  {
    BucketList bucketList = new BucketList(ID.RandomID);
    3200.ForEach(() =&gt; bucketList.AddContact(new Contact(null, ID.RandomID)));
    int contacts = bucketList.Buckets.Sum(b =&gt; b.Contacts.Count);
    contactsAdded.Add(contacts);
  });

  Assert.IsTrue(contactsAdded.Average().ApproximatelyEquals(1900, 200), &quot;Unexpected distribution.&quot;);
  Assert.IsTrue(contactsAdded.Select(n =&gt; (double)n).StdDev().ApproximatelyEquals(750, 50), &quot;Bad distribution&quot;);
}</pre>
<p>Notice how 
large the standard deviation is -- there is something go on here, which we'll 
explore next.</p>
<h3>How a Contact ID Affects Distribution</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> Let's look at what happens when we assign a node ID as one of 2<sup>i</sup> 
where 0 &lt;= i &lt; 160 and add 3200 integer random contact ID's.&nbsp; Here's the unit test, which outputs the count of 
contacts added to each node ID in the set of <i>i</i>:</p>
<pre>[TestMethod]
public void DistributionTestForEachPrefix()
{
  Random rnd = new Random();
  StringBuilder sb = new StringBuilder();
  byte[] buffer = new byte[20];

  160.ForEach((i) =&gt;
  {
    BucketList bucketList = new BucketList(new ID(BigInteger.Pow(new BigInteger(2), i)));
    rnd.NextBytes(buffer);

    3200.ForEach(() =&gt;
    {
      rnd.NextBytes(buffer);
      bucketList.AddContact(new Contact(null, new ID(buffer)));
    });

    int contacts = bucketList.Buckets.Sum(b =&gt; b.Contacts.Count);
    sb.Append(i + &quot;,&quot; + contacts + CRLF);
  });

  File.WriteAllText(&quot;prefixTest.txt&quot;, sb.ToString());
}</pre>
<p align="center"><img border="0" src="dist3.png" width="482" height="289"></p>
<p>That looks fairly reasonable.&nbsp; </p>
<p><img border="0" src="unittest.png" width="14" height="32"> Compare the above with the distribution of contact counts when the contact ID 
is selected from a random prefix with randomized bits after the prefix as 
opposed to a random integer ID:</p>
<pre>[TestMethod]
public void DistributionTestForEachPrefixWithRandomPrefixDistributedContacts()
{
  StringBuilder sb = new StringBuilder();

  160.ForEach((i) =&gt;
  {
    BucketList bucketList = new BucketList(new ID(BigInteger.Pow(new BigInteger(2), i)));
    3200.ForEach(() =&gt; bucketList.AddContact(new Contact(null, ID.RandomID)));
    int contacts = bucketList.Buckets.Sum(b =&gt; b.Contacts.Count);
    sb.Append(i + &quot;,&quot; + contacts + CRLF);
  });

  File.WriteAllText(&quot;prefixTest.txt&quot;, sb.ToString());
}</pre>
<p align="center"><img border="0" src="dist2.png" width="487" height="296"></p>
<p align="left">If there was a question as to whether to choose a node ID based 
on an even distribution in the prefix space vs. simply a random integer ID, I 
think this clearly demonstrates that a random integer ID is the best choice.&nbsp; 
If we want to support more than an average of ~700 contacts in our peer, we can 
always increase <i>b</i>. </p>
<h2 align="left">Node Lookup - Discussion</h2>
<p align="left"><font color="#FF00FF">The most important procedure a Kademlia 
participant must perform is to locate the k closest nodes to some given node ID. 
We call this procedure a node lookup. Kademlia employs a recursive algorithm for 
node lookups. The lookup initiator starts by picking <i>a</i> nodes from its closest 
non-empty k-bucket (or, if that bucket has fewer than <i>a</i> entries, it just takes 
the <i>a</i> closest nodes it knows of). The initiator then sends parallel, 
asynchronous FIND_NODE RPCS to the <i>a</i> nodes it has chosen, <i>a</i> is a system-wide 
concurrency parameter, such as 3.</font></p>
<p>and:</p>
<p><font color="#FF00FF">In the recursive step, the initiator resends the 
FIND_NODE to nodes it has learned about from previous RPCs. (This recursion can 
begin before all <i>a</i> of the previous RPCs have returned). Of the <i>k</i> nodes the 
initiator has heard of closest to the target, it picks <i>a</i> that it has not yet 
queried and resends the FIND_NODE RPC to them. Nodes that fail to respond 
quickly are removed from consideration until and unless they do respond. If a 
round of FIND_NODES fails to return a node any closer than the closest already 
seen, the initiator resends the FIND_NODE to all of the <i>k</i> closest nodes it has 
not already queried. The lookup terminates when the initiator has queried and 
gotten responses from the k closest nodes it has seen. When a = 1, the lookup 
algorithm resembles Chord’s in terms of message cost and the latency of 
detecting failed nodes. However, Kademlia can route for lower latency because it 
has the flexibility of choosing any one of k nodes to forward a request to.</font></p>
<p>The idea here is to:</p>
<ol>
	<li>Try really hard to return k close nodes.</li>
	<li>Contact other peers in parallel to minimize latency.</li>
</ol>
<p align="center"><img border="0" src="lookup1.png" width="784" height="983"></p>
<p>Got it?</p>
<h3>Terminology</h3>
<ul>
	<li>The lookup initiator - this is your own peer wanting to make a store or 
retrieve call to other peers.&nbsp; The node lookup is performed before you 
	store or retrieve a value so that your peer has a reasonable.</li>
</ul>
<h3>Ambiguity #3</h3>
<p>Given &quot;<font color="#FF00FF">To 
store a (key,value) pair, a participant locates the k closest nodes to the key 
and sends them STORE RPCS.</font>&quot; here the term &quot;locates&quot; actually means 
performing the lookup.&nbsp; Contrast with &quot;<font color="#FF00FF">To find a (key,value) 
pair, a node starts by performing a lookup to find the k nodes with IDs closest 
to the key.</font>&quot; in which the term &quot;lookup&quot; is specifically used.</p>
<p>We can see this implemented in the Python code:</p>
<pre>async def get(self, key):
  &quot;&quot;&quot;
  Get a key if the network has it.
  Returns:
  :class:`None` if not found, the value otherwise.
  &quot;&quot;&quot;
  dkey = digest(key)
  # if this node has it, return it
  if self.storage.get(dkey) is not None:
    return self.storage.get(dkey)
    node = Node(dkey)
<b>    nearest = self.protocol.router.findNeighbors(node)</b>
    ...</pre>
<p>and:</p>
<pre>async def set(self, key, value):
  &quot;&quot;&quot;
  Set the given string key to the given value in the network.
  &quot;&quot;&quot;
  self.log.debug(&quot;setting '%s' = '%s' on network&quot; % (key, value))
  dkey = digest(key)
  return await self.set_digest(dkey, value)

async def set_digest(self, dkey, value):
  &quot;&quot;&quot;
  Set the given SHA1 digest key (bytes) to the given value in the network.
  &quot;&quot;&quot;
  node = Node(dkey)

  nearest = self.protocol.router.findNeighbors(node)
  ...</pre>
<p>where <code>findNeighbors</code> is the lookup algorithm described in the specification.</p>
<h3>Ambiguity #4</h3>
<p>What does &quot;<font color="#FF00FF">Nodes that fail to respond quickly&quot; </font>
mean?&nbsp; Particularly, the term &quot;quickly?&quot;</p>
<h3>Ambiguity #5</h3>
<p>What if the peer you yourself don't have peers in any k-buckets?&nbsp; That 
shouldn't happen (you should at least have the peer you are contacting) but if 
that peer only has you in its k-buckets, then there's nothing to return.</p>
<h3>Ambiguity #6</h3>
<p>In &quot;<font color="#FF00FF"> from its closest non-empty k-bucket&quot;</font>, what 
does &quot;closest&quot; mean?&nbsp; I am assuming here that it is the XOR distance 
metric, but then the question is, what do we use as the &quot;key&quot; for a bucket with 
a range of contacts?&nbsp; Since this is not defined, the implementation will 
search all the contacts across all buckets for the initial set of contacts that 
are closer.&nbsp; Also, the XOR distance computation means that we can't just 
ping-pong in an outer search from the bucket containing the range in which the 
key resides.&nbsp; This more matches the other condition &quot;<font color="#FF00FF">or, 
if that bucket has fewer than <i>a</i> entries, it just takes 
the <i>a</i> closest nodes it knows of</font>&quot; which implies searching for all 
<i>a</i> closest nodes across all buckets.</p>
<h3>Ambiguity #7</h3>
<p>In &quot;<font color="#FF00FF">The lookup initiator starts by picking <i>a</i> 
nodes</font>&quot; what does &quot;picking&quot; mean?&nbsp; Does this mean additionally 
sorting the contacts in the &quot;closest bucket&quot; also by closeness?&nbsp; It's 
completely undefined.</p>
<p>If you want to try the &quot;closest bucket&quot; version, enable the define 
<code>TRY_CLOSEST_BUCKET</code>, which is implemented like this:</p>
<pre>// Spec: The lookup initiator starts by picking a nodes from its closest non-empty k-bucket
KBucket bucket = FindClosestNonEmptyKBucket(key);

// Not in spec -- sort by the closest nodes in the closest bucket.
List&lt;Contact&gt; nodesToQuery = GetClosestNodes(key, bucket).Take(Constants.ALPHA).ToList();</pre>
<p>otherwise, the implementation simply gets the closest <i>a</i> contacts 
across all buckets:</p>
<pre>List&lt;Contact&gt; nodesToQuery = node.BucketList.GetCloseContacts(key, node.OurContact.ID).Take(Constants.ALPHA).ToList();</pre>
<p>However, this implementation, when testing with virtual nodes (where the 
system essentially knows every other node) effectively gets the k closest 
contacts, because it's searched all the buckets in virtual node space.&nbsp; So, 
if we want to exercise the algorithm, this is better:</p>
<pre>#if DEBUG
  List&lt;Contact&gt; allNodes = node.BucketList.GetKBucket(key).Contacts.Take(Constants.K).ToList();
#else
  // This is a bad way to get a list of close contacts with virtual nodes because we're always going to get the closest nodes right at the get go.
  List&lt;Contact&gt; allNodes = node.BucketList.GetCloseContacts(key, node.OurContact.ID).Take(Constants.K).ToList(); 
#endif

  List&lt;Contact&gt; nodesToQuery = allNodes.Take(Constants.ALPHA).ToList();</pre>
<p>This actually leads to the next ambiguity.</p>
<h3>Ambiguity #8</h3>
<p>In the initial acquisition of a contacts as per the code above, should 
contacts (I'm using &quot;contact&quot; and &quot;node&quot; rather interchangeably) that are closer 
at this point be added to the list of closer contacts?&nbsp; The spec doesn't 
say not to, but it doesn't explicitly say one should do this.&nbsp; Given that 
we pick only <i>a</i> contacts to start with, we definitely don't have the k 
contacts that the lookup is expected to return, so I'm implementing this as 
described above -- the <i>a</i> closest contacts we have are added to the 
&quot;closer&quot; list, and the <i>a</i> farther contacts we have are added to the 
&quot;farther&quot; list.</p>
<pre>List&lt;Contact&gt; nodesToQuery = allNodes.Take(Constants.ALPHA).ToList();

// Also not explicitly in spec:
// Any closer node in the alpha list is immediately added to our closer contact list, and
// any farther node in the alpha list is immediately added to our farther contact list.
closerContacts.AddRange(nodesToQuery.Where(n =&gt; (n.ID.Value ^ key.Value) &lt; (node.OurContact.ID.Value ^ key.Value)));
fartherContacts.AddRange(nodesToQuery.Where(n =&gt; (n.ID.Value ^ key.Value) &gt;= (node.OurContact.ID.Value ^ key.Value)));</pre>
<h3>Ambiguity #9</h3>
<p>What do we do with the contacts outside of <i>a</i>?&nbsp; Given this: &quot;<font color="#FF00FF">If 
a round of FIND_NODES fails to return a node any closer than the closest already 
seen, the initiator resends the FIND_NODE to all of the <i>k</i> closest nodes 
it has not already queried.&quot; </font>does it apply to the first query of <i>a</i> 
nodes, or only to the set of nodes returned after the query?&nbsp; I'm going to 
assume that it applies to the remainder of the <i>a</i> nodes not queried in the 
first query, which will be a maximum of <i>k</i>-<i>a</i> contacts.</p>
<h3>Ambiguity #10</h3>
<p>The spec says this: &quot;<font color="#FF00FF">Most operations are implemented in 
terms of the above lookup procedure.</font>&quot;&nbsp; What operations, and when?&nbsp; 
We'll have to address this later.</p>
<h3>The Concept of Closeness</h3>
<p><font color="#FF00FF">Many of Kademlia’s benefits result from its use of a 
novel XOR metric for distance between points in the key space. XOR is symmetric, 
allowing Kademlia participants to receive lookup queries from precisely the same 
distribution of nodes contained in their routing tables.</font></p>
<p>Therefore, the distance between a node and a key is the node ID XOR'd with 
the key.&nbsp; Unfortunately, an XOR distance metric is not amenable to a 
pre-sorted list of ID's.&nbsp; The resulting &quot;distance&quot; computation can be very 
different for two keys when XOR'd with the contact list.&nbsp; As described on 
Stack Overflow<sup>13 </sup>:</p>
<blockquote>
	<p>&quot;The thing is that buckets don't have to be full, and if you want to 
	send, let's say 20 nodes in a response a single bucket will not suffice.&nbsp; 
	So you have to traverse the routing table (either sorted based on your own 
	node ID or by the natural distance) in ascending distance (XOR) order 
	relative to the target key to visit multiple buckets.&nbsp; Since the XOR 
	distance metric folds at each bit-carry (XOR == carry-less addition) it does 
	not map nicely to any routing table layout. In other words, visiting the 
	nearest buckets won't do...I figure that many people simply iterate over the 
	whole routing table because for regular nodes it will only contain a few 
	dozen buckets at most and a DHT node does not see much traffic, so it only 
	has to execute this operation a few times per second and if you implement 
	this in a dense, cache-friendly datastructure then the lion's share might 
	actually be the memory traffic and not the CPU instructions doing a few XORs 
	and comparisons.<br>
	<br>
	I.e. a full-table-scan is just easy to implement.&quot;</p>
</blockquote>
<p>The author of that post provides an implementation<sup>14</sup> that doesn't 
require a full table scan, but in my implementation, we'll just do a full scan 
of the bucket list contacts.</p>
<h2>Node Lookup - Implementation</h2>
<p>Let's start with a baseline implementation that for the moment:</p>
<ol>
	<li>Doesn't deal with the issue of parallelism.</li>
<li>Doesn't deal with querying only <i>a</i> nodes - we set it that constant to
<i>k</i> for the moment.</li>
	<li>At the moment, we're also ignoring the fact that this algorithm is the 
	same for node lookup as it is for value lookup.</li>
</ol>
<p>This simplifies the implementation so that we can provide some unit tests for 
the basic algorithm, then add the parallelism and <i>a</i> concept later, and 
our unit tests should still pass.</p>
<p>Also, the methods here are all marked as <code>virtual</code> in case you want to override 
the implementation.&nbsp; First, some helper methods:</p>
<h3>FindClosestNonEmptyKBucket</h3>
<pre>/// &lt;summary&gt;
/// Using the k-bucket's key (it's high value), find the closest 
/// k-bucket the given key that isn't empty.
/// &lt;/summary&gt;
#if DEBUG // For unit testing.
  public virtual KBucket FindClosestNonEmptyKBucket(ID key)
#else
  protected virtual KBucket FindClosestNonEmptyKBucket(ID key)
#endif
{
  KBucket closest = Node.BucketList.Buckets.Where(b =&gt; b.Contacts.Count &gt; 0).OrderBy(b =&gt; b.Key ^ key.Value).FirstOrDefault();
  Validate.IsTrue&lt;NoNonEmptyBucketsException&gt;(closest != null, &quot;No non-empty buckets exist. You must first register a peer and add that peer to your bucketlist.&quot;);

  return closest;
}
</pre>
<h3>GetClosestNodes</h3>
<pre>/// &lt;summary&gt;
/// Get sorted list of closest nodes to the given key.
/// &lt;/summary&gt;
#if DEBUG // For unit testing.
  public List&lt;Contact&gt; GetClosestNodes(ID key, KBucket bucket)
#else
  protected List&lt;Contact&gt; GetClosestNodes(ID key, KBucket bucket)
#endif
{
  return bucket.Contacts.OrderBy(c =&gt; c.ID.Value ^ key.Value).ToList();
}</pre>
<h3>RpcFindNodes</h3>
<pre>/// &lt;summary&gt;
/// For each contact, call the FindNodes and return all the nodes whose contacts responded
/// within a &quot;reasonable&quot; period of time.
/// &lt;/summary&gt;
protected List&lt;Contact&gt; RpcFindNodes(ID key, List&lt;Contact&gt; contacts)
{
  List&lt;Contact&gt; nodes = new List&lt;Contact&gt;();
  contacts.ForEach(c =&gt; nodes.AddRange(c.Protocol.FindNode(key)));

  return nodes;
}</pre>
<h3>GetCloserNodes</h3>
<p><img border="0" src="note.png" width="24" height="32"> Note that we always 
exclude our own node and the nodes we're contacting.</p>
<pre>/// &lt;summary&gt;
/// Get closer nodes to the current uncontacted nodes and update the list of closer and farther nodes.
/// &lt;/summary&gt;
#if DEBUG // For unit testing.
public void GetCloserNodes(ID key, List&lt;Contact&gt; nodesToQuery, List&lt;Contact&gt; closerContacts, List&lt;Contact&gt; fartherContacts)
#else
protected void GetCloserNodes(ID key, List&lt;Contact&gt; nodesToQuery, List&lt;Contact&gt; closerContacts, List&lt;Contact&gt; fartherContacts)
#endif
{
  // As in, peer's nodes:
  // Exclude ourselves and the peers we're contacting to a get unique list of new peers.
  // Compare by ID's as Contact is different instance except with a virtual network.
  List&lt;Contact&gt; peersNodes = RpcFindNodes(key, nodesToQuery).ExceptBy(node.OurContact, c =&gt; c.ID.Value).ExceptBy(nodesToQuery, c =&gt; c.ID.Value).ToList();
  var nearestNodeDistance = nodesToQuery.OrderBy(n =&gt; n.ID.Value ^ key.Value).First().ID.Value;

  closerContacts.
    AddRangeDistinctBy(peersNodes.
      Where(p =&gt; (p.ID.Value ^ key.Value) &lt; nearestNodeDistance),
      (a, b) =&gt; a.ID.Value == b.ID.Value);

  fartherContacts.
    AddRangeDistinctBy(peersNodes.
      Where(p =&gt; (p.ID.Value ^ key.Value) &gt;= nearestNodeDistance),
      (a, b) =&gt; a.ID.Value == b.ID.Value);
}</pre>
<h3>Lookup</h3>
<p>This flowchart all comes together here:</p>
<pre>public virtual List&lt;Contact&gt; Lookup(ID key, bool giveMeAll = false)
{
  bool haveWork = true;
  List&lt;Contact&gt; ret = new List&lt;Contact&gt;();
  List&lt;Contact&gt; contactedNodes = new List&lt;Contact&gt;();
  List&lt;Contact&gt; closerContacts = new List&lt;Contact&gt;();
  List&lt;Contact&gt; fartherContacts = new List&lt;Contact&gt;();

#if TRY_CLOSEST_BUCKET
  // Spec: The lookup initiator starts by picking a nodes from its closest non-empty k-bucket
KBucket bucket = FindClosestNonEmptyKBucket(key);

  // Not in spec -- sort by the closest nodes in the closest bucket.
  List&lt;Contact&gt; allNodes = node.BucketList.GetCloseContacts(key, node.OurContact.ID).Take(Constants.K).ToList(); 
  List&lt;Contact&gt; nodesToQuery = allNodes.Take(Constants.ALPHA).ToList();
  fartherContacts.AddRange(allNodes.Skip(Constants.ALPHA).Take(Constants.K - Constants.ALPHA));
#else
#if DEBUG
  List&lt;Contact&gt; allNodes = node.BucketList.GetKBucket(key).Contacts.Take(Constants.K).ToList();
#else
  // This is a bad way to get a list of close contacts with virtual nodes because we're always going to get the closest nodes right at the get go.
  List&lt;Contact&gt; allNodes = node.BucketList.GetCloseContacts(key, node.OurContact.ID).Take(Constants.K).ToList(); 
#endif
  List&lt;Contact&gt; nodesToQuery = allNodes.Take(Constants.ALPHA).ToList();

  // Also not explicitly in spec:
  // Any closer node in the alpha list is immediately added to our closer contact list, and
  // any farther node in the alpha list is immediately added to our farther contact list.
  closerContacts.AddRange(nodesToQuery.Where(n =&gt; (n.ID.Value ^ key.Value) &lt; (node.OurContact.ID.Value ^ key.Value)));
  fartherContacts.AddRange(nodesToQuery.Where(n =&gt; (n.ID.Value ^ key.Value) &gt;= (node.OurContact.ID.Value ^ key.Value)));

  // The remaining contacts not tested yet can be put here.
  fartherContacts.AddRange(allNodes.Skip(Constants.ALPHA).Take(Constants.K - Constants.ALPHA));
#endif

  // We're about to contact these nodes.
  contactedNodes.AddRangeDistinctBy(nodesToQuery, (a, b) =&gt; a.ID.Value == b.ID.Value);

  // Spec: The initiator then sends parallel, asynchronous FIND_NODE RPCS to the a nodes it has chosen, a is a system-wide concurrency parameter, such as 3.
  GetCloserNodes(key, nodesToQuery, closerContacts, fartherContacts);

  // Add any new closer contacts to the list we're going to return.
  ret.AddRangeDistinctBy(closerContacts, (a, b) =&gt; a.ID.Value == b.ID.Value);

  // Spec: The lookup terminates when the initiator has queried and gotten responses from the k closest nodes it has seen.
  while (ret.Count &lt; Constants.K &amp;&amp; haveWork)
  {
    List&lt;Contact&gt; closerUncontactedNodes = closerContacts.Except(contactedNodes).ToList();
    List&lt;Contact&gt; fartherUncontactedNodes = fartherContacts.Except(contactedNodes).ToList();
    bool haveCloser = closerUncontactedNodes.Count &gt; 0;
    bool haveFarther = fartherUncontactedNodes.Count &gt; 0;

    haveWork = haveCloser || haveFarther;

    // Spec: Of the k nodes the initiator has heard of closest to the target...
    if (haveCloser)
    {
      // We're about to contact these nodes.
      contactedNodes.AddRangeDistinctBy(closerUncontactedNodes, (a, b) =&gt; a.ID.Value == b.ID.Value);

      // Spec: ...it picks a that it has not yet queried and resends the FIND_NODE RPC to them. 
      GetCloserNodes(key, closerUncontactedNodes.Take(Constants.ALPHA).ToList(), closerContacts, fartherContacts);
    }
    else if (haveFarther)
    {
      // We're about to contact these nodes.
      contactedNodes.AddRangeDistinctBy(fartherUncontactedNodes, (a, b) =&gt; a.ID.Value == b.ID.Value);
      GetCloserNodes(key, fartherUncontactedNodes, closerContacts, fartherContacts);
    }
  }

#if DEBUG // For unit testing.
  CloserContacts = closerContacts;
  FartherContacts = fartherContacts;
#endif

  // Spec (sort of): Return max(k) closer nodes, sorted by distance.
  // For unit testing, giveMeAll can be true so that we can match against our alternate way of getting closer contacts.
  return giveMeAll ? ret : ret.Take(Constants.K).OrderBy(c=&gt;c.ID.Value ^ key.Value).ToList();
}</pre>
<p><img border="0" src="note.png" width="24" height="32"> This algorithm is 
iteration, not recursion, as the specification states.&nbsp; Every 
implementation I've seen uses iteration.</p>
<h3>Extension Methods</h3>
<p>A few extension methods that are used:</p>
<h4>AddRangeDistinctBy</h4>
<pre>public static void AddRangeDistinctBy&lt;T&gt;(this List&lt;T&gt; target, IEnumerable&lt;T&gt; src, Func&lt;T, T, bool&gt; equalityComparer)
{
  src.ForEach(item =&gt;
  {
    // no items in the list must match the item.
    if (target.None(q =&gt; equalityComparer(q, item)))
    {
      target.Add(item);
    }
  });
}</pre>
<h4>ExceptBy</h4>
<pre>public static IEnumerable&lt;T&gt; ExceptBy&lt;T, TKey&gt;(this IEnumerable&lt;T&gt; src, T item, Func&lt;T, TKey&gt; keySelector)
{
  TKey itemKey = keySelector(item);

  using (var enumerator = src.GetEnumerator())
  {
    while (enumerator.MoveNext())
    {
      T current = enumerator.Current;

      if (!keySelector(current).Equals(itemKey))
      {
        yield return current;
      }
    }
  }
}

public static IEnumerable&lt;T&gt; ExceptBy&lt;T, TKey&gt;(this IEnumerable&lt;T&gt; src, IEnumerable&lt;T&gt; items, Func&lt;T, TKey&gt; keySelector)
{
  using (var enumerator = src.GetEnumerator())
  {
    while (enumerator.MoveNext())
    {
      T current = enumerator.Current;

      if (items.None(i =&gt; keySelector(current).Equals(keySelector(i))))
      {
        yield return current;
      }
    }
  }
}</pre>
<h2>Node Lookup - Unit Tests</h2>
<p>Before Getting Into Unit Tests we need to be able to create virtual nodes, which means implementing a 
minimal virtual protocol:</p>
<h3>Virtual Node/Protocol</h3>
<pre>public class VirtualProtocol : IProtocol
{
  public Node Node { get { return node; } set { node = value; } }

  protected Node node;

  /// &lt;summary&gt;
  /// For unit testing with deferred node setup.
  /// &lt;/summary&gt;
  public VirtualProtocol()
  {
  }

  /// &lt;summary&gt;
  /// Register the in-memory node with our virtual protocol.
  /// &lt;/summary&gt;
  public VirtualProtocol(Node node)
  {
    this.node = node;
  }

  /// &lt;summary&gt;
  /// Get the list of contacts for this node closest to the key.
  /// &lt;/summary&gt;
  public List&lt;Contact&gt; FindNode(Contact sender, ID key)
  {
    return node.FindNode(sender, key).contacts;
  }
}</pre>
<h3>Missing Implementation Needs to be Added Now</h3>
<p>We also have to implement FindNode in the Node class:</p>
<pre>/// &lt;summary&gt;
/// From the spec: FindNode takes a 160-bit ID as an argument. The recipient of the RPC returns (IP address, UDP port, Node ID) triples 
/// for the k nodes it knows about closest to the target ID. These triples can come from a single k-bucket, or they may come from 
/// multiple k-buckets if the closest k-bucket is not full. In any case, the RPC recipient must return k items (unless there are 
/// fewer than k nodes in all its k-buckets combined, in which case it returns every node it knows about).
/// &lt;/summary&gt;
/// &lt;returns&gt;&lt;/returns&gt;
public (List&lt;Contact&gt; contacts, string val) FindNode(Contact sender, ID toFind)
{
  Validate.IsFalse&lt;SendingQueryToSelfException&gt;(sender.ID.Value == ourContact.ID.Value, &quot;Sender should not be ourself!&quot;);
  bucketList.AddContact(sender);
  // Exclude sender.
  var contacts = bucketList.GetCloseContacts(toFind, sender.ID);

  return (contacts, null);
}</pre>
<p>Note how this also registers the sender as a contact, which either adds 
(maybe) the contact to the recipient's bucket list or updates the contact 
information.&nbsp; Ignore the tuple return for now.</p>
<p>And we need an algorithm for finding close contacts across the recipient's 
bucket range:</p>
<pre>/// &lt;summary&gt;
/// Brute force distance lookup of all known contacts, sorted by distance, then we take at most k (20) of the closest.
/// &lt;/summary&gt;
/// &lt;param name=&quot;toFind&quot;&gt;The ID for which we want to find close contacts.&lt;/param&gt;
/// &lt;param name=&quot;exclude&quot;&gt;The ID to exclude (the requestor's ID)&lt;/param&gt;
public List&lt;Contact&gt; GetCloseContacts(ID toFind, ID exclude)
{
  var contacts = buckets.
    SelectMany(b =&gt; b.Contacts).
    Where(c =&gt; c.ID.Value != exclude.Value).
    Select(c =&gt; new { contact = c, distance = c.ID.Value ^ toFind.Value }).
    OrderBy(d =&gt; d.distance).
    Take(Constants.K);

  // Spec (sort of): Return max(k) closer nodes, sorted by distance.
  return ret.Take(Constants.K).OrderBy(c=&gt;c.ID.Value ^ key.Value).ToList();
}</pre>
<h3>GetCloseContacts Test</h3>
<p>This tests the 
sorting and the maximum number of contacts returned limit.&nbsp; Note that it's 
probably not the most ideal situation that I'm using all random ID's, however, 
to ensure consistent unit testing, we seed the random number generator with the 
same value in DEBUG mode:</p>
<pre>#if DEBUG
private static Random rnd = new Random(1);
#else
private static Random rnd = new Random();
#endif</pre>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; Our test method:</p>
<pre>[TestMethod]
public void GetCloseContactsOrderedTest()
{
  Contact sender = new Contact(null, ID.RandomID);
  Node node = new Node(new Contact(null, ID.RandomID), null);
  List&lt;Contact&gt; contacts = new List&lt;Contact&gt;();
  // Force multiple buckets.
  100.ForEach(() =&gt; contacts.Add(new Contact(null, ID.RandomID)));
  contacts.ForEach(c =&gt; node.BucketList.AddContact(c));
  ID key = ID.RandomID; // Pick an ID
  List&lt;Contact&gt; closest = node.FindNode(sender, key).contacts;

  Assert.IsTrue(closest.Count == Constants.K, &quot;Expected K contacts to be returned.&quot;);

  // The contacts should be in ascending order with respect to the key.
  var distances = closest.Select(c =&gt; c.ID.Value ^ key.Value).ToList();
  var distance = distances[0];

  // Verify distances are in ascending order:
  distances.Skip(1).ForEach(d =&gt;
  {
    Assert.IsTrue(distance &lt; d, &quot;Expected contacts ordered by distance.&quot;);
    distance = d;
  });


  // Verify the contacts with the smallest distances were returned from all possible distances.
  var lastDistance = distances[distances.Count - 1];
  var others = node.BucketList.Buckets.SelectMany(b =&gt; b.Contacts.Except(closest)).Where(c =&gt; (c.ID.Value ^ key.Value) &lt; lastDistance);
  Assert.IsTrue(others.Count() == 0, &quot;Expected no other contacts with a smaller distance than the greatest distance to exist.&quot;);
}</pre>
<h3>NoNodesToQuery Test</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> This test simply 
verifies that we get no new nodes to query given that all the nodes we're 
contacting are already being contacted.</p>
<pre> /// &lt;summary&gt;
/// Given that all the nodes we're contacting are nodes *being* contacted, 
/// the result should be no new nodes to contact.
/// &lt;/summary&gt;
[TestMethod]
public void NoNodesToQueryTest()
{
  // Setup
  router = new Router(new Node(new Contact(null, ID.Mid), null));

  nodes = new List&lt;Node&gt;();
  20.ForEach((n) =&gt; nodes.Add(new Node(new Contact(null, new ID(BigInteger.Pow(new BigInteger(2), n))), null)));

  // Fixup protocols:
  nodes.ForEach(n =&gt; n.OurContact.Protocol = new VirtualProtocol(n));

  // Our contacts:
  nodes.ForEach(n =&gt; router.Node.BucketList.AddContact(n.OurContact));

  // Each peer needs to know about the other peers except of course itself.
  nodes.ForEach(n =&gt; nodes.Where(nOther =&gt; nOther != n).ForEach(nOther =&gt; n.BucketList.AddContact(nOther.OurContact)));

  // Select the key such that n ^ 0 == n
  // This ensures that the distance metric uses only the node ID, which makes for an integer difference for distance, not an XOR distance.
  key = ID.Zero; 
  contactsToQuery = router.Node.BucketList.Buckets[0].Contacts; // all contacts are in one bucket.

  closerContacts = new List&lt;Contact&gt;();
  fartherContacts = new List&lt;Contact&gt;();
  router.GetCloserNodes(key, contactsToQuery, closerContacts, fartherContacts);

  Assert.IsTrue(closerContacts.Count == 0, &quot;No new nodes expected.&quot;);
  Assert.IsTrue(fartherContacts.Count == 0, &quot;No new nodes expected.&quot;);
}</pre>
<h3>GetCloserNodes Test</h3>
<p>Getting the system to exercise the different paths in the flowchart is an 
interesting exercise.&nbsp; Again, note that it's probably not the most ideal 
situation that I'm using all random ID's.&nbsp; Let's start with one of the first more complicated 
helper methods, <code>GetCloserNodes</code>.&nbsp; </p>
<p><img border="0" src="unittest.png" width="14" height="32">&nbsp; The unit test itself is a beast:</p>
<pre>[TestMethod]
public void GetCloserNodesTest()
{
  // Seed with different random values
  100.ForEach(seed =&gt;
  {
    ID.rnd = new Random(seed);
    // Setup
    Router router = new Router(new Node(new Contact(null, ID.RandomID), null));

    List&lt;Node&gt; nodes = new List&lt;Node&gt;();
    100.ForEach(() =&gt; nodes.Add(new Node(new Contact(null, ID.RandomID), null)));

    // Fixup protocols:
    nodes.ForEach(n =&gt; n.OurContact.Protocol = new VirtualProtocol(n));

    // Our contacts:
    nodes.ForEach(n =&gt; router.Node.BucketList.AddContact(n.OurContact));

    // Each peer needs to know about the other peers except of course itself.
    nodes.ForEach(n =&gt; nodes.Where(nOther =&gt; nOther != n).ForEach(nOther =&gt; n.BucketList.AddContact(nOther.OurContact)));

    ID key = ID.RandomID; // Pick an ID
    // TODO: Pick a random bucket, or bucket where the key is in range, otherwise we're defeating the purpose of the algorithm.
    // DO NOT DO THIS:
    // List&lt;Contact&gt; nodesToQuery = router.Node.BucketList.GetCloseContacts(key, router.Node.OurContact.ID).Take(Constants.ALPHA).ToList();

    List&lt;Contact&gt; nodesToQuery = router.Node.BucketList.GetKBucket(key).Contacts.Take(Constants.ALPHA).ToList();
    // or:
    // List&lt;Contact&gt; nodesToQuery = router.FindClosestNonEmptyKBucket(key).Contacts.Take(Constants.ALPHA).ToList();

    List&lt;Contact&gt; closerContacts = new List&lt;Contact&gt;();
    List&lt;Contact&gt; fartherContacts = new List&lt;Contact&gt;();

    List&lt;Contact&gt; closerContactsAltComputation = new List&lt;Contact&gt;();
    List&lt;Contact&gt; fartherContactsAltComputation = new List&lt;Contact&gt;();
    Contact theNearestContactedNode = nodesToQuery.OrderBy(n =&gt; n.ID.Value ^ key.Value).First();
    var distance = theNearestContactedNode.ID.Value;

    // Setup done.

    router.GetCloserNodes(key, nodesToQuery, closerContacts, fartherContacts);

    // Test whether the results are correct: 

    // For each node (ALPHA == K for testing) in our bucket (nodesToQuery) we're going to get k nodes closest to the key:
    foreach (Contact contact in nodesToQuery)
    {
      // Find the node we're contacting:
      Node contactNode = nodes.Single(n =&gt; n.OurContact == contact);

      // Close contacts except ourself and the nodes we're contacting.
      // Note that of all the contacts in the bucket list, many of the k returned
      // by the GetCloseContacts call are contacts we're querying, so they are being excluded.
      var closeContactsOfContactedNode =
        contactNode.
          BucketList.
          GetCloseContacts(key, router.Node.OurContact.ID).
          ExceptBy(nodesToQuery, c =&gt; c.ID.Value);

      foreach (Contact closeContactOfContactedNode in closeContactsOfContactedNode)
      {
        // Which of these contacts are closer?
        if ((closeContactOfContactedNode.ID.Value ^ key.Value) &lt; distance)
        {
          closerContactsAltComputation.AddDistinctBy(closeContactOfContactedNode, c =&gt; c.ID.Value);
        }

        // Which of these contacts are farther?
        if ((closeContactOfContactedNode.ID.Value ^ key.Value) &gt;= distance)
        {
          fartherContactsAltComputation.AddDistinctBy(closeContactOfContactedNode, c =&gt; c.ID.Value);
        }
      }
    }

    Assert.IsTrue(closerContacts.Count == closerContactsAltComputation.Count, &quot;Closer computations do not match.&quot;);
    Assert.IsTrue(fartherContacts.Count == fartherContactsAltComputation.Count, &quot;Farther computations do not match.&quot;);
  });
}</pre>
<p>The idea here is that with virtual nodes, we first get the results using the 
&quot;RPC&quot; calls and some hopefully readable Linq.&nbsp; Then, using a different 
algorithm with a lot less Linq, we then iterate over the contacts in the nodes 
we're querying, as set up by the unit test.&nbsp; This actually tests a lot of 
the system, and interestingly, as a result of these two different approaches, I found a bug in the <code>GetCloseContacts</code> 
-- so much for &quot;it's not practical testing all the simple methods.&quot;&nbsp; As a 
side note, it's interesting to see how much shorter the Linq for the code that 
obtains the close and far contacts.</p>
<h3>Lookup Unit Test</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> Ironically, there really is no alternative way of getting these nodes, 
particularly with regards to the <code>while</code> loop in the <code>Lookup</code> method.&nbsp; 
So without beating my head over the issue, I implemented this test:</p>
<pre>[TestMethod]
public void LookupTest()
{
  // Seed with different random values
  100.ForEach(seed =&gt;
  {
    ID.rnd = new Random(seed);
    Setup();

    List&lt;Contact&gt; closeContacts = router.Lookup(key, true);
    List&lt;Contact&gt; contactedNodes = new List&lt;Contact&gt;(closeContacts);

    // Is the above call returning the correct number of close contacts?
    // The unit test for this is sort of lame. We should get at least as many contacts 
    // as when calling GetCloserNodes. 

    GetAltCloseAndFar(contactsToQuery, closerContactsAltComputation, fartherContactsAltComputation);

    Assert.IsTrue(closeContacts.Count &gt;= closerContactsAltComputation.Count, &quot;Expected at least as many contacts.&quot;);

    // Technically, we can't even test whether the contacts returned in GetCloserNodes exists
    // in router.Lookup because it may have found nodes even closer, and it only returns K nodes!
    // We can overcome this by eliminating the Take in the return of router.Lookup().

    closerContactsAltComputation.ForEach(c =&gt; Assert.IsTrue(closeContacts.Contains(c)));
  });
}</pre>
<h3>Simple Closer Contacts Test</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> This test, and the 
next one, essentially exercises the part of the <code>Lookup</code> algorithm before the 
<code>while</code> loop.&nbsp;
<img border="0" src="note.png" width="24" height="32">Note how the bucket and ID's are set 
up.</p>
<pre> /// &lt;summary&gt;
/// Creates a single bucket with node ID's 2^i for i in [0, K) and
/// 1. use a key with ID.Value == 0 to that distance computation is an integer difference
/// 2. use an ID.Value == ID.Max for our node ID so all other nodes are closer.
/// &lt;/summary&gt;
[TestMethod]
public void SimpleAllCloserContacts()
{
  // Setup
  // By selecting our node ID to zero, we ensure that all distances of other nodes are &gt; the distance to our node.
  router = new Router(new Node(new Contact(null, ID.Max), null));

  nodes = new List&lt;Node&gt;();
  Constants.K.ForEach((n) =&gt; nodes.Add(new Node(new Contact(null, new ID(BigInteger.Pow(new BigInteger(2), n))), null)));

  // Fixup protocols:
  nodes.ForEach(n =&gt; n.OurContact.Protocol = new VirtualProtocol(n));

  // Our contacts:
  nodes.ForEach(n =&gt; router.Node.BucketList.AddContact(n.OurContact));

  // Each peer needs to know about the other peers except of course itself.
  nodes.ForEach(n =&gt; nodes.Where(nOther =&gt; nOther != n).ForEach(nOther =&gt; n.BucketList.AddContact(nOther.OurContact)));

  // Select the key such that n ^ 0 == n
  // This ensures that the distance metric uses only the node ID, which makes for an integer difference for distance, not an XOR distance.
  key = ID.Zero;
  contactsToQuery = router.Node.BucketList.Buckets[0].Contacts; // all contacts are in one bucket.

  var contacts = router.Lookup(key, true);

  Assert.IsTrue(contacts.Count == Constants.K, &quot;Expected k closer contacts.&quot;);
  Assert.IsTrue(router.CloserContacts.Count == Constants.K, &quot;All contacts should be closer.&quot;);
  Assert.IsTrue(router.FartherContacts.Count == 0, &quot;Did not expected farther contacts.&quot;);
}</pre>
<h3>Simple Farther Contacts Test</h3>
<p><img border="0" src="unittest.png" width="14" height="32">
<img border="0" src="note.png" width="24" height="32"> Again note how the bucket 
and ID's 
are set up:</p>
<pre> /// &lt;summary&gt;
/// Creates a single bucket with node ID's 2^i for i in [0, K) and
/// 1. use a key with ID.Value == 0 to that distance computation is an integer difference
/// 2. use an ID.Value == 0 for our node ID so all other nodes are farther.
/// &lt;/summary&gt;
[TestMethod]
public void SimpleAllFartherContacts()
{
  // Setup
  // By selecting our node ID to zero, we ensure that all distances of other nodes are &gt; the distance to our node.
  router = new Router(new Node(new Contact(null, ID.Zero), null));

  nodes = new List&lt;Node&gt;();
  Constants.K.ForEach((n) =&gt; nodes.Add(new Node(new Contact(null, new ID(BigInteger.Pow(new BigInteger(2), n))), null)));

  // Fixup protocols:
  nodes.ForEach(n =&gt; n.OurContact.Protocol = new VirtualProtocol(n));

  // Our contacts:
  nodes.ForEach(n =&gt; router.Node.BucketList.AddContact(n.OurContact));

  // Each peer needs to know about the other peers except of course itself.
  nodes.ForEach(n =&gt; nodes.Where(nOther =&gt; nOther != n).ForEach(nOther =&gt; n.BucketList.AddContact(nOther.OurContact)));

  // Select the key such that n ^ 0 == n
  // This ensures that the distance metric uses only the node ID, which makes for an integer difference for distance, not an XOR distance.
  key = ID.Zero;
  contactsToQuery = router.Node.BucketList.Buckets[0].Contacts; // all contacts are in one bucket.

  var contacts = router.Lookup(key, true);

  Assert.IsTrue(contacts.Count == 0, &quot;Expected no closer contacts.&quot;);
  Assert.IsTrue(router.CloserContacts.Count == 0, &quot;Did not expected closer contacts.&quot;);
  Assert.IsTrue(router.FartherContacts.Count == Constants.K, &quot;All contacts should be farther.&quot;);
}</pre>
<h2>Value Lookup - Discussion</h2>
<p>From the spec: <font color="#FF00FF">FIND_VALUE behaves like FIND_NODE - 
returning (IP address, UDP port, Node ID) triples - with one exception. If the 
RPC recipient has received a STORE RPC for the key, it just returns the stored 
value.</font></p>
<p>That seems clear enough, but we have to consider this part of the spec as 
well:</p>
<p><font color="#FF00FF">To find a (key,value) pair, a node starts by performing 
a lookup to find the k nodes with IDs closest to the key. However, value lookups 
use FIND_VALUE rather than FIND_NODE RPCS. Moreover, the procedure halts 
immediately when any node returns the value. For caching purposes, once a lookup 
succeeds, the requesting node stores the (key,value) pair at the closest node it 
observed to the key that did not return the value.</font></p>
<p>We now get to address ambiguity #10: The spec says this: &quot;<font color="#FF00FF">Most 
operations are implemented in terms of the above lookup procedure.</font>&quot;&nbsp; 
When we're performing a lookup, the initiator will be using the lookup call for 
both finding nodes and finding values.&nbsp; If it's finding values, it needs to 
stop if/when the value is found.&nbsp; </p>
<h3>Ambiguity #12</h3>
<p>&nbsp;This statement: <font color="#FF00FF">For caching purposes, once a 
lookup succeeds, the requesting node stores the (key,value) pair at the closest node it 
observed to the key that did not return the value.</font> can be ambiguous -- 
what does &quot;requesting node&quot; mean?&nbsp; Is it the requesting performing the 
lookup, or the node that made the GetValue request?&nbsp; It would seem to be 
the former, because &quot;it observed to the key that did not return the value&quot; would 
otherwise not make any sense.</p>
<h3>Refactorings</h3>
<p>We need to some refactoring to pass in 
the RPC call that we want to make, and how we handle a found value for the FindValue RPC call.</p>
<h4>Refactoring the Router.Lookup Method</h4>
<p>We have some major refactoring to do to how lookups are performed.&nbsp; The 
signature of the Lookup method changes so that:</p>
<ol>
	<li>We can pass in the particular RPC call to make.</li>
<li>We get back either a list of contacts (val will be null) or the found value 
(contacts will be null.)</li>
</ol>
<pre>public virtual (List&lt;Contact&gt; contacts, string val) Lookup(
  ID key, 
  Func&lt;ID, List&lt;Contact&gt;, (List&lt;Contact&gt; contacts, string val)&gt; rpcCall, 
  bool giveMeAll = false)
{
  ...</pre>
<p>We also need to pass the RPC call into <code>GetCloserNodes</code> (which meant 
refactoring the unit tests!) and test whether it found a value (which will only 
be true for when the RPC call is for finding values):</p>
<pre>if (GetCloserNodes(key, rpcCall, nodesToQuery, closerContacts, fartherContacts, out val, out foundBy))
{
  return (true, closerContacts, foundBy, val);
}</pre>
<p>This stops the lookup immediately when a value is found.&nbsp; There are 
other refactoring's in the router's <code>Lookup</code> method (for example the method 
signature) that I'm omitting.</p>
<h4>Refactoring the GetCloserNodes Method</h4>
<p>The signature changes:</p>
<pre>public bool GetCloserNodes(
  ID key, 
  Func&lt;ID, List&lt;Contact&gt;, (List&lt;Contact&gt; contacts, string val)&gt; rpcCall, 
  List&lt;Contact&gt; nodesToQuery, 
  List&lt;Contact&gt; closerContacts, 
  List&lt;Contact&gt; fartherContacts,
  out string val)</pre>
<p>Also the way we call the RPC changes, and of course, the method now has a 
return value:</p>
<pre>var (contacts, foundVal) = rpcCall(key, nodesToQuery);
val = foundVal;
List&lt;Contact&gt; peersNodes = contacts.ExceptBy(node.OurContact, c =&gt; c.ID.Value).ExceptBy(nodesToQuery, c =&gt; c.ID.Value).ToList();
...
return val != null;</pre>
<h4>Refactoring the RpcFindNodes Method</h4>
<p>A minor change here (also handling something we haven't talked about yet), in that we know we're finding only nodes, but we need a 
unified return with <code>RpcFindValue</code>.&nbsp; Notice the method is now 
public so that the Dht (discussed later) and our unit tests can specify the 
appropriate RPC call.</p>
<pre>public (List&lt;Contact&gt; contacts, Contact foundBy, string val) RpcFindNodes(ID key, List&lt;Contact&gt; contacts)
{
  List&lt;Contact&gt; nodes = new List&lt;Contact&gt;();
  contacts.ForEach(c =&gt; nodes.AddRange(c.Protocol.FindNode(node.OurContact, key)));

  return (nodes, null, null);
}
</pre>
<h3>Adding the RpcFindValue Method</h3>
<p>The <code>foundBy</code> tuple field will be illustrated later when we talk about the Dht 
class.</p>
<pre> /// &lt;summary&gt;
/// For each contact, call the FindNode and return all the nodes whose contacts responded
/// within a &quot;reasonable&quot; period of time, unless a value is returned, at which point we stop.
/// &lt;/summary&gt;
public (List&lt;Contact&gt; contacts, Contact foundBy, string val) RpcFindValue(ID key, List&lt;Contact&gt; contacts)
{
  List&lt;Contact&gt; nodes = new List&lt;Contact&gt;();
  string retval = null;
  Contact foundBy = null;

  foreach(Contact c in contacts)
  {
    (var otherContacts, var val) = c.Protocol.FindValue(node.OurContact, key);

    if (otherContacts != null)
    {
      nodes.AddRange(otherContacts);
    }
    else
    {
      Validate.IsTrue&lt;ValueCannotBeNullException&gt;(val != null, &quot;Null values are not supported nor expected.&quot;);
      nodes.Add(c); // The node we just contacted found the value.
      foundBy = c;
      retval = val;
      break;
    }
  }

  return (nodes, foundBy, retval);
}
</pre>
<p>After making these structural changes and refactoring the unit tests, they 
still pass (well, that should be expected, as these changes were really only 
structural.)&nbsp; </p>
<p><img border="0" src="note.png" width="24" height="32"> Discussing value 
lookup tests doesn't make sense outside of the context of the <code>Dht</code> wrapper, so 
the unit tests for the value lookup will be done in the <code>Dht</code> testing.</p>
<h2>Value Lookup - Implementation</h2>
<p>First, we need to implement a simple virtual (in memory) storage mechanism:</p>
<pre>public class VirtualStorage : IStorage
{
  protected Dictionary&lt;BigInteger, string&gt; store;

  public VirtualStorage()
  {
    store = new Dictionary&lt;BigInteger, string&gt;();
  }

  public bool Contains(ID key)
  {
    return store.ContainsKey(key.Value);
  }

  public string Get(ID key)
  {
    return store[key.Value];
  }

  public void Set(ID key, string val)
  {
    store[key.Value] = val;
  }
}</pre>
<p>We can get away with using <code>BigInteger</code> as the key to the dictionary as it is a 
<code>struct</code>.</p>
<h3>The Store Implementation</h3>
<p>In the <code>Node</code> class:</p>
<pre>/// &lt;summary&gt;
/// Store a key-value pair in our storage space, updating the contact if it's not us.
/// &lt;/summary&gt;
public void Store(Contact sender, ID key, string val)
{
  Validate.IsFalse&lt;SendingQueryToSelfException&gt;(sender.ID.Value == ourContact.ID.Value, &quot;Sender should not be ourself!&quot;);
  bucketList.AddContact(sender);

  storage.Set(key, val);
}
</pre>
<h3>The FindValue Implementation</h3>
<p>In the <code>Node</code> class:</p>
<pre>/// &lt;summary&gt;
/// Returns either a list of close contacts or a the value, if the node's storage contains the value for the key.
/// &lt;/summary&gt;
public (List&lt;Contact&gt; contacts, string val) FindValue(Contact sender, ID key)
{
  Validate.IsFalse&lt;SendingQueryToSelfException&gt;(sender.ID.Value == ourContact.ID.Value, &quot;Sender should not be ourself!&quot;);
  bucketList.AddContact(sender);

  if (storage.Contains(key))
  {
    return (null, storage.Get(key));
  }
  else
  {
    // Exclude sender.
    return (bucketList.GetCloseContacts(key, sender.ID), null);
  }
}</pre>
<h2>The Dht Class - Discussion</h2>
<p>We use a wrapper <code>Dht</code> class, which will 
become the main entry point for <i>our</i> peer, for interacting with <i>other</i> 
peers.&nbsp; The main purpose of this class is:</p>
<ol>
	<li>When storing a value, use the lookup algorithm to find other closer 
	peers to propagate the key-value.</li>
<li>When looking up a value, if our peer doesn't have the value, we again use 
the lookup algorithm to find other closer nodes that might have the value.</li>
	<li>Later we'll add a bootstrapping method that registers our peer with 
	another peer and initializes our bucket list with that peer's closest 
	contacts.</li>
</ol>
<h2>The Dht Class - Implementation</h2>
<pre>public class Dht
{
#if DEBUG // for unit testing
  public Router Router { get { return router; } }
#endif

  protected Router router;
  protected IStorage storage;
  protected IProtocol protocol;
  protected Node node;

  public Dht(ID id, IProtocol protocol, IStorage storage)
  {
    this.storage = storage;
    node = new Node(new Contact(protocol, id), storage);
    router = new Router(node);
  }

  public void Store(ID key, string val)
  {
    // We're storing to ourselves as well as k closer contacts.
    storage.Set(key, val);
    List&lt;Contact&gt; contacts = router.Lookup(key, router.RpcFindNodes).contacts;
    contacts.ForEach(c =&gt; c.Protocol.Store(node.OurContact, key, val));
  }

public (bool found, List&lt;Contact&gt; contacts, string val) FindValue(ID key)
{
  TouchBucketWithKey(key);

  string ourVal;
  List&lt;Contact&gt; contactsQueried = new List&lt;Contact&gt;();
  (bool found, List&lt;Contact&gt; contacts, string val) ret = (false, null, null);

  // If we have it, return with our value.
  if (storage.TryGetValue(key, out ourVal))
  {
    ret = (true, null, ourVal);
  }
  else
  {
    var lookup = router.Lookup(key, router.RpcFindValue);

    if (lookup.found)
    {
      ret = (true, null, lookup.val);
      // Find the first close contact (other than the one the value was found by) in which to also store the key-value.
      var storeTo = lookup.contacts.Where(c =&gt; c != lookup.foundBy).OrderBy(c =&gt; c.ID.Value ^ key.Value).FirstOrDefault();

      if (storeTo != null)
      {
        storeTo.Protocol.Store(node.OurContact, key, lookup.val);
      }
    }
  }

  return ret;
}</pre>
<h2>The Dht Class - Unit Tests</h2>
<h3>LocalStoreFoundValueTest</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> To get started, let's just make sure we can set/get values in our local store 
with an empty bucket list.</p>
<pre>[TestMethod]
public void LocalStoreFoundValueTest()
{
  VirtualProtocol vp = new VirtualProtocol();
  Dht dht = new Dht(ID.RandomID, vp, new VirtualStorage());
  vp.Node = dht.Router.Node;
  ID key = ID.RandomID;
  string val = &quot;Test&quot;;
  dht.Store(key, val);
  string retval = dht.FindValue(key).val;
  Assert.IsTrue(retval == val, &quot;Expected to get back what we stored&quot;);
}</pre>
<h3>ValueStoredInCloserNodeTest</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> This test creates a single contact and stores the value in that contact.&nbsp; 
We set up the ID's so that the contact's ID is less (XOR metric) than our peer's 
ID, and we use a key of ID.Zero to prevent further complexities when computing 
the distance.&nbsp; Most of the code here is to 
set up the conditions to make this test!</p>
<pre>[TestMethod]
public void ValueStoredInCloserNodeTest()
{
  VirtualProtocol vp1 = new VirtualProtocol();
  VirtualProtocol vp2 = new VirtualProtocol();
  VirtualStorage store1 = new VirtualStorage();
  VirtualStorage store2 = new VirtualStorage();

  // Ensures that all nodes are closer, because ID.Max ^ n &lt; ID.Max when n &gt; 0.
  Dht dht = new Dht(ID.Max, vp1, store1);
  vp1.Node = dht.Router.Node;

  ID contactID = ID.Mid; // a closer contact.
  Contact otherContact = new Contact(vp2, contactID);
  Node otherNode = new Node(otherContact, store2);
  vp2.Node = otherNode;

  // Add this other contact to our peer list.
  dht.Router.Node.BucketList.AddContact(otherContact);

  // We want an integer distance, not an XOR distance.
  ID key = ID.Zero;

  // Set the value in the other node, to be discovered by the lookup process.
  string val = &quot;Test&quot;;
  otherNode.SimpleStore(key, val);

  Assert.IsFalse(store1.Contains(key), &quot;Expected our peer to NOT have cached the key-value.&quot;);

  // Try and find the value, given our Dht knows about the other contact.
  string retval = dht.FindValue(key).val;

  Assert.IsTrue(retval == val, &quot;Expected to get back what we stored&quot;);
  Assert.IsTrue(store1.Contains(key), &quot;Expected our peer to have cached the key-value.&quot;);
}</pre>
<p>The method SimpleStore simply stores the value in the node's storage -- this 
method is available only in DEBUG mode for unit testing:</p>
<pre>#if DEBUG // For unit testing
public void SimpleStore(ID key, string val)
{
  storage.Set(key, val);
}
#endif
</pre>
<h3>ValueFoundInFartherNodeTest</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> We can change the setup of the ID's and verify that the we find the value in 
a farther node.</p>
<pre>[TestMethod]
public void ValueStoredInFartherNodeTest()
{
  VirtualProtocol vp1 = new VirtualProtocol();
  VirtualProtocol vp2 = new VirtualProtocol();
  VirtualStorage store1 = new VirtualStorage();
  VirtualStorage store2 = new VirtualStorage();

  // Ensures that all nodes are closer, because ID.Max ^ n &lt; ID.Max when n &gt; 0.
  Dht dht = new Dht(ID.Zero, vp1, store1);
  vp1.Node = dht.Router.Node;

  ID contactID = ID.Max; // a closer contact.
  Contact otherContact = new Contact(vp2, contactID);
  Node otherNode = new Node(otherContact, store2);
  vp2.Node = otherNode;

  // Add this other contact to our peer list.
  dht.Router.Node.BucketList.AddContact(otherContact);

  // We want an integer distance, not an XOR distance.
  ID key = ID.One;

  // Set the value in the other node, to be discovered by the lookup process.
  string val = &quot;Test&quot;;
  otherNode.SimpleStore(key, val);

  Assert.IsFalse(store1.Contains(key), &quot;Expected our peer to NOT have cached the key-value.&quot;);

  // Try and find the value, given our Dht knows about the other contact.
  string retval = dht.FindValue(key).val;

  Assert.IsTrue(retval == val, &quot;Expected to get back what we stored&quot;);
  Assert.IsTrue(store1.Contains(key), &quot;Expected our peer to have cached the key-value.&quot;);
}</pre>
<h3>ValueStoredGetsPropagatedTest</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> Here we test that when we store a value to our peer, it 
also gets propagated to 
another peer that our peer knows about:</p>
<pre>[TestMethod]
public void ValueStoredGetsPropagatedTest()
{
  VirtualProtocol vp1 = new VirtualProtocol();
  VirtualProtocol vp2 = new VirtualProtocol();
  VirtualStorage store1 = new VirtualStorage();
  VirtualStorage store2 = new VirtualStorage();

  // Ensures that all nodes are closer, because ID.Max ^ n &lt; ID.Max when n &gt; 0.
  Dht dht = new Dht(ID.Max, vp1, store1);
  vp1.Node = dht.Router.Node;

  ID contactID = ID.Mid; // a closer contact.
  Contact otherContact = new Contact(vp2, contactID);
  Node otherNode = new Node(otherContact, store2);
  vp2.Node = otherNode;

  // Add this other contact to our peer list.
  dht.Router.Node.BucketList.AddContact(otherContact);

  // We want an integer distance, not an XOR distance.
  ID key = ID.Zero;
  string val = &quot;Test&quot;;

  Assert.IsFalse(store1.Contains(key), &quot;Obviously we don't have the key-value yet.&quot;);
  Assert.IsFalse(store2.Contains(key), &quot;And equally obvious, the other peer doesn't have the key-value yet either.&quot;);

  dht.Store(key, val);

  Assert.IsTrue(store1.Contains(key), &quot;Expected our peer to have stored the key-value.&quot;);
  Assert.IsTrue(store2.Contains(key), &quot;Expected the other peer to have stored the key-value.&quot;);
}</pre>
<h3>GetValuePropagatesToCloserNodeTest</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> This test verifies 
that, given three nodes (the first of which is us), where node 2 has the value, 
a get value also propagates to node 3 because a lookup was performed.</p>
<pre>[TestMethod]
public void GetValuePropagatesToCloserNodeTest()
{
  VirtualProtocol vp1 = new VirtualProtocol();
  VirtualProtocol vp2 = new VirtualProtocol();
  VirtualProtocol vp3 = new VirtualProtocol();
  VirtualStorage store1 = new VirtualStorage();
  VirtualStorage store2 = new VirtualStorage();
  VirtualStorage store3 = new VirtualStorage();

  // Ensures that all nodes are closer, because ID.Max ^ n &lt; ID.Max when n &gt; 0.
  Dht dht = new Dht(ID.Max, vp1, store1);
  vp1.Node = dht.Router.Node;

  // Setup node 2:

  ID contactID2 = ID.Mid; // a closer contact.
  Contact otherContact2 = new Contact(vp2, contactID2);
  Node otherNode2 = new Node(otherContact2, store2);
  vp2.Node = otherNode2;

  // Add the second contact to our peer list.
  dht.Router.Node.BucketList.AddContact(otherContact2);

  // Node 2 has the value.
  // We want an integer distance, not an XOR distance.
  ID key = ID.Zero;
  string val = &quot;Test&quot;;
  otherNode2.Storage.Set(key, val);

  // Setup node 3:

  ID contactID3 = ID.Zero.SetBit(158); // 01000.... -- a farther contact.
  Contact otherContact3 = new Contact(vp3, contactID3);
  Node otherNode3 = new Node(otherContact3, store3);
  vp3.Node = otherNode3;

  // Add the third contact to our peer list.
  dht.Router.Node.BucketList.AddContact(otherContact3);

  Assert.IsFalse(store1.Contains(key), &quot;Obviously we don't have the key-value yet.&quot;);
  Assert.IsFalse(store3.Contains(key), &quot;And equally obvious, the third peer doesn't have the key-value yet either.&quot;);

  var ret = dht.FindValue(key);

  Assert.IsTrue(ret.found, &quot;Expected value to be found.&quot;);
  Assert.IsTrue(store3.Contains(key), &quot;Expected the third peer to have stored the key-value.&quot;);
}</pre>
<h2>The Dht - Bootstrapping Discussion</h2>
<p>From the spec: <font color="#FF00FF">To join the network, a node <i>u</i> 
must have a contact to an already participating node <i>w</i>. <i>u</i> inserts
<i>w</i> into the appropriate k-bucket. <i>u</i> then performs a node lookup for 
its own node ID. Finally, <i>u</i> refreshes all k-buckets further away than its 
closest neighbor. During the refreshes, <i>u</i> both populates its own 
k-buckets and inserts itself into other nodes' k-buckets as necessary.</font></p>
<p>The wikipedia 
page adds a little more detail:</p>
<blockquote>
	<p>&quot;The joining node inserts the bootstrap node into one of its k-buckets. 
	The joining node then does a FIND_NODE of its own ID against the bootstrap 
	node (the only other node it knows). The &quot;self-lookup&quot; will populate other 
	nodes' k-buckets with the new node ID, and will populate the joining node's 
	k-buckets with the nodes in the path between it and the bootstrap node. 
	After this, the joining node refreshes all k-buckets further away than the 
	k-bucket the bootstrap node falls in. This refresh is just a lookup of a 
	random key that is within that k-bucket range.&quot;</p>
</blockquote>
<p>By choosing a random ID within the contact's bucket range, we are creating an 
ID whose prefix determines the ordering of the contacts returned by 
<code>GetCloseContacts</code>:</p>
<pre>Select(c =&gt; new { contact = c, distance = c.ID.Value ^ key.Value }).
OrderBy(d =&gt; d.distance).</pre>
<p>This will sort the contacts such that those that are closer -- those where no 
bits are set in the prefix of the contact -- are first in the list.&nbsp; 
Ideally, with many peers participating, we should get <i>k</i> contacts that are 
closer.</p>
<p><img border="0" src="note.png" width="24" height="32"> Of particular note 
here is that when a peer network is small or in the throws of being born, other 
contacts that nodes have will not be discovered until the bootstrapping bucket 
splits.&nbsp; We'll see how the network self-corrects later on.</p>
<p><img border="0" src="note.png" width="24" height="32"> It's also interesting 
to realize that &quot;joining&quot; actually means contacting another node with any one of 
the four RPC calls.&nbsp; A new peer could join an existing network with its 
first RPC being FindValue!</p>
<h2>The Dht - Bootstrapping Implementation</h2>
<h3>RandomIDWithinBucket</h3>
<p>Getting a random ID within a bucket range is interesting and based on knowing 
that bucket ranges are always powers of 2:</p>
<pre> /// &lt;summary&gt;
/// Returns an ID within the range of the bucket's Low and High range.
/// The optional parameter forceBit1 is for our unit tests.
/// This works because the bucket low-high range will always be a power of 2!
/// &lt;/summary&gt;
public static ID RandomIDWithinBucket(KBucket bucket, bool forceBit1 = false)
{
  // Simple case:
  // High = 1000
  // Low = 0010
  // We want random values between 0010 and 1000

  // Low and High will always be powers of 2.
  var lowBits = new ID(bucket.Low).Bytes.Bits().Reverse();
  var highBits = new ID(bucket.High).Bytes.Bits().Reverse();

  // We randomize &quot;below&quot; this High prefix range.
  int highPrefix = highBits.TakeWhile(b =&gt; !b).Count() + 1;
  // Up to the prefix of the Low range.
  // This sets up a mask of 0's for the LSB's in the Low prefix.
  int lowPrefix = lowBits.TakeWhile(b =&gt; !b).Count();
  // RandomizeBeyond is little endian for &quot;bits after&quot; so reverse high/low prefixes.
  ID id = Zero.RandomizeBeyond(Constants.ID_LENGTH_BITS - highPrefix, Constants.ID_LENGTH_BITS - lowPrefix, forceBit1);

  // The we add the low range.
  id = new ID(bucket.Low + id.Value);

  return id;
}</pre>
<h3>Bootstrap</h3>
<pre>/// &lt;summary&gt;
/// Bootstrap our peer by contacting another peer, adding its contacts
/// to our list, then getting the contacts for other peers not in the
/// bucket range of our known peer we're joining.
/// &lt;/summary&gt;
public void Bootstrap(Contact knownPeer)
{
  node.BucketList.AddContact(knownPeer);
  List&lt;Contact&gt; contacts = knownPeer.Protocol.FindNode(ourContact, ourId);
  contacts.ForEach(c =&gt; node.BucketList.AddContact(c));
  KBucket knownPeerBucket = node.BucketList.GetKBucket(knownPeer.ID);
  // Resolve the list now, so we don't include additional contacts as we add to our bucket additional contacts.
  var otherBuckets = node.BucketList.Buckets.Where(b =&gt; b != knownPeerBucket);
  otherBuckets.ForEach(b =&gt; RefreshBucket(b));
}

protected void RefreshBucket(KBucket bucket)
{
  ID rndId = ID.RandomIDWithinBucket(bucket);
  // Isolate in a separate list as contacts collection for this bucket might change.
  List&lt;Contact&gt; contacts = bucket.Contacts.ToList();
  contacts.ForEach(c =&gt; c.Protocol.FindNode(ourContact, rndId).ForEach(otherContact =&gt; node.BucketList.AddContact(otherContact)));
}</pre>
<h2>The Dht - Bootstrapping Unit Tests</h2>
<h3>RandomWithinBucketTests</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> Getting a random 
ID within a bucket range was 
complicated enough that it deserves a unit test:</p>
<pre>[TestMethod]
public void RandomWithinBucketTests()
{
  // Must be powers of 2.
  List&lt;(int low, int high)&gt; testCases = new List&lt;(int low, int high)&gt;()
  {
    (0, 256), // 7 bits should be set
    (256, 1024), // 2 bits (256 + 512) should be set
    (65536, 65536 * 2), // no additional bits should be set.
    (65536, 65536 * 4), // 2 bits (65536 and 65536*2) should be set.
    (65536, 65536 * 16), // 4 bits (65536, 65536*2, 65536*4, 65536*8) should be set.
  };

  foreach (var testCase in testCases)
  {
    KBucket bucket = new KBucket(testCase.low, testCase.high);
    // We force all bits in the range we are &quot;randomizing&quot; to be true
    // so it's not really randomized. This verifies the outer algorithm
    // that figures out which bits to randomize.
    ID id = ID.RandomIDWithinBucket(bucket, true); 

    Assert.IsTrue(id.Value &gt;= bucket.Low &amp;&amp; id.Value &lt; bucket.High, &quot;ID is outside of bucket range.&quot;);

    // The ID, because we're forcing bits, should always be (high - 1) &amp; ~max(0, low - 1)
    int bitCheck = (testCase.high - 1) &amp; ~Math.Max(0, testCase.low - 1);

    Assert.IsTrue(id.Value == bitCheck, &quot;Expected bits are not correct.&quot;);
  }
}</pre>
<h3>BootstrapWithinBootstrappingBucketTest</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> In the actual 
bootstrapping unit test, we are setting up a bootstrapping peer we are joining 
to with 10 contacts.&nbsp; One of those contacts also knows about 10 other 
contacts.&nbsp; The joining peer will receive 10 contacts (for a total of 11, 
the bootstrapper + 10) and will not find any others because the &quot;other peers not 
in the known peer bucket&quot; are all in the same bucket (the bucket hasn't split 
yet.)&nbsp; The ID's for our peers are irrelevant in this scenario.</p>
<pre>[TestMethod]
public void BootstrapWithinBootstrappingBucketTest()
{
  // We need 22 virtual protocols. One for the bootstrap peer,
  // 10 for the nodes the bootstrap peer knows about, and 10 for the nodes
  // one of those nodes knows about, and one for us to rule them all.
  VirtualProtocol[] vp = new VirtualProtocol[22];
  22.ForEach((i) =&gt; vp[i] = new VirtualProtocol());

  // Us
  Dht dhtUs = new Dht(ID.RandomID, vp[0], null);
  vp[0].Node = dhtUs.Router.Node;

  // Our bootstrap peer
  Dht dhtBootstrap = new Dht(ID.RandomID, vp[1], null);
  vp[1].Node = dhtBootstrap.Router.Node;
  Node n = null;

  // Our boostrapper knows 10 contacts
  10.ForEach((i) =&gt;
  {
    Contact c = new Contact(vp[i + 2], ID.RandomID);
    n = new Node(c, null);
    vp[i + 2].Node = n;
    dhtBootstrap.Router.Node.BucketList.AddContact(c);
  });

  // One of those nodes, in this case the last one we added to our bootstrapper
  // for convenience, knows about 10 other contacts.
  10.ForEach((i) =&gt;
  {
    Contact c = new Contact(vp[i + 12], ID.RandomID);
    Node n2 = new Node(c, null);
    vp[i + 12].Node = n;
    n.BucketList.AddContact(c); // Note we're adding these contacts to the 10th node.
  });

  dhtUs.Bootstrap(dhtBootstrap.Router.Node.OurContact);

  Assert.IsTrue(dhtUs.Router.Node.BucketList.Buckets.Sum(c =&gt; c.Contacts.Count) == 11, &quot;Expected our peer to get 11 contacts.&quot;);
}</pre>
<h3>BootstrapOutsideBootstrappingBucketTest</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> In this test, we 
set up 20 nodes in the bootstrap peer in such a way that we know how the buckets 
split <i>for us</i> (20 in the left one, 1 in the right one) and add 10 contacts 
to the one in the right one.&nbsp; Because out bootstrap peer will be in the our 
left bucket, we should have a total of 31 contacts (bootstrap + its 20 contacts 
+ the other nodes 10 contacts.)</p>
<pre>[TestMethod]
public void BootstrapOutsideBootstrappingBucketTest()
{
  // We need 32 virtual protocols. One for the bootstrap peer,
  // 20 for the nodes the bootstrap peer knows about, 10 for the nodes
  // one of those nodes knows about, and one for us to rule them all.
  VirtualProtocol[] vp = new VirtualProtocol[32];
  32.ForEach((i) =&gt; vp[i] = new VirtualProtocol());

  // Us, ID doesn't matter.
  Dht dhtUs = new Dht(ID.RandomID, vp[0], null);
  vp[0].Node = dhtUs.Router.Node;

  // Our bootstrap peer
  // All ID's are &lt; 2^159
  Dht dhtBootstrap = new Dht(ID.Zero.RandomizeBeyond(Constants.ID_LENGTH_BITS - 1), vp[1], null);
  vp[1].Node = dhtBootstrap.Router.Node;
  Node n = null;

  // Our boostrapper knows 20 contacts
  20.ForEach((i) =&gt;
  {
    ID id;

    // All ID's are &lt; 2^159 except the last one, which is &gt;= 2^159
    // which will force a bucket split for _us_
    if (i &lt; 19)
    {
      id = ID.Zero.RandomizeBeyond(Constants.ID_LENGTH_BITS - 1);
    }
    else
    {
      id = ID.Max;
    }

    Contact c = new Contact(vp[i + 2], id);
    n = new Node(c, null);
    vp[i + 2].Node = n;
    dhtBootstrap.Router.Node.BucketList.AddContact(c);
    });

  // One of those nodes, in this case specifically the last one we added to our bootstrapper
  // so that it isn't in the bucket of our bootstrapper, we add 10 contacts. The ID's of
  // those contacts don't matter.
  10.ForEach((i) =&gt;
  {
    Contact c = new Contact(vp[i + 22], ID.RandomID);
    Node n2 = new Node(c, null);
    vp[i + 22].Node = n;
    n.BucketList.AddContact(c); // Note we're adding these contacts to the 10th node.
  });

  dhtUs.Bootstrap(dhtBootstrap.Router.Node.OurContact);

  Assert.IsTrue(dhtUs.Router.Node.BucketList.Buckets.Sum(c =&gt; c.Contacts.Count) == 31, &quot;Expected our peer to have 31 contacts.&quot;);
}</pre>
<h2>Bucket Management</h2>
<h3>Evicting Unresponsive Contacts In Full Buckets</h3>
<p>We should now address this in the <code>AddContact</code> method:</p>
<pre>// TODO: Ping the oldest contact to see if it's still 
// around and replace it if not.
</pre>
<p>In our VirtualProtocol, we'll simulate a node that doesn't respond:</p>
<pre>public bool Ping(Contact sender)
{
  // Ping still adds/updates the sender's contact.
  if (Responds)
  {
    node.Ping(sender);
  }

  return Responds;
}</pre>
<p>We can then implement the handling of a non-responsive node:</p>
<pre>if (CanSplit(kbucket))
{
  // Split the bucket and try again.
  (KBucket k1, KBucket k2) = kbucket.Split();
  int idx = GetKBucketIndex(contact.ID);
  buckets[idx] = k1;
  buckets.Insert(idx + 1, k2);
  AddContact(contact);
}
else
{
  Contact lastSeenContact = kbucket.Contacts.OrderBy(c =&gt; c.LastSeen).Last();
  bool stillUp = lastSeenContact.Protocol.Ping(ourContact);

  if (!stillUp)
  {
    kbucket.EvictContact(lastSeenContact);
    kbucket.AddContact(contact);
  }
}</pre>
<p><img border="0" src="unittest.png" width="14" height="32"> The unit test for 
this is straight forward -- we create a virtual node that simulates not 
responding.&nbsp; </p>
<p><img border="0" src="note.png" width="24" height="32"> Note how we're setting 
up the contacts to force a split failure, so that we trigger the part of the 
code that checks for non-responding contacts.</p>
<pre>[TestMethod]
public void NonRespondingContactTest()
{
  Contact dummyContact = new Contact(new VirtualProtocol(), ID.Zero);
  ((VirtualProtocol)dummyContact.Protocol).Node = new Node(dummyContact, null);

  BucketList bucketList = SetupSplitFailure();

  Assert.IsTrue(bucketList.Buckets.Count == 2, &quot;Bucket split should have occurred.&quot;);
  Assert.IsTrue(bucketList.Buckets[0].Contacts.Count == 1, &quot;Expected 1 contact in bucket 0.&quot;);
  Assert.IsTrue(bucketList.Buckets[1].Contacts.Count == 20, &quot;Expected 20 contacts in bucket 1.&quot;);

  // The bucket is now full. Pick the first contact, as it is last seen (they are added in chronological order.)
  Contact nonRespondingContact = bucketList.Buckets[1].Contacts[0];

  // Since the protocols are shared, we need to assign a unique protocol for this node for testing.
  VirtualProtocol vpUnresponding = new VirtualProtocol(((VirtualProtocol)nonRespondingContact.Protocol).Node, false);
  nonRespondingContact.Protocol = vpUnresponding;

  // Setup the next new contact (it can respond.)
  Contact nextNewContact = new Contact(dummyContact.Protocol, ID.Zero.SetBit(159));

  bucketList.AddContact(nextNewContact);

  Assert.IsTrue(bucketList.Buckets[1].Contacts.Count == 20, &quot;Expected 20 contacts in bucket 1.&quot;);

  // Verify CanSplit -&gt; Evict happened.
  Assert.IsFalse(bucketList.Buckets.SelectMany(b =&gt; b.Contacts).Contains(nonRespondingContact), &quot;Expected bucket to NOT contain non-responding contact.&quot;);
  Assert.IsTrue(bucketList.Buckets.SelectMany(b =&gt; b.Contacts).Contains(nextNewContact), &quot;Expected bucket to contain new contact.&quot;);
}</pre>
<h3>Bucket Refresh - Discussion</h3>
<p>From the spec: <font color="#FF00FF">Buckets are generally kept fresh by the 
traffic of requests traveling through nodes. To handle pathological cases in 
which there are no lookups for a particular ID range, each node refreshes any 
bucket to which it has not performed a node lookup in the past hour. Refreshing 
means picking a random ID in the bucket’s range and performing a node search for 
that ID.</font></p>
<h4>Ambiguity #11</h4>
<p>The phrase &quot;any bucket to which it has not performed a node lookup&quot; is 
subject to interpretation.&nbsp; One way to interpret this is possibly &quot;the 
bucket whose range contains the key in the key-value pair for a Store or 
FindValue operation.&nbsp; Another interpretation is: the k-bucket containing 
the range for any contact ID queried during 
during the lookup process.&nbsp; This second approach might seem more correct 
because&nbsp;the original alpha contacts is determined from the list of closest 
contacts across all buckets, but it then becomes arbitrary as to whether to also touch 
the buckets containing the contacts returned by the FindNodes query that are 
then queried further.&nbsp; </p>
<h3>Bucket Refresh - Implementation</h3>
<p>I am choosing the first interpretation, which 
means that the bucket containing the key gets touched in the Store and FindValue 
methods:</p>
<pre>public void Store(ID key, string val)
{
  TouchBucketWithKey(key);
  ...
}

public (bool found, List&lt;Contact&gt; contacts, string val) FindValue(ID key)
{
  TouchBucketWithKey(key);
  ...
}

protected void TouchBucketWithKey(ID key)
{
  node.BucketList.GetKBucket(key).Touch();
}</pre>
<p>Then we set up a simple refresh timer in the <code>Dht</code> class:</p>
<pre>protected void SetupBucketRefreshTimer()
{
  bucketRefreshTimer = new Timer(Constants.BUCKET_REFRESH_INTERVAL);
  bucketRefreshTimer.AutoReset = true;
  bucketRefreshTimer.Elapsed += BucketRefreshTimerElapsed;
  bucketRefreshTimer.Start();
}

private void BucketRefreshTimerElapsed(object sender, ElapsedEventArgs e)
{
  node.BucketList.Buckets.
  Where(b =&gt; (DateTime.Now - b.TimeStamp).TotalMilliseconds &gt;= Constants.BUCKET_REFRESH_INTERVAL).
  ForEach(b =&gt; RefreshBucket(b));
}

protected void RefreshBucket(KBucket bucket)
{
  bucket.Touch();
  ID rndId = ID.RandomIDWithinBucket(bucket);
  // Isolate in a separate list as contacts collection for this bucket might change.
  List&lt;Contact&gt; contacts = bucket.Contacts.ToList();
  contacts.ForEach(c =&gt; c.Protocol.FindNode(ourContact, rndId).ForEach(otherContact =&gt; node.BucketList.AddContact(otherContact)));
}</pre>
<p><img border="0" src="note.png" width="24" height="32">Note that now when a 
bucket is refreshed, it is always touched, which updates its last seen 
timestamp:</p>
<pre>public void Touch()
{
  TimeStamp = DateTime.Now;
}</pre>
<h2>Key-Value Management</h2>
<h3>Storing Key-Values Onto the new Node When a new Node Registers - Discussion</h3>
<p><font color="#FF00FF">When a new node joins the system, it must store any 
key-value pair to which it is one of the k closest. Existing nodes, by similarly 
exploiting complete knowledge of their surrounding subtrees, will know which 
key-value pairs the new node should store. Any node learning of a new node 
therefore issues STORE RPCs to transfer relevant key-value pairs to the new 
node. To avoid redundant STORE RPCs, however, a node only transfers a key-value 
pair if it’s own ID is closer to the key than are the IDs of other nodes.</font></p>
<h4>Interpretation</h4>
<ol>
	<li>a new node (contact) will be instructed to store key-values that exist 
	on the bootstrapping node (the one it's boostrapping with) for key-values 
	that meet the following condition:</li>
	<li>the key XOR'd with the bootstrapping node's ID &lt; (closer than) the key 
	XOR'd the ID's of other nodes.</li>
</ol>
<h4>Ambiguity #13</h4>
<p>What does &quot;other nodes&quot; mean?&nbsp; Are these all other 
contacts the bootstrapping node knows about, or just the <i>k</i> closest 
contacts in the joining node's bucket, or some other determination?&nbsp; We 
have to understand what &quot;exploiting complete knowledge of their surrounding 
subtrees&quot; means.&nbsp; First, this indicates that it isn't just the joining 
node's bucket.&nbsp; It 
would make sense to interpret this as &quot;store the values onto the joining node for any 
key-value where the joining node will be closer to that key <i>when there are no 
other nodes that are closer.</i>&quot;&nbsp; If the joining 
node&nbsp; becomes the <i>closest</i> node to a key-value, then it is requested 
to store that key-value.</p>
<p><img border="0" src="note.png" width="24" height="32"> It's interesting to 
note that this algorithm executes regardless of whether the bootstrapping node 
actually added the the joining node to a k-bucket.&nbsp; Remember also that 
&quot;joining&quot; actually means contacting another node with any one of the four RPC 
calls.</p>
<h3>Storing Key-Values Onto the new Node When a new Node Registers - 
Implementation</h3>
<pre>protected void SendKeyValuesToNewContact(Contact sender)
{
  // If we have a new contact...
  if (!bucketList.ContactExists(sender))
  {
    // and our distance to the key &lt; any other contact's distance to the key...
    storage.ForEach(k =&gt;
    {
      var contacts = bucketList.Buckets.SelectMany(b =&gt; b.Contacts);

      if (contacts.Count() &gt; 0)
      {
        var distance = contacts.Min(c =&gt; k ^ c.ID.Value);

        if ((k ^ ourContact.ID.Value) &lt; distance)
        {
          sender.Protocol.Store(ourContact, new ID(k), storage.Get(k)); // send it to the new contact.
        }
      }
    });
  }
}</pre>
<p><img border="0" src="todo.png" width="82" height="32"> Annoyingly, for every 
stored value, there just isn't any way to not perform the XOR computation on 
every contact.&nbsp; This could get expensive and should probably be done 
asynchronously.</p>
<h3>Storing Key-Values Onto the new Node When a new Node Registers - Unit Test</h3>
<p><img border="0" src="unittest.png" width="14" height="32"> There's a lot of 
setup here to for creating two existing contacts and two key-values and their 
ID's have been specifically set.&nbsp; See the comments for the XOR distance 
&quot;math.&quot;</p>
<pre>/// &lt;summary&gt;
/// Verify that we get stored values whose keys ^ contact ID are less than stored keys ^ other contacts.
/// &lt;/summary&gt;
[TestMethod]
public void TestNewContactGetsStoredContactsTest()
{
  // Set up a node at the midpoint.
  // The existing node has the ID 10000....
  Node existing = new Node(new Contact(null, ID.Mid), new VirtualStorage());
  string val1 = &quot;Value 1&quot;;
  string valMid = &quot;Value Mid&quot;;

  // The existing node stores two items, one with an ID &quot;hash&quot; of 1, the other with ID.Max
  // Simple storage, rather than executing the code for Store.
  existing.SimpleStore(ID.One, val1);
  existing.SimpleStore(ID.Mid, valMid);

  Assert.IsTrue(existing.Storage.Count() == 2, &quot;Expected the existing node to have two key-values.&quot;);

  // Create a contact in the existing node's bucket list that is closer to one of the values.
  // This contact has the prefix 010000....
  Contact otherContact = new Contact(null, ID.Zero.SetBit(158));
  Node other = new Node(otherContact, new VirtualStorage());
  existing.BucketList.Buckets[0].Contacts.Add(otherContact);

  // The unseen contact has a prefix 0110000....
  VirtualProtocol unseenvp = new VirtualProtocol();
  Contact unseenContact = new Contact(unseenvp, ID.Zero.SetBit(157));
  Node unseen = new Node(unseenContact, new VirtualStorage());
  unseenvp.Node = unseen; // final fixup.

  Assert.IsTrue(unseen.Storage.Count() == 0, &quot;The unseen node shouldn't have any key-values!&quot;);

  // An unseen node pings, and we should get back valMin only, as ID.One ^ ID.Mid &lt; ID.Max ^ ID.Mid
  existing.Ping(unseenContact);

  // Contacts     V1          V2 
  // 10000000     00...0001   10...0000
  // 01000000
  
  // Math:
  // c1 ^ V1     c1 ^ V2     c2 ^ V1     c2 ^ V2 
  // 100...001   000...000   010...001   110...000

  // c1 ^ V1 &gt; c2 ^ V1, so V1 doesn't get sent to the unseen node.
  // c1 ^ V2 &lt; c2 ^ V2, so V2 does get sent.

  Assert.IsTrue(unseen.Storage.Count() == 1, &quot;Expected 1 value stored in our new node.&quot;);
  Assert.IsTrue(unseen.Storage.Contains(ID.Mid), &quot;Expected valMid to be stored.&quot;);
  Assert.IsTrue(unseen.Storage.Get(ID.Mid) == valMid, &quot;Expected valMid value to match.&quot;);
}</pre>
<h3>Key Republishing - Discussion</h3>
<p>
<font color="#FF00FF">To ensure the persistence of key-value pairs, nodes 
must periodically republish keys. Otherwise, two phenomena may cause lookups for 
valid keys to fail. First, some of the k nodes that initially get a key-value 
pair when it is published may leave the network. Second, new nodes may join the 
network with IDs closer to some published key than the nodes on which the 
key-value pair was originally published. In both cases, the nodes with a 
key-value pair must republish it so as once again to ensure it is available on 
the k nodes closest to the key.</font></font> </p>
<p>
<font color="#FF00FF"> To compensate for nodes leaving the network, Kademlia 
republishes each key-value pair once an hour. A naive implementation of this 
strategy would require many messages—each of up to k nodes storing a key-value 
pair would perform a node lookup followed by k - 1 STORE RPCs every hour.&nbsp; 
</font></font></p>
<p>From wikipedia<sup>15</sup>, which can be helpful for understanding the spec with 
different phrasing:</p>
<p>&quot;Periodically, a node that stores a value will explore the network to find 
the k nodes that are close to the key value and replicate the value onto them. 
This compensates for disappeared nodes.&quot;</p>
<p>and...</p>
<p>&quot;The node that is providing the file [key-value] will periodically refresh the 
information onto the network (perform FIND_NODE and STORE messages). When all of 
the nodes having the file [key-value] go offline, nobody will be refreshing its values 
(sources and keywords) and the information will eventually disappear from the 
network.&quot;</p>
<p>The wikipedia write-up clarifies what is meant by &quot;on the k nodes closest to 
the key&quot; - in other words, for each key, a FindNode is called to find closer 
nodes and the value is republished.&nbsp; Without the optimizations, this can be 
a time consuming process if there's a lot of key-values in a node's store, which 
is addressed in an optimization later.</p>
<h4>First Optimization</h4>
<p><font color="#FF00FF">Fortunately, the republishing process can be heavily 
optimized. First, when a node receives a STORE RPC for a given key-value pair, 
it assumes the RPC was also issued to the other k - 1 closest nodes, and thus 
the recipient will not republish the key-value pair in the next hour. This 
ensures that as long as republication intervals are not exactly synchronized, 
only one node will republish a given key-value pair every hour.&nbsp; </font></p>
<p>This first optimization is simple - when receiving a Store, update the 
timestamp on the key-value.&nbsp; Any key-value that has been touched within the 
last hour is not republished as we can assume:</p>
<ol>
	<li>For a new key-value, it was also published to <i>k</i> closer nodes.</li>
	<li>If it's been republished by another node, that node republished it to <i>
	k</i> closer nodes.</li>
</ol>
<h4>Second Optimization</h4>
<p><font color="#FF00FF">A second 
optimization avoids performing node lookups before republishing keys. As 
described in Section 2.4, to handle unbalanced trees, nodes split k-buckets as 
required to ensure they have complete knowledge of a surrounding subtree with at 
least k nodes. If, before republishing key-value pairs, a node <i>u</i> 
refreshes all k-buckets in this subtree of k nodes, it will automatically be 
able to figure out the k closest nodes to a given key. These bucket refreshes 
can be amortized over the republication of many keys.</font></p>
<p>This second optimization is sort of straight forward -- if we've done a bucket refresh 
within the last hour, we can avoid calling FindNode (the node lookup algorithm.)&nbsp; 
How do we determine the bucket to test if it's been refreshed?&nbsp; The bucket 
for which the key is in range should contain some closer contacts we've seen for 
that key.&nbsp; While the answer might be obvious, it's worthwhile to discuss 
the reasoning here.&nbsp; 
</p>
<p><img border="0" src="note.png" width="24" height="32"> Buckets in the bucket 
list are maintained in range order rather than in a tree, which naturally orders 
them by their prefix:</p>
<table border="1" width="66%">
	<tr>
		<td>State</td>
		<td>Bucket Range(s)</td>
		<td width="142">Prefix(es)</td>
	</tr>
	<tr>
		<td>Initial Bucket</td>
		<td>0 .. 2<sup>160</sup></td>
		<td width="142">1</td>
	</tr>
	<tr>
		<td>Two Buckets</td>
		<td>0 .. 2<sup>159 |</sup> 2<sup>159</sup> .. 2<sup>160</sup></td>
		<td width="142">01, 1</td>
	</tr>
	<tr>
		<td>Four Buckets</td>
		<td>0 .. 2<sup>158</sup> | 2<sup>158</sup> .. 2<sup>159</sup> | 2<sup>159</sup> 
		- 2<sup>159 </sup>+ 2<sup>158 </sup>| 2<sup>159</sup> - 2<sup>159</sup>+2<sup>158</sup> 
		.. 2<sup>160</sup></td>
		<td width="142">001, 01, 10, 1</td>
	</tr>
</table>
<p>When we identify a bucket a given key, the contacts in that bucket are 
closest, as per the XOR computation on the prefix.&nbsp; For example, looking at 
the four buckets with prefixes 001, 01, 10, and 1, we see that the contacts in 
the key's bucket range are closest (closest bucket contacts are in green, 
farther bucket contacts are in red):</p>
<table border="1" width="65%">
	<tr>
		<td>Key Prefix</td>
		<td>Key Prefix ^ Bucket Prefixes</td>
		<td>Explanation</td>
	</tr>
	<tr>
		<td>1</td>
		<td><b><font color="#FF0000">101, 11, 01</font>, <font color="#00FF00">0</font></b></td>
		<td>Bucket with prefix 1 always has contacts that are closer</td>
	</tr>
	<tr>
		<td>01</td>
		<td><b><font color="#FF0000">011</font>, <font color="#00FF00">00</font>,
		<font color="#FF0000">11, 11</font></b></td>
		<td>Bucket with prefix 01 always has contacts that are closer</td>
	</tr>
	<tr>
		<td>001</td>
		<td><b><font color="#00FF00">000</font>,<font color="#FF0000"> 011, 101, 
		101</font></b></td>
		<td>Bucket with prefix 001 always has contacts that are closer</td>
	</tr>
	<tr>
		<td>0001</td>
		<td><b><font color="#00FF00">0011</font>, <font color="#FF0000">0101, 
		1001, 1001</font></b></td>
		<td>Bucket with prefix 001 always has contacts that are closer</td>
	</tr>
</table>
<h3>Key Republishing - Implementation</h3>
<p>One refactoring that has to occur is that the storage mechanism needs to 
associate a timestamp with the key-value, which you'll see used in the following 
code.</p>
<pre>/// &lt;summary&gt;
/// Replicate key values if the key-value hasn't been touched within the republish interval.
/// Also don't do a FindNode lookup if the bucket containing the key has been refreshed within the refresh interval.
/// &lt;/summary&gt;
protected void KeyValueRepublishElapsed(object sender, ElapsedEventArgs e)
{
  DateTime now = DateTime.Now;

  node.Storage.Where(
  k =&gt; (now - storage.GetTimeStamp(k)).TotalMilliseconds &gt;= Constants.KEY_VALUE_REPUBLISH_INTERVAL &amp;&amp;
    (now - node.BucketList.GetKBucket(k).TimeStamp).TotalMilliseconds &gt;= Constants.BUCKET_REFRESH_INTERVAL).
  ForEach(k =&gt;
  {
    ID kid = new ID(k);
    router.Lookup(kid, router.RpcFindNodes).contacts.ForEach(c =&gt; c.Protocol.Store(node.OurContact, kid, storage.Get(k)));
    storage.Touch(k);
  });
}</pre>
<h3>Over-Caching - Discussion</h3>
<p><font color="#FF00FF">To avoid “over-caching,” we make the expiration time of 
a (key,value) pair in any node’s database exponentially inversely proportional 
to the number of nodes between the current node and the node whose ID is closest 
to the key ID.</font></p>
<h4>Ambiguity #14</h4>
<p>The specification provides no guidance for what the calculation for 
&quot;exponentially inversely proportional&quot; should actually be.&nbsp; It's also 
undefined as to what the time constants are -- what is a baseline time for which 
a key-value should persist?&nbsp; Some digging around found a useful post on the 
emule-project forum<sup>16</sup> section 3.2.4 
(the whole forum post and responses are worth reading):</p>
<blockquote>
	<p>&quot;Gleaned from their implementation and according to the M&amp;M paper, key 
	space=160, k=20, m=60, r=24, alpha=3, b=5, p=1*m, c=0.5*m, 
	o=1/(2^(b*gap/(2^b-1)))...<br>
	<br>
	key space is defined as the system-wide size, in bits, of any key or ID.<br>
	k is defined as the system-wide replication parameter.<br>
	m is defined as the system-wide persistence parameter.<br>
	r is defined as the system-wide expiration parameter.<br>
	alpha is defined as the system-wide concurrency parameter.<br>
	<br>
	b is defined as the node-specific search accelerator parameter, specifying 
	the number of bits to hop per iteration during node lookups.<br>
	p is defined as the node-dependent pathological parameter.<br>
	c is defined as the node-dependent consistency parameter.<br>
	o is defined as the node-specific over-caching parameter.<br>
	...<br>
	Determine distance delta relative to me keyRme : d(key, Me ID) = Delta<br>
	....<br>
	all expiration timers that are associated with the values to a key are 
	re-adjusted to prevent over-caching. Initially, the expiration timer is 
	m*r*o, with o at 1. On adjustment the expiration is shortened by the o 
	factor. This factor is determined from the absolute gap in k-buckets between 
	distances keyRme and newRkey: o = 1/(2^(b*gap/(2^b-1))).&quot;</p>
</blockquote>
<p>The computation for <i>o</i> isn't in the spec, so it must have been gleaned 
from eMule's implementation.&nbsp; The above computation looks at the distance 
between buckets rather than the spec's &quot;number of nodes&quot; metric.&nbsp;&nbsp; The 
baseline expiration time of 1400 minutes (24 hours) comes from the spec:</p>
<p><font color="#FF00FF">For Kademlia’s current application (file sharing), we 
also require the original publisher of a (key,value) pair to republish it every 
24 hours. Otherwise, (key,value) pairs expire 24 hours after publication, so as 
to limit stale index information in the system. For other applications, such as 
digital certificates or cryptographic hash to value mappings, longer expiration 
times may be appropriate.</font></p>
<p>We therefore need to distinguish between key-values for which we are the 
original publisher and key-values in the store that are republications from 
other nodes.&nbsp; We also need to track an expiration time that is separate 
from the key-value republish timestamp.&nbsp; Furthermore, up to this point, I 
haven't implemented the concept of accelerated lookup optimization, which is 
where the value of <i>b </i>comes from.&nbsp; In this implementation, where we 
have bucket ranges, rather than a bucket per bit in the key space, the 
accelerated lookup optimization is irrelevant, so we'll use b==5 which is the 
spec's recommended value for that optimization. </p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>Ping</h2>
<p>Ping is simply a &quot;respond back with the random ID&quot; that was sent.&nbsp; 
Internally the buckets are potentially updated and if the contact is new, it is 
sent any values that it should store, as discussed above when a new node 
registers.</p>
<h3>Piggy-Backed Ping</h3>
<p>From: <a href="http://pub.tik.ee.ethz.ch/students/2006-So/SA-2006-19.pdf">
http://pub.tik.ee.ethz.ch/students/2006-So/SA-2006-19.pdf</a> </p>
<p><font color="#FF0000">&nbsp;The situation is different when the first message 
a node received is a request<br>
message. In this case, the receiver cannot be sure whether the sender’s contact 
informations are<br>
correct. It could be that the request was faked. To determine this, the 
piggy-backed ping is used.<br>
The effect of the piggy-backed ping is that the original sender of the request 
must send a ping reply<br>
upon receiving the reply message. Thus, the receiver of the request message is 
able to determine<br>
the correctness of the sender as well.</font></p>
<h2>Persisting the Dht</h2>
<p>The bucket lists and contacts in each bucket need to be persisted so that in 
case of a server restart, the last known state of the Dht can be restored.&nbsp; 
This is baked into the Dht implementation, serializing the data in a JSON file.&nbsp; 
The persistence of key-values is handled separately and is defined by the 
specific implementation needs.</p>
<p>&nbsp;</p>
<h2>Thread Safety</h2>
<h2>Some Enhancements</h2>
<h3>Operator Overloading of the ID Class</h3>
<h2>Not Implemented</h2>
<h3>Delayed Eviction (Optimized Contact Accounting) - Discussion</h3>
<p><font color="#FF00FF">To reduce traffic, Kademlia delays probing contacts 
until it has useful messages to send them. When a Kademlia node receives an RPC 
from an unknown contact and the k-bucket for that contact is already full with 
<i>k</i> entries, the node places the new contact in a replacement cache of 
nodes eligible to replace stale k-bucket entries. The next time the node queries 
contacts in the k-bucket, any unresponsive ones can be evicted and replaced with 
entries in the replacement cache. The replacement cache is kept sorted by time 
last seen, with the most recently seen entry having the highest priority as a 
replacement candidate.</font></p>
<h3>UDP Drop Outs - Discussion</h3>
<p><font color="#FF00FF">A related problem is that because Kademlia uses UDP, 
valid contacts will sometimes fail to respond when network packets are dropped. 
Since packet loss often indicates network congestion, Kademlia locks 
unresponsive contacts and avoids sending them any further RPCs for an 
exponentially increasing backoff interval. Because at most stages Kademlia’s 
lookup only needs to hear from one of k nodes, the system typically does not 
retransmit dropped RPCs to the same node.</font></p>
<font color="#FF00FF"> When a contact fails to respond to 5 RPCs in a row, it 
is considered stale. If a fe-bucket is not full or its replacement cache is 
empty, Kademlia merely flags stale contacts rather than remove them. This 
ensures, among other things, that if a node’s own network connection goes down 
temporarily, the node won’t completely void all of its k-buckets.</font>
<p>This is true not just for UDP packets but any connection -- it may go down 
for a while.&nbsp; This algorithm is somewhat entangled with delayed eviction.&nbsp; 
In delayed eviction, the spec state &quot;any unresponsive ones can be evicted.&quot;&nbsp; 
It is the spec's description of UDP drop outs that actually defines what 
&quot;unresponsive&quot; actually means.</p>
<h3>Accelerated Lookups - Discussion</h3>
<font color="#FF00FF">When a contact fails to respond to 5 RPCs in a row, it 
is considered stale. If a fe-bucket is not full or its replacement cache is 
empty, Kademlia merely flags stale contacts rather than remove them. This 
ensures, among other things, that if a node’s own network connection goes down 
temporarily, the node won’t completely void all of its k-buckets.</font>
<p><font color="#FF00FF">Another optimization in the implementation is to 
achieve fewer hops per lookup by increasing the routing table size. 
Conceptually, this is done by considering IDs 6 bits at a time instead of just 
one bit at a time. As previously described, the expected number of hops per 
lookup is log2 n. By increasing the routing table’s size to an expected 2b log2t 
n k-buckets, we can reduce the number of expected hops to log2&amp; n.</font></p>
<p>In this implementation, where we have bucket ranges rather than a bucket per 
bit in the key space, therefore the accelerated lookup optimization is 
irrelevant because the bucket ranges typically span many prefix bits.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>&nbsp;</h2>
<h2>References</h2>
<p>[1] -
<a href="http://www.tandfonline.com/doi/abs/10.1080/15427951.2015.1051674?src=recsys&journalCode=uinm20">
http://www.tandfonline.com/doi/abs/10.1080/15427951.2015.1051674?src=recsys&amp;journalCode=uinm20</a>
</p>
<p>[2] -
<a href="https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia">
https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia</a></p>
<p>[3] -
<a href="http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#FIND_NODE">
http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html</a></p>
<p>[4] -
<a href="https://github.com/bmuller/kademlia">
https://github.com/bmuller/kademlia</a></p>

<p>[5] - <a href="https://en.wikipedia.org/wiki/Smart_contract">
https://en.wikipedia.org/wiki/Smart_contract</a></p>
<p>[6] -
<a href="http://sandhill.com/article/is-data-decentralization-the-new-trend/">
http://sandhill.com/article/is-data-decentralization-the-new-trend/</a></p>
<p>[7] - <a href="https://arxiv.org/pdf/1506.03471.pdf">
https://arxiv.org/pdf/1506.03471.pdf</a></p>
<p>[8] - <a href="https://en.wikipedia.org/wiki/BitTorrent">
https://en.wikipedia.org/wiki/BitTorrent</a></p>
<p>[9] - <a href="https://en.wikipedia.org/wiki/Kad_network">
https://en.wikipedia.org/wiki/Kad_network</a></p>
<p>[10] - <a href="https://en.wikipedia.org/wiki/Chord_(peer-to-peer)">https://en.wikipedia.org/wiki/Chord_(peer-to-peer)</a> </p>
<p>[11] - <a href="https://en.wikipedia.org/wiki/Pastry_(DHT)">https://en.wikipedia.org/wiki/Pastry_(DHT)</a> </p>
<p>[12] -
<a href="https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00042.html">
https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00042.html</a> </p>

<p>[13] -
<a href="https://stackoverflow.com/questions/30654398/implementing-find-node-on-torrent-kademlia-routing-table">
https://stackoverflow.com/questions/30654398/implementing-find-node-on-torrent-kademlia-routing-table</a></p>
<p>[14] -
<a href="https://github.com/the8472/mldht/blob/9fb056390b50e9ddf84ed7709283b528a77a0fe5/src/lbms/plugins/mldht/kad/KClosestNodesSearch.java#L104-L170">
https://github.com/the8472/mldht/blob/9fb056390b50e9ddf84ed7709283b528a77a0fe5/src/lbms/plugins/mldht/kad/KClosestNodesSearch.java#L104-L170</a></p>
<p>[15] - <a href="https://en.wikipedia.org/wiki/Kademlia">
https://en.wikipedia.org/wiki/Kademlia</a> </p>

[16] - <a href="https://forum.emule-project.net/index.php?showtopic=32335">
https://forum.emule-project.net/index.php?showtopic=32335</a>

</font>

<p>[17] - <a href="http://www.emule-project.net/home/perl/general.cgi?l=1">
http://www.emule-project.net/home/perl/general.cgi?l=1</a> </p>
<p>&nbsp;</p>

</body>

</html>