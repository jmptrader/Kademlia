<html>

<head>
<meta http-equiv="Content-Language" content="en-us">
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Implementing the Kademlia P2P DH</title>
</head>

<body>

<p>Implementing the Kademlia Peer-to-Peer Distributed Hash Table</p>
<p>A journey from specification to implementation (with some help along the 
way.)</p>
<h2>TL;DR</h2>
<p>This is a huge article.&nbsp; The whole point of it is to show how I took the 
Kademlia peer-to-peer distributed hash table specification and implement it 
using a couple other open source implementations (one in C#, one in Python) as 
well as some ancillary documentation to do figure stuff out.&nbsp; Yes, it's a 
tome.&nbsp; But the benefit for me is that I now have a fully documented code 
base that maps implementation to specification, something rarely seen.&nbsp; 
Once the basic algorithm is implemented, I discover some flaws in my 
implementation that I demonstrate with unit testing and exploring distribution 
graphs of buckets.</p>
<h2>Introduction</h2>
<p>There's quite a few implementations of the Kademlia peer-to-peer (P2P) 
distributed hash table (DHT) algorithm out there on GitHub.&nbsp; My perusal of 
the implementations (mainly focusing on C#, but some Python and Go projects as 
well) on <a href="https://github.com/search?utf8=&#10003;&q=kademlia&type=">GitHub</a> 
vary from incomplete to WTF?&nbsp; All the implementation pretty much suffer 
from:</p>
<ol>
	<li>Lack of documentation: by this I mean matching code to the 
	specifications in the original document.&nbsp; Strange code behaviors are 
	not discussed.</li>
	<li>Not fully implemented: some repos appear to be incomplete attempts or 
	are
	<a href="https://www.codeproject.com/Lounge.aspx?msg=5429459#xx5429459xx">
	obviously buggy</a>.</li>
	<li>Entanglement: several implementations are entangled with &quot;applications&quot;, 
	such as P2P music streaming and vote tallying</li>
	<li>Lack of abstraction: pretty much every implementation I've seen does not 
	abstract out the communication protocol, whether UPD, TCP, or in-memory, 
	which is particularly useful for testing.</li>
	<li>Overly complex: some implementations incorporate asynchronous handling 
	of messages and other behaviors that are best abstracted out of the core 
	implementation.</li>
</ol>
<p>I know, it's easy to be an armchair critic!</p>
<p>The best C# (but incomplete) implementation that I've found is
<a href="https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia">
zencoders sambatyon repo</a> and the best Python implementation I've found (I 
haven't looked at them all) is <a href="https://github.com/bmuller/kademlia">
Brian Muller's</a>.&nbsp; Brian Muller's implementation is really quite 
excellent, and I highly recommend perusing the code -- I'll be showing some of 
it later on.&nbsp; As far as I can tell, the only significant issue with 
these implementations are the lack of abstraction of the transport layer (C# 
uses UDP and the Python code uses Twisted) and the C# code implementation 
doesn't appear to abstract out the data store, which is &quot;hard coded&quot; as as a 
file-based audio player.&nbsp; That said, I reference these 
implementation frequently.</p>
<p>As an aside, I'm learning some things about open source projects:</p>
<ol>
	<li>One person open source projects are great when they implement something 
	simple and compartmentalized.</li>
	<li>More complex open source solutions work best when there's a team of 
	people to review everything from architecture to stupid spelling mistakes to 
	writing and maintaining decent tests and documentation.</li>
	<li>
	<p>Having many open source projects on GitHub, most of which fail to provide 
	the benefits of a team mentioned in point #2, I actually consider myself to 
	be contributing to the problem, not the solution!</p>
	</li>
</ol>
<h3>What is Kademlia?</h3>
<p>From Wikipedia:</p>
<p><i>Kademlia is a distributed hash table for decentralized peer-to-peer 
computer networks designed by Petar Maymounkov and David Mazières in 2002. It 
specifies the structure of the network and the exchange of information through 
node lookups. Kademlia nodes communicate among themselves using UDP. A virtual 
or overlay network is formed by the participant nodes. Each node is identified 
by a number or node ID. The node ID serves not only as identification, but the 
Kademlia algorithm uses the node ID to locate values (usually file hashes or 
keywords). In fact, the node ID provides a direct map to file hashes and that 
node stores information on where to obtain the file or resource.</i></p>
<h3>Who Uses Kademlia?</h3>
<p>Kademlia is used in file sharing networks.&nbsp; For example,
<a href="https://en.wikipedia.org/wiki/BitTorrent">BitTorrent</a> uses a DHT 
based on an implementation of the Kademlia algorithm.&nbsp;
<a href="https://en.wikipedia.org/wiki/Kad_network">Kad network</a> uses the 
Kademlia protocol, with <a href="https://en.wikipedia.org/wiki/EMule">eMule</a> 
being an open source Windows client.</p>
<h3>The Kademlia Specification</h3>
<p>The original specification can be found
<a href="https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf">
here</a>.&nbsp; We'll reference this spec frequently as the code is developed.&nbsp; 
A decent slide deck with some nice pictures is
<a href="https://tams.informatik.uni-hamburg.de/lehre/2004ss/vorlesung/medientechnik/material/kpres.pdf">
here</a>.&nbsp; Lastly, an excellent specification for Kademlia can be found
<a href="http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html">
here</a>.</p>
<h3>But Why?</h3>
<p>I've become interested in peer-to-peer networks as a result of my &quot;fly on the 
wall&quot; involvement with <a href="https://holochain.org/">Holochain</a> (from the 
same people that were co-authors of the
<a href="https://www.codeproject.com/Articles/894188/Introducing-Semtrex">
Semtrex</a> article) and the underlying technologies of blockchains like Bitcoin 
and Ethereum.&nbsp; I've already written about some of the core technology 
components, such as
<a href="https://www.codeproject.com/Articles/1176140/Understanding-Merkle-Trees-Why-use-them-who-uses-t">
Merkle Trees</a> and a
<a href="https://www.codeproject.com/Articles/1172340/Hashcash-or-Proof-of-Work">
Proof of Work</a> algorithm; a deep understanding of a respected P2P DHT 
algorithm seemed like the next logical step in understanding the whole gestalt of blockchains.&nbsp; </p>
<p>I also am a firm believer that:</p>
<ol>
	<li><a href="https://en.wikipedia.org/wiki/List_of_cryptocurrencies">As 
	wikipedia puts it</a> &quot;New cryptocurrency can be created any time.&quot;&nbsp; 
	These things are here and are not going to go away.&nbsp; It's chaos right 
	now, there's lots of questions and problems, but
	<a href="http://www.businessinsider.com/bitcoin-price-security-equity-sec-2017-7">
	even the SEC is looking at how to regulate cryptocurrencies</a>, and I 
	suspect the IRS is trying to figure out how to tax these things.</li>
	<li>The underlying technology of not just cryptocurrency but any blockchain 
	that implement <a href="https://en.wikipedia.org/wiki/Smart_contract">smart 
	contracts</a> essentially must include a peer-to-peer distributed hash 
	table, at least with regards to how blockchain technology is being discussed 
	and applied (using a blockchain in a centralized scenario is sort of 
	pointless except perhaps for logging purposes.)&nbsp; Understanding how this 
	works is important.</li>
	<li>Centralized data, except for performance reasons, is
	<a href="http://sandhill.com/article/is-data-decentralization-the-new-trend/">
	on its way out</a>.&nbsp; As that last link states: &quot;The more the data 
	management industry consolidates, the more opposing forces decentralize the 
	market.&quot;&nbsp; And peer-to-peer decentralizing has built in redundancy 
	protecting from single-point data loss and access failures.&nbsp; Not that 
	decentralizing has its own problems -- security will probably be the main 
	one, if it isn't already.&nbsp; As an aside, read this short paper on
	<a href="https://arxiv.org/pdf/1506.03471.pdf">Enigma</a>.</li>
</ol>
<p>So while this is a personal venture, it is also a recognition that there are 
some interesting and complicated technologies coming down the road that need to 
be properly understood, and protocols like Kademlia are a good starting point 
for looking at a P2P DHT implementation.&nbsp; As to why Kademlia specifically, 
the summary to the spec says it best:</p>
<p><i>&quot;With its novel XOR-based metric topology, Kademlia is the first 
peer-to-peer system to combine provable consistency and performance, 
latency-minimizing routing, and a symmetric, unidirectional topology. Kademlia 
furthermore introduces a concurrency parameter, a, that lets people trade a 
constant factor in bandwidth for asynchronous lowest-latency hop selection and 
delay-free fault recovery. Finally, Kademlia is the first peer-to-peer system to 
exploit the fact that node failures are inversely related to uptime.&quot;</i></p>
<h3>Where did the Name Come From?</h3>
<p>As <a href="http://www.maymounkov.org/kademlia">Petar Maymounkov</a>, one of 
the co-creators of Kademlia says: &quot;it is a Turkish word for a “lucky man” and, 
more importantly, is the name of a mountain peak in Bulgaria.&quot;&nbsp; OK then.</p>
<h3>Protocol Before Implementation</h3>
<p>And as Petar stated (same link as above): &quot;The good or bad news (depending on 
how you look at it) is that Kademlia was baked as a protocol and algorithm 
before it ever was implemented.&quot;&nbsp; Fascinating.&nbsp; I just would not have 
the confidence to do that!</p>
<h2>Resources Used In This Research</h2>
<p>The original Kademlia specification:
<a href="http://www.cs.rice.edu/Conferences/IPTPS02/109.pdf">
http://www.cs.rice.edu/Conferences/IPTPS02/109.pdf</a></p>
<p>The longer Kademlia specification:
<a href="https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf">
https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf</a></p>
<p>Mike De Boer's description of k-buckets:
<a href="https://github.com/mikedeboer/node-k-bucket">
https://github.com/mikedeboer/node-k-bucket</a></p>
<p>Brian Muller's Python implementation:
<a href="https://github.com/bmuller/kademlia">
https://github.com/bmuller/kademlia</a></p>
<p>zencoders' implementation:
<a href="https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia">
https://github.com/zencoders/sambatyon/tree/master/Kademlia/Kademlia</a></p>
<p>Jim Dixon's post on the two different versions of the specification:
<a href="https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00039.html">
https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00039.html</a></p>
<p>Jim Dixon's description of the shorter specification:
<a href="http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#FIND_NODE">
http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#FIND_NODE</a></p>
<h2>High Level Architecture</h2>
<p>In this document, <font color="#FF00FF">fuchsia text</font> is used when 
quoting from the Kademlia specification and other documents.</p>
<p>There are four components to the high level architecture necessary to 
implement the Kademlia protocol:</p>
<ol>
	<li>Node: The concept of a node.&nbsp; Each node has a private 160-bit ID (a 
	SHA-1 hash).&nbsp; <font color="#FF00FF">Keys are opaque, 160-bit quantities 
	(e.g., the SHA-1 hash of some larger data). Participating computers each 
	have a node ID in the 160-bit key space. </font>(From the Introduction)</li>
	<li>Storage: Each node stores key-value pairs, where the key is also a 
	160-bit SHA-1 hash.&nbsp;&nbsp; <font color="#FF00FF">(key,value) pairs are 
	stored on nodes with IDs “close” to the key for some notion of closeness.</font>&nbsp; 
	The storage mechanism, whether in-memory, key-value database, file system, 
	or other, is not specified and is a good point for abstraction. (From the 
	Introduction)</li>
	<li>Routing: Nearby servers for a given key are located with an efficient 
	routing algorithm.&nbsp; <font color="#FF00FF">A node- ID-based routing 
	algorithm lets anyone efficiently locate servers near any given target key. </font>
	(From the Introduction)</li>
	<li>Communication protocol: a means of communicating between nodes (usually 
	separate computers) must exist.&nbsp; The original Kademlia specification 
	states that <font color="#FF00FF">every node keeps a list of (IP address, 
	UDP port, Node ID)</font> of nearby nodes.&nbsp; As with storage, this is a 
	good place for abstraction so that different protocols can be easily 
	employed. (Section 2.2 of the spec)</li>
</ol>
<p>This is expressed in the following diagram:</p>
<p><img border="0" src="highlevel.png" width="625" height="271"></p>
<h3>Wireframe Implementation</h3>
<p>From the above, we can put together a wireframe implementation.&nbsp; The 
abstractions are implemented as interfaces:</p>
<pre>public interface IRouter { }
public interface IAddress { }

public interface IStorage
{
  string Get(string key);
  string Set(string key, string val);
}</pre>
<p>and the concrete class is a stub:</p>
<pre>public class Router
{
}</pre>
<p>The <code>Node</code> class has a minimal implementation for initializing an ID (explained 
next):</p>
<pre>public class Node
{
  public ID NodeID { get; }

  public Node()
  {
    NodeID = ID.RandomID();
  }

  public Node(ID id)
  {
    NodeID = id;
  }

  public Node(byte[] id)
  {
    NodeID = new ID(id);
  }
}</pre>
<p>and there's a simple in-memory storage wrapping a <code>Dictionary</code>:</p>
<pre>/// &lt;summary&gt;
/// Implements in-memory storage for key-value pairs.
/// &lt;/summary&gt;
public class InMemoryStorage : IStorage
{
  protected Dictionary&lt;string, string&gt; storage;

  public InMemoryStorage()
  {
    storage = new Dictionary&lt;string, string&gt;();
  }

  public string Get(string key)
  {
    return storage[key];
  }

  public void Set(string key, string val)
  {
    storage[key] = val;
  }
}</pre>
<h3>The ID Class (Section 2.1)</h3>
<p>This class is heavily borrowed from zencoders peer-to-peer music player, the 
original source can be found
<a href="https://github.com/zencoders/sambatyon/blob/master/Kademlia/Kademlia/ID.cs">
here</a>.&nbsp; I stripped out a variety of things, but the core implementation 
remains: </p>
<p><img border="0" src="id.png" width="231" height="394"></p>
<p>Why do we need this?&nbsp; Well, as the specification states:</p>
<p><font color="#FF00FF">Many of Kademlia’s benefits result from its use of a 
novel XOR metric for distance between points in the key space. XOR is symmetric, 
allowing Kademlia participants to receive lookup queries from precisely the same 
distribution of nodes contained in their routing tables...Kademlia effectively 
treats nodes as leaves in a binary tree, with each node’s position determined by 
the shortest unique prefix of its ID...</font><span style="font-size: 12.0pt; font-family: 'Times New Roman',serif; color: #FF00FF">The 
Kademlia protocol ensures that every node knows of at least one node in each of 
its subtrees, if that subtree contains a node. With this guarantee, any node can 
locate any other node by its ID. </span></p>
<p>The ID class implements the distance computations and other algorithmic 
pieces necessary to manage the 160-bit ID, which is at the heart of Kademlia's 
routing algorithm.&nbsp; Portions of this implementation are discussed next.</p>
<h2>The Concept of Closeness (Section 2.1)</h2>
<p><font color="#FF00FF">Each Kademlia node has a 160-bit node ID. Node IDs are 
currently just random 160-bit identifiers, though they could equally well be 
constructed as in Chord. Every message a node transmits includes its node ID, 
permitting the recipient to record the sender’s existence if necessary.</font></p>
<p><font color="#FF00FF">Keys, too, are 160-bit identifiers. To assign (key,value) 
pairs to particular nodes, Kademlia relies on a notion of distance between two 
identifiers. Given two 160-bit identifiers, x and y, Kademlia defines the 
distance between them as their bitwise exclusive or (XOR) interpreted as an 
integer, d(x,y) = x ® y.</font></p>
<p>This is implemented as:</p>
<pre>public static ID operator ^(ID a, ID b)
{
  byte[] xoredData = new byte[Constants.ID_LENGTH_BYTES];
  Constants.ID_LENGTH_BYTES.ForEach(n =&gt; xoredData[n] = (byte)(a.id[n] ^ b.id[n]));

  return new ID(xoredData);
}</pre>
<p><font color="#FF00FF">We next note that XOR captures the notion of distance 
implicit in our binary- tree-based sketch of the system. In a fully-populated 
binary tree of 160-bit IDs, the magnitude of the distance between two IDs is the 
height of the smallest subtree containing them both. When a tree is not fully 
populated, the closest leaf to an ID x is the leaf whose ID shares the longest 
common prefix of x. </font></p>
<p>This is handled by the <code>&lt;</code> and <code>&gt;</code> operators used to measure distance:</p>
<pre>public static bool operator &lt;(ID a, ID b)
{
  return Constants.ID_LENGTH_BYTES.Range().SkipWhile(n =&gt; a.id[n] == b.id[n]).IsNext(n =&gt; a.id[n] &lt; b.id[n]);
}

public static bool operator &gt;(ID a, ID b)
{
  return Constants.ID_LENGTH_BYTES.Range().SkipWhile(n =&gt; a.id[n] == b.id[n]).IsNext(n =&gt; a.id[n] &gt; b.id[n]);
}</pre>
<p>A couple extension methods are used:</p>
<pre>public static IEnumerable&lt;int&gt; Range(this int n)
{
  return Enumerable.Range(0, n);
}

public static bool IsNext&lt;T&gt;(this IEnumerable&lt;T&gt; source, Func&lt;T, bool&gt; predicate)
{
  using (var enumerator = source.GetEnumerator())
  {
    enumerator.MoveNext();
    return predicate(enumerator.Current);
  }
}</pre>
<p>I know, you probably think this is excessive.</p>
<h3>Some Unit Tests</h3>
<p>These unit tests verify the primitive comparison operations.&nbsp; Given:</p>
<pre>public static ID ZeroID()
{
  byte[] data = new byte[Constants.ID_LENGTH_BYTES];

  return new ID(data);
}

public static ID OneID()
{
  byte[] data = new byte[Constants.ID_LENGTH_BYTES];
  data[Constants.ID_LENGTH_BYTES - 1] = 1;

  return new ID(data);
}

public static ID MaxID()
{
  byte[] data = new byte[Constants.ID_LENGTH_BYTES];
  Constants.ID_LENGTH_BYTES.ForEach(n =&gt; data[n] = 0xFF);

  return new ID(data);
}</pre>
<p>We have a few tests:</p>
<pre>[TestMethod]
public void CompareToTests()
{
  Assert.IsTrue(ID.OneID().CompareTo(ID.MaxID()) == -1, &quot;Expected OneID &lt; MaxID&quot;);
  Assert.IsTrue(ID.OneID().CompareTo(ID.OneID()) == 0, &quot;Expected OneID == OneID&quot;);
  Assert.IsTrue(ID.MaxID().CompareTo(ID.OneID()) == 1, &quot;Expected MaxID &gt; OneID&quot;);
}

[TestMethod]
public void ComparisonTests()
{
  Assert.IsTrue(ID.ZeroID() &lt; ID.MaxID(), &quot;Expected ZeroID &lt; MaxID&quot;);
  Assert.IsTrue(ID.OneID() &lt; ID.MaxID(), &quot;Expected OneID &lt; MaxID&quot;);
  Assert.IsTrue(ID.ZeroID() &lt; ID.OneID(), &quot;Expected ZeroID &lt; OneID&quot;);
  Assert.IsTrue(ID.OneID() == ID.OneID(), &quot;Expected OneID == OneID&quot;);
  Assert.IsTrue(ID.MaxID() &gt; ID.ZeroID(), &quot;Expected MaxID &gt; ZeroID&quot;);
  Assert.IsTrue(ID.MaxID() &gt; ID.OneID(), &quot;Expected MaxID &gt; OneID&quot;);
  Assert.IsTrue(ID.OneID() &gt; ID.ZeroID(), &quot;Expected OneID &gt; ZeroID&quot;);

  // edge cases:
  Assert.IsFalse(ID.ZeroID() &lt; ID.ZeroID(), &quot;Expected OneID == OneID&quot;);
  Assert.IsFalse(ID.ZeroID() &gt; ID.ZeroID(), &quot;Expected OneID == OneID&quot;);
  Assert.IsFalse(ID.MaxID() &lt; ID.MaxID(), &quot;Expected OneID == OneID&quot;);
  Assert.IsFalse(ID.MaxID() &gt; ID.MaxID(), &quot;Expected OneID == OneID&quot;);
}

[TestMethod]
public void XorTest()
{
  Assert.IsTrue((ID.MaxID() ^ ID.MaxID()) == ID.ZeroID(), &quot;XOR failure.&quot;);
}</pre>
<h2>Node State (Section 2.2)</h2>
<p><font color="#FF00FF">Kademlia nodes store contact information about each 
other to route query messages. For each 0 &lt; i &lt; 160, every node keeps a list of 
(IP address, UDP port, Node ID) triples for nodes of distance between 2<sup>i</sup> and 
2<sup>i+1</sup> from itself. We call these lists k-buckets. Each k-bucket is kept sorted 
by time last seen—least-recently seen node at the head, most-recently seen at 
the tail. For small values of i, the k-buckets will generally be empty (as no 
appropriate nodes will exist). For large values of i, the lists can grow up to 
size k, where k is a system-wide replication parameter. k is chosen such that 
any given k nodes are very unlikely to fail within an hour of each other (for 
example k = 20).</font></p>
<p>That phrase &quot;fall within an hour of each other&quot; is determined by an analysis 
of the <a href="https://en.wikipedia.org/wiki/Chord_(peer-to-peer)">Chord P2P 
DHT</a>, which can be read in the Kademlia spec.</p>
<h3>Abstracting the Triplet</h3>
<p>The Kademlia spec &quot;hardwires&quot; the contact information as an IP address and 
UDP port.&nbsp; We want to abstract this so that systems that implement other 
addressing schemes can 
be easily implemented.&nbsp; TCP/IP, IPv6, multiple IP addresses for the same 
node, and in-memory node instances for test purposes are some examples of other 
addressing schemes.&nbsp; We'll use an interface and wrapper class for this 
(stubs at the moment):</p>
<pre>public interface IAddress { }

public class Contact
{
  public IAddress Address { get; set; }
  public ID NodeID { get; set; }
}</pre>
<p>The interface IAddress will eventually define methods for handling messages 
that we send.&nbsp; A stub implementation for UDP communication can 
then be defined:</p>
<pre>public class UdpAddress : IAddress
{
  public IPAddress Address { get; set; }
  public int Port { get; set; }
}</pre>
<p>We can also implement a stub for our in-memory testing, which directly 
references the contact node:</p>
<pre>
public class InMemoryNodeAddress : IAddress
{
  public Node RecipientNode { get; set; }
}</pre>
<h3>K-Buckets</h3>
<p>This is where reading the spec starts to feel like those annoying word 
problems in school:</p>
<p><font color="#FF00FF">For each 0 &lt; i &lt; 160, every node keeps a list of 
(IP address, UDP port, Node ID) triples for nodes of distance between 2<sup>i</sup> and 
2<sup>i+1</sup> from itself. We call these lists k-buckets. Each k-bucket is 
kept sorted by time last seen—least-recently seen node at the head, 
most-recently seen at the tail.</font></p>
<p>I believe that the above range for <code>i</code> is wrong: it should be <code>0 &lt;= i &lt; 160</code> as this 
is necessary to allow for a node ID of 0.</p>
<p>Reading the spec on the
<a href="http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#distance">
SourceForge link</a> makes this a bit clearer:</p>
<p><i>A Kademlia node organizes its contacts, other nodes known to it, in 
buckets which hold a maximum of k contacts. These are known as k-buckets.</i></p>
<p>We can define a couple constants:</p>
<pre>public const int K = 20;
public const int ID_LENGTH_BYTES = 20;
public const int ID_LENGTH_BITS = 160;</pre>
<p>We therefore need to implement a bucket list that contains 160 buckets, each 
with k contacts, and these buckets must be kept sorted (or are sortable) by last 
time seen.&nbsp; The terms &quot;head&quot; and &quot;tail&quot; may not be obvious to people 
anymore (not that such arbitrary terms were ever obvious), so a quick reminder:</p>
<ul>
	<li>The head of the list is the first node (or leftmost node) in the list.</li>
	<li>The tail of the list is the last node (or rightmost node) in the list.</li>
</ul>
<p>Therefore, the contacts in each bucket are kept in oldest-to-newest date/time order -- the 
least recently seen node (the one with the oldest date) at the head (the first entry) and the most recently 
seen (the one with the newest date) at the tail (the last entry.)</p>
<p>Based on this information, we revise our <code>Contact</code> class to include a <code>LastSeen</code> 
property as well as away to update it:</p>
<pre>public class Contact
{
  public DateTime LastSeen { get; set; }
  public IAddress Address { get; set; }
  public ID NodeID { get; set; }

  public void Touch()
  {
    LastSeen = DateTime.Now;
  }
}
</pre>
<p>We define a <code>BucketList</code> class that contains the 160 buckets of k contacts, 
handled in the <code>K_Bucket class</code>:</p>
<pre>public class KBucket
{
  protected List&lt;Contact&gt; contacts;

  public KBucket()
  {
    contacts = new List&lt;Contact&gt;(Constants.K);
  }
}

public class BucketList
{
  protected List&lt;KBucket&gt; buckets;

  public BucketList()
  {
    buckets = new List&lt;KBucket&gt;(Constants.ID_LENGTH_BITS);
    Constants.ID_LENGTH_BITS.ForEach(() =&gt; buckets.Add(new KBucket()));
  }
}</pre>
<p>This creates 3200 <code>Contact</code> entries (160 * 20).&nbsp; We could 
implement this as a <code>List&lt;List&lt;Contact&gt;&gt;</code> but for semantic clarity, I prefer the 
above approach.&nbsp; An overly-cute (but useful) extension method is used:</p>
<pre>public static void ForEach(this int n, Action action)
{
  for (int i = 0; i &lt; n; i++)
  {
    action();
  }
}</pre>
<h3>Adding a Contact</h3>
<p><font color="#FF00FF">Each k-bucket is kept sorted by time last 
seen—least-recently seen node at the head, most-recently seen at the tail.</font></p>
<p>We can implement an <code>HaveContact</code> method whose purpose is to always maintain 
a sorted list.&nbsp; This method does two things:</p>
<ol>
	<li>Adds a contact to the tail if never been seen before, dropping of a 
	contact at the head if the bucket size == k</li>
<li>Moves a contact to the tail if it already exists.</li>
</ol>
<p>This is implemented in the <code>KBucket</code> class and assumes that the correct <code>KBucket</code> 
has been determined already:</p>
<pre>public bool Exists(ID id)
{
  return contacts.Any(c =&gt; c.NodeID == id);
}

public void HaveContact(Contact contact)
{
  if (Exists(contact.NodeID))
  {
    contacts.MoveToTail(contact, c =&gt; c.NodeID == contact.NodeID);
  }
  else
  {
    contacts.AddMaximum(contact, Constants.K);
  }
}</pre>
<p>For readability and to keep the list management separate from the <code>KBucket</code> 
class, these are implemented as extension methods:</p>
<pre>public static void MoveToTail&lt;T&gt;(this List&lt;T&gt; list, T item, Predicate&lt;T&gt; pred)
{
  int idx = list.FindIndex(pred);
  list.RemoveAt(idx);
  list.Add(item);
}

public static void AddMaximum&lt;T&gt;(this List&lt;T&gt; list, T item, int max)
{
  list.Add(item);

  if (list.Count &gt; max)
  {
    list.RemoveAt(0);
  }
}</pre>
<p>Lastly, each node has a bucket list:</p>
<pre>public class Node
{
  public ID NodeID { get; }

  <font color="#FF0000">protected BucketList bucketList;</font>

  public Node()
  {
    NodeID = ID.RandomID();
    <font color="#FF0000">bucketList = new BucketList();</font>
  }
  ...</pre>
<h3>What KBucket Does a Contact go Into?</h3>
<p>Each KBucket represents a range of 2<sup>i</sup> to 2<sup>i+1</sup> nodes, where 0 &lt;= i 
&lt; 160.&nbsp; Given a 160-bit ID, we can determine which k-bucket the contact 
goes into.&nbsp; The k-bucket index is based on powers of 2 which can be 
determined by counting the number of 0 bits from the most significant bit of the 
ID):</p>
<pre>public int GetBucketIndex()
{
  return (Constants.ID_LENGTH_BITS - id.Bits().TakeWhile(b =&gt; !b).Count() - 1).Max(0);
}</pre>
<p>Some extension method helpers:</p>
<pre>public static IEnumerable&lt;bool&gt; Bits(this byte[] bytes)
{
  IEnumerable&lt;bool&gt; GetBits(byte b)
  {
    for (int i = 0; i &lt; 8; i++)
    {
      yield return (b &amp; 0x80) != 0;
      b &lt;&lt;= 1;
    }
  }

  return bytes.SelectMany(GetBits);
}

/// &lt;summary&gt;
/// Value cannot be less than min.
/// &lt;/summary&gt;
public static int Max(this int a, int min)
{
  return (a &lt; min) ? min : a;
}</pre>
<p>An ID of 0 should have a bucket index of 0 (representing 2<sup>^0</sup> 
through 2<sup>^1</sup> - 1) and an ID with the most significant&nbsp;set should have 
a bucket index of 159, representing 2<sup>^159</sup> through 2<sup>^160</sup> - 1.&nbsp; 
A simple test:</p>
<pre>ID id1 = new ID(new byte[20]);
int idx1 = id1.GetBucketIndex();
Console.WriteLine(idx1);

byte[] b2 = new byte[20];
b2[0] = 0x80;
ID id2 = new ID(b2);
int idx2 = id2.GetBucketIndex();
Console.WriteLine(idx2);</pre>
<p>
gives us:</p>
<p>
<img border="0" src="bucket1.png" width="219" height="63"></p>
<p>
Or if you prefer some unit tests:</p>
<pre>
/// &lt;summary&gt;
/// Test bucket indexing by testing all patterns:
/// 1xxxxx (idx 159)
/// 01xxxx (idx 158)
/// 001xxx (idx 157)
/// etc. that we get the correct index back.
/// &lt;/summary&gt;
[TestMethod]
public void BucketIndexTest()
{
  int byteIdx = 0;
  byte bitIdx = 0x80;

  for (int i = 0; i &lt; Constants.ID_LENGTH_BITS; i++)
  {
    // bits 0 to i are 0, set bit i (counting from MSB), and set remaining bits (of the LSB's) to random values.
    byte[] idbytes = new byte[Constants.ID_LENGTH_BYTES];
    idbytes[byteIdx] = bitIdx;
    ID id = new ID(idbytes);
    id = id.RandomizeBeyond(i);
    int bucketIdx = id.GetBucketIndex();
    Assert.IsTrue(bucketIdx == (Constants.ID_LENGTH_BITS - (i+1)), &quot;Bucket index does not match expected index.&quot;);

    bitIdx &gt;&gt;= 1;

    if (bitIdx == 0)
    {
      ++byteIdx;
      bitIdx = 0x80;
    }
  }
}

[TestMethod]
public void EdgeCase0Test()
{
  byte[] idbytes = new byte[Constants.ID_LENGTH_BYTES];
  ID id = new ID(idbytes);
  int bucketIdx = id.GetBucketIndex();
  Assert.IsTrue(bucketIdx == 0, &quot;Index should be 0.&quot;);
}

[TestMethod]
public void EdgeCaseMaxTest()
{
  byte[] idbytes = new byte[Constants.ID_LENGTH_BYTES];
  Constants.ID_LENGTH_BYTES.ForEach((n) =&gt; idbytes[n] = 0xFF);
  ID id = new ID(idbytes);
  int bucketIdx = id.GetBucketIndex();
  Assert.IsTrue(bucketIdx == Constants.ID_LENGTH_BITS - 1, &quot;Index should be 159.&quot;);
}</pre>
<p>
However!&nbsp; As per the
<a href="http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#distance">
SourceForge spec</a>: <font color="#FF00FF">The buckets are organized by <b>the 
distance</b> between the node and the contacts in the bucket.</font></p>
<p>
Yes, this is in the Kademlia spec as well, but you have to catch it:</p>
<p>
<font color="#FF00FF">for nodes of <b>distance</b> between 2<sup>i</sup> and 2<sup>i+1</sup> 
<b>from itself</b>.</font> </p>
<p>
(My bolding - the language is the Kademlia spec is more obtuse.)</p>
<p>
Adding a contact to a bucket means that we have to provide <i>our node's ID</i> 
in order to find the correct bucket index.&nbsp; In <code>BucketList</code> we therefore 
implement (<b>incorrectly, which will be discussed much later as to why</b>):</p>
<pre>
public void HaveContact(ID ourId, Contact contact)
{
  var distance = ourId ^ contact.NodeID;
  int bucketIdx = distance.GetBucketIndex();
  buckets[bucketIdx].HaveContact(contact);
}
</pre>
<p>
Now we have the pieces in place for this part of Section 2.2:</p>
<p>
<font color="#FF00FF">When a Kademlia node receives any message (request or 
reply) from another node, it updates the appropriate k-bucket for the sender’s 
node ID. If the sending node already exists in the recipient’s k-bucket, the 
recipient moves it to the tail of the list. If the node is not already in the 
appropriate k-bucket and the bucket has fewer than k entries, then the recipient 
just inserts the new sender at the tail of the list. </font></p>
<p>
But we have a problem with the next part:</p>
<p>
<font color="#FF00FF">If the appropriate k-bucket is full, however, then the 
recipient pings the k-bucket’s least-recently seen node to decide what to do. If 
the least- recently seen node fails to respond, it is evicted from the k-bucket 
and the new sender inserted at the tail. Otherwise, if the least-recently seen 
node responds, it is moved to the tail of the list, and the new sender’s contact 
is discarded.</font></p>
<p>
While we haven't implemented the protocol yet, 
we can refactor the <code>HaveContact</code> method to take a <code>Func</code> 
that we can call to determine what to do (isn't inversion of control awesome?):</p>
<pre>
public void HaveContact(Contact contact, Func&lt;Contact, bool&gt; discardHead)
{
  contact.Touch();

  // If contact exists, promote it to the tail.
  if (Exists(contact.NodeID))
  {
    contacts.MoveToTail(contact, c =&gt; c.NodeID == contact.NodeID);
  }
  else
  {
    // When contact doesn't exist, if there's room to add it, just do so.
    if (contacts.Count &lt; Constants.K)
    {
      contacts.Add(contact);
    }
    else if (discardHead(contacts[0]))
    {
      // Otherwise, if the least recently seen node doesn't respond to a ping, discard it and
      // replace it with our new contact.
      contacts.AddMaximum(contact, Constants.K);
    }
    // Otherwise we discard the new contact, as we don't know anything about how reliable it is.
  }
}</pre>
<p>
and we pass this function in to the <code>BucketList</code> class:</p>
<pre>public void HaveContact(ID ourId, Contact contact, Func&lt;Contact, bool&gt; discardHead)
{
  var distance = ourId ^ contact.NodeID;
  int bucketIdx = distance.GetBucketIndex();
  buckets[bucketIdx].HaveContact(contact, discardHead);
}</pre>
<p>See how nice it is to have separate classes for the bucket list and the 
k-bucket?&nbsp; If we didn't do this, all this code would be in one big ugly 
class.&nbsp; Also, at this point, a unit test verifying that &quot;last seen&quot; 
ordering is preserved is useful:</p>
<pre>/// &lt;summary&gt;
/// Test that contacts added to a kbucket are in least to most-recently seen order.
/// &lt;/summary&gt;
[TestMethod]
public void LeastSeenOrderingTest()
{
  KBucket kbucket = new KBucket();
  40.ForEach(() =&gt;
  {
    kbucket.HaveContact(new Contact(), contact =&gt; false);
    Thread.Sleep(2); // need to have some time go by.
  });

  Assert.IsTrue(kbucket.Contacts.Count == Constants.K, &quot;Expected k contacts.&quot;);

  DateTime last = default(DateTime);
  kbucket.Contacts.ForEach(contact =&gt;
  {
    Assert.IsTrue(last &lt; contact.LastSeen, &quot;Contacts are out of order with regards to last seen.&quot;);
    last = contact.LastSeen;
  });
}</pre>
<p>Granted, this tests only one branch for adding contacts when the bucket is 
full.&nbsp; We can add more tests later.</p>
<p>The whole point of this process is nicely explained in the Kademlia 
documentation:</p>
<p><font color="#FF00FF">k-buckets effectively implement a least-recently seen 
eviction policy, except that live nodes are never removed from the list. This 
preference for old contacts is driven by our analysis of Gnutella trace data 
collected by Saroiu et. al. ... The longer a node has been up, the more likely 
it is to remain up another hour. By keeping the oldest live contacts around, 
k-buckets maximize the probability that the nodes they contain will remain 
online.</font></p>
<p><font color="#FF00FF">A second benefit of k-buckets is that they provide 
resistance to certain DoS attacks. One cannot flush nodes’ routing state by 
flooding the system with new nodes. Kademlia nodes will only insert the new 
nodes in the k-buckets when old nodes leave the system.</font></p>
<p>Pretty cool!</p>
<h2>The Kademlia Protocol (Section 2.3)</h2>
<p>This is where we get into the real meat and potatoes of the spec.&nbsp;
<font color="#FF00FF">The Kademlia protocol consists of four RPCs: PING, 
STORE, FIND_NODE, and FIND_VALUE.&nbsp; </font>Let's explore this a bit before implementing some stubs.</p>
<p><b>Ping</b></p>
<p><font color="#FF00FF">The PING RPC probes a node to see if it is online.</font> </p>
<p>Obviously, a ping will respond with something that we'll call a &quot;pong.&quot;&nbsp; 
We'll deal over-the-wire serialization and responses later (much later.)</p>
<p><b>Store</b></p>
<p><font color="#FF00FF">STORE instructs a node to store a (key, value) pair for 
later retrieval.</font></p>
<p><b>FindNode</b></p>
<p><font color="#FF00FF">FIND_NODE takes a 160-bit ID as an argument. The 
recipient of a the RPC returns (IP address, UDP port, Node ID) triples for the k 
nodes it knows about closest to the target ID. These triples can come from a 
single k-bucket, or they may come from multiple k-buckets if the closest 
k-bucket is not full. In any case, the RPC recipient must return k items (unless 
there are fewer than k nodes in all its k-buckets combined, in which case it 
returns every node it knows about).</font></p>
<p><b>FindValue</b></p>
<p><font color="#FF00FF">FIND_VALUE behaves like FIND_NODE—returning (IP 
address, UDP port, Node ID) triples—with one exception. If the RPC recipient has 
received a STORE RPC for the key, it just returns the stored value.</font></p>
<p>The implication here is that the key associated with the value should be a 
parameter as well.</p>
<p><b>And Lastly</b></p>
<p><font color="#FF00FF">In all RPCs, the recipient must echo a 160-bit random 
RPC ID, which provides some resistance to address forgery, PINGS can also be 
piggy-backed on RPC replies for the RPC recipient to obtain additional assurance 
of the sender’s network address.</font></p>
<p>Both of those statements are a bit confusing, we'll see if we can understand 
it better later.&nbsp; The questions are:</p>
<ul>
	<li>What do we do with this 160-bit random RPC ID and 
	how does it provide resistance to address forgery?</li>
<li><font color="#FF0000">What does that last sentence about piggy-backed pings 
mean?</font></li>
</ul>
<p>Based on the SourceForge spec:</p>
<p><font color="#FF00FF">All RPC packets are required to carry an RPC identifier 
assigned by the sender and echoed in the reply. This is a quasi-random number of 
length B (160 bits).</font></p>
<p>This makes it clearer, as this clearly states what &quot;must echo...&quot; means.&nbsp; 
Again, reading the original spec requires really reading it <i>carefully.</i></p>
<p>We'll also have to deal with this fun statement in the spec:
<font color="#FF00FF">Most operations are implemented in terms of [a] lookup 
procedure.</font></p>
<h3>Stub Implementation</h3>
<p>These are added to the IAddress interface:</p>
<pre>public interface IAddress
{
  Contact Ping(Contact sender, IAddress recipient, ID randomID);
  void Store(Contact sender, IAddress recipient, ID randomID, string key, string val);
  List&lt;Contact&gt; FindNode(Contact sender, IAddress recipient, ID randomID, ID toFind);
  (List&lt;Contact&gt; nodes, string val) FindValue(Contact sender, IAddress recipient, ID randomID, string key);
}</pre>
<p>Note the use of the C# 7 syntax!</p>
<p>Our <code>InMemoryNodeAddress</code> class (and any other communication class) must 
implement these methods, in this case as pass-through's to the node associated 
with the address (the casting bothers me, <font color="#FF0000">something to 
refactor</font>):</p>
<pre>public class InMemoryNodeAddress : IAddress
{
  public Node RecipientNode { get; set; }

  public Contact Ping(Contact sender, IAddress recipient, ID randomID)
  {
    return ((InMemoryNodeAddress)recipient).RecipientNode.Ping(sender);
  }

  public void Store(Contact sender, IAddress recipient, ID randomID, string key, string val)
  {
    ((InMemoryNodeAddress)recipient).RecipientNode.Store(sender, key, val);
  }

  public List&lt;Contact&gt; FindNode(Contact sender, IAddress recipient, ID randomID, ID toFind)
  {
    return ((InMemoryNodeAddress)recipient).RecipientNode.FindNode(sender, toFind);
  }

  public (List&lt;Contact&gt; nodes, string val) FindValue(Contact sender, IAddress recipient, ID randomID, string key)
  {
    return ((InMemoryNodeAddress)recipient).RecipientNode.FindValue(sender, key);
  }
}
</pre>
<p>A few points here:</p>
<ul>
	<li>When communicating over the wire, the parameters must be appropriately 
serialized and the response appropriately deserialized.</li>
	<li>The over-the-wire protocol must be more diligent in verifying the 
	<code>randomID</code> in the response.</li>
	<li>Responders have of course not been implemented yet.</li>
</ul>
<p>Also, it should be obvious that the <code>Node</code> class needs to 
implement these methods as well.&nbsp; Note that the <code>Node</code> class is not directly 
responsible for forming the appropriate packet to serialize and send back to the 
caller -- this will be handled by the responder to the RPC.&nbsp; The <code>Node</code> 
class has been refactored to provide some of this implementation, stubs of 
others.&nbsp; Note the constructor changes as well and the addition of the 
storage <code>property</code>:</p>
<pre>public class Node
{
  public Contact OurContact { get; set; }

  protected BucketList bucketList;
  protected IStorage storage;

  protected Node()
  {
    bucketList = new BucketList();
  }

  public Node(Contact us) : this()
  {
    OurContact = us;
  }

  public Contact Ping(Contact sender)
  {
    return OurContact;
  }

  public void Store(Contact sender, string key, string val)
  {
    storage.Set(key, val);
  }

  public List&lt;Contact&gt; FindNode(Contact sender, ID toFind)
  {
    return null;
  }

  public (List&lt;Contact&gt; nodes, string val) FindValue(Contact sender, string key)
  {
    return (null, null);
  }
}</pre>
<p>Let's revisit this statement:</p>
<p><font color="#FF00FF">When a Kademlia node receives any message (request or 
reply) from another node, it updates the appropriate k-bucket for the sender’s 
node ID.</font></p>
<p>and refactor the Node class <i>yet again</i> to implement this requirement:</p>
<pre>public Contact Ping(Contact sender)
{
  bucketList.HaveContact(OurContact.NodeID, sender, (_) =&gt; false);
  return OurContact;
}

public void Store(Contact sender, string key, string val)
{
  bucketList.HaveContact(OurContact.NodeID, sender, (_) =&gt; false);
  storage.Set(key, val);
}

public List&lt;Contact&gt; FindNode(Contact sender, ID toFind)
{
  bucketList.HaveContact(OurContact.NodeID, sender, (_) =&gt; false);
  return null;
}

public (List&lt;Contact&gt; nodes, string val) FindValue(Contact sender, string key)
{
  bucketList.HaveContact(OurContact.NodeID, sender, (_) =&gt; false);
  return (null, null);
}</pre>
<p>Note that we're stubbing the &quot;discard head&quot; function at the moment.</p>
<h3>FindNode Basic Implementation</h3>
<p>We'll start with this specification and work out the implementation.</p>
<p><font color="#FF00FF">FIND_NODE takes a 160-bit ID as an argument. The 
recipient of the RPC returns (IP address, UDP port, Node ID) triples for the k 
nodes it knows about closest to the target ID. These triples can come from a 
single k-bucket, or they may come from multiple k-buckets if the closest 
k-bucket is not full. In any case, the RPC recipient must return k items (unless 
there are fewer than k nodes in all its k-buckets combined, in which case it 
returns every node it knows about).</font></p>
<p>It's important to also review the notes on
<a href="http://xlattice.sourceforge.net/components/protocol/kademlia/specs.html#FIND_NODE">
SourceForge</a>: </p>
<p><font color="#FF00FF">The recipient of a FIND_NODE should never return a 
triple containing the nodeID of the requestor. If the requestor does receive 
such a triple, it should discard it. A node must never put its own nodeID into a 
bucket as a contact.</font></p>
<p>To restate these requirements:</p>
<ul>
	<li>The recipient should not return a triple containing the requestor's ID.</li>
	<li>A node must never put its own node ID into a bucket as a contact.</li>
</ul>
<p>The reason for this check is that it prevents would could potentially be 
infinite recursion in the node lookup algorithm (discussed later).&nbsp; Let's 
deal with that second point first.&nbsp; </p>
<pre>public void HaveContact(ID ourId, Contact contact, Func&lt;Contact, bool&gt; discardHead)
{
  // A node must never put its own node ID into a bucket as a contact.
  if (ourId != contact.NodeID)
  {
    var distance = ourId ^ contact.NodeID;
    int bucketIdx = distance.GetBucketIndex();
    buckets[bucketIdx].HaveContact(contact, discardHead);
  }
}</pre>
<p>Done!&nbsp; </p>
<p>The implementation is unfortunately a brute force iteration of all the known 
contacts in the bucket list.&nbsp; The first <i>k</i> nodes that are the 
shortest distance to the ID are returned, in ascending (shortest to greatest) 
distance.&nbsp; This algorithm is modified from the <code>ClosestContacts</code> algorithm
<a href="https://github.com/zencoders/sambatyon/blob/master/Kademlia/Kademlia/BucketList.cs">
here</a>, starting on line 208.&nbsp; (To a large extent, it really helps to 
understand the code by matching the code to the specification.)&nbsp; Using Linq, 
we have:</p>
<pre>/// &lt;summary&gt;
/// Algorithm idea from https://github.com/zencoders/sambatyon/blob/master/Kademlia/Kademlia/BucketList.cs, starting on line 208.
/// Brute force distance lookup of all known contacts, sorted by distance, then we take at most k (20) of the closest.
/// &lt;/summary&gt;
/// &lt;param name=&quot;toFind&quot;&gt;The ID for which we want to find close contacts.&lt;/param&gt;
/// &lt;param name=&quot;exclude&quot;&gt;The ID to exclude (the requestor's ID)&lt;/param&gt;
public List&lt;Contact&gt; GetCloseContacts(ID toFind, ID exclude)
{
  var contacts = buckets.
    SelectMany(b =&gt; b.Contacts).
    Where(c =&gt; c.NodeID != exclude).
    Select(c =&gt; new { contact = c, distance = c.NodeID ^ toFind }).
    OrderBy(d =&gt; d.distance).
    Take(Constants.K);

  return contacts.Select(c=&gt;c.contact).ToList();
}</pre>
<p>Linq is amazing!&nbsp; Note that the <code>where</code> clause takes care of the other 
requirement &quot;The recipient should not return a triple containing the requestor's 
ID.&quot;</p>
<p>This code is ripe for a unit test that verifies the contacts are sorted from 
least to greatest distance:</p>
<pre>// Create k contacts of random ID's and verify that they come back in sorted distances from least distance to greatest.
// We assume that we will never get two occurrances of the same random ID.
[TestMethod]
public void CloseContactTest()
{
  ID ourID = ID.RandomID();
  ID toFind = ID.RandomID();
  BucketList bucketList = new BucketList();
  Constants.K.ForEach(() =&gt; bucketList.HaveContact(ourID, new Contact() { NodeID = ID.RandomID() }, (contact) =&gt; false));
  List&lt;Contact&gt; contacts = bucketList.GetCloseContacts(toFind, ourID);

  Assert.IsTrue(contacts.Count == Constants.K, &quot;Expected k contacts returned.&quot;);

  ID distance = contacts[0].NodeID ^ toFind;

  for (int n = 1; n &lt; Constants.K; n++)
  {
    ID nextDistance = contacts[n].NodeID ^ toFind;
    Assert.IsTrue(distance &lt; nextDistance, &quot;Distances are not sorted in least to greatest order.&quot;);
    distance = nextDistance;
  }
}</pre>
<p>One might think that once the initial bucket index is found, one 
should be able to find &quot;nearby buckets&quot; by expanding the search to neighboring 
buckets +/- <i>n</i>, incrementing n until<i> k</i> contacts are found or we've 
searched the entire bucket list.&nbsp; It looks like this is what
<a href="https://github.com/bmuller">Brian Muller</a> implemented in the 
TableTraverser class in his Python version:</p>
<pre>def next(self):
  &quot;&quot;&quot;
  Pop an item from the left subtree, then right, then left, etc.
  &quot;&quot;&quot;
  if len(self.currentNodes) &gt; 0:
    return self.currentNodes.pop()

  if self.left and len(self.leftBuckets) &gt; 0:
    self.currentNodes = self.leftBuckets.pop().getNodes()
    self.left = False
    return self.next()

  if len(self.rightBuckets) &gt; 0:
    self.currentNodes = self.rightBuckets.pop().getNodes()
    self.left = True
    return self.next()

  raise StopIteration</pre>
<p>However, as Brian himself points out in
<a href="https://github.com/bmuller/kademlia/issues/28">an issue</a>, and as
<a href="https://stackoverflow.com/questions/30654398/implementing-find-node-on-torrent-kademlia-routing-table">
this Stack Overflow response</a> states: &quot;Since the XOR distance metric folds at 
each bit-carry (XOR == carry-less addition) it does not map nicely to any 
routing table layout. In other words, visiting the nearest buckets won't do.&quot;&nbsp; 
So we'll stick with the brute force algorithm.</p>
<h3>Node Lookup Implementation</h3>
<p>Now we get to the business of &quot;<font color="#FF00FF">Most operations are 
implemented in terms of [a] lookup procedure.</font>&quot;&nbsp; The lookup procedure 
in the spec is described as (my numbering):</p>
<ol>
	<li><font color="#FF00FF">Kademlia employs a recursive algorithm for node 
	lookups. The lookup initiator starts by picking alpha nodes from its closest 
	non-empty k-bucket (or, if that bucket has fewer than a entries, it just 
	takes the alpha closest nodes it knows of).</font></li>
	<li><font color="#FF00FF">The initiator then sends parallel, asynchronous 
	FIND_NODE RPCS to the alpha nodes it has chosen, alpha is a system-wide concurrency 
	parameter, such as 3.</font></li>
	<li><font color="#FF00FF">In the recursive step, the initiator resends the 
	FIND_NODE to nodes it has learned about from previous RPCs. (This recursion 
	can begin before all a of the previous RPCs have returned). </font></li>
	<li><font color="#FF00FF">Of the k nodes the initiator has heard of closest 
	to the target, it picks alpha that it has not yet queried and resends the FIND_NODE RPC to them. </font></li>
	<li><font color="#FF00FF">Nodes that fail to respond quickly are removed 
	from consideration until and unless they do respond. </font></li>
	<li><font color="#FF00FF">If a round of FIND_NODES fails to return a node 
	any closer than the closest already seen, the initiator resends the 
	FIND_NODE to all of the k closest nodes it has not already queried. </font>
	</li>
	<li><font color="#FF00FF">The lookup terminates when the initiator has 
	queried and gotten responses from the k closest nodes it has seen.</font></li>
</ol>
<p>There are some questions points to this set of requirements:</p>
<ol>
	<li>What is this &quot;recursive&quot; thing?&nbsp; The SourceForge spec says that the 
	algorithm is actually iterative.</li>
	<li>I'm going to assume that while the node lookup algorithm uses 
	the <code>FindNode</code> RPC, it is not recursive -- <code>FindNode</code> itself does not initiate 
	its own node lookup algorithm.&nbsp; Both
	<a href="https://github.com/bmuller/kademlia">Brian's Python code</a> and 
	the <a href="https://github.com/zencoders/sambatyon/tree/master/Kademlia">C# 
	zencoders</a> implementation confirm this: <code>FindNode</code> simply returns the 
	closest nodes known to the recipient. </li>
<li>Do operations like <code>Store</code> and <code>GetValue</code> use this algorithm?&nbsp; In the 
Python code, no -- the node lookup algorithm is implemented in completely 
separate
<a href="https://github.com/bmuller/kademlia/blob/master/kademlia/crawling.py">
<code>NodeSpiderCrawl</code> and <code>ValueSpiderCrawl</code> classes</a>.&nbsp; The node lookup is 
	not called as part of the <code>Store</code>, <code>FindNode</code>, or <code>FindValue</code> calls -- only 
	immediate neighbors are returned for <code>FindNode</code> and <code>FindValue</code>.&nbsp; 
	Conversely, in the C# zencoders algorithm, the answer is yes -- <code>Store</code> calls <code>
	IList&lt;Contact&gt; closest = IterativeFindNode(ID.FromString(tag.Hash));</code> 
which is the node lookup algorithm.</li>
	<li>It makes sense for FindValue to call the node lookup algorithm, and 
	again, in the C# zencoders implementation, we see this in the call 
	<code>IterativeFindValue(key, ref found, out close);</code></li>
</ol>
<p>With regards to node lookup, it appears that the main difference between 
Brian's Python code and zencoders C# code is that in the Python code, the 
discovery of closer nodes is handled by a separate crawler.&nbsp; I can see pros 
and cons to this implementation, particularly in the performance of the <code>Store</code> 
and <code>FindValue</code> RPC calls, but it's a tradeoff between performance and accuracy (finding the nearest node.)</p>
<p>A few other points:</p>
<ul>
	<li>Statements like &quot;nodes that fail to respond quickly&quot; always bother me -- 
	any time dependent aspect of an algorithm is suspect.&nbsp;&nbsp; </li>
	<li>This algorithm clearly demands an asynchronous implementation.&nbsp; 
	This makes it harder to test, which we'll attempt to deal with later.</li>
</ul>
<p>It's worth comparing the original spec with the SourceForge writeup.&nbsp; 
The algorithm is the same, but reading it expressed in a different way is 
useful, particularly to disambiguate the meaning of phrases like &quot;it has learned 
about from previous RPC's&quot; in the original spec.&nbsp; Does this many nodes 
discovered in the lookup algorithm, or any node from any previous RPC?&nbsp; It 
appears that &quot;nodes discovered in the lookup algorithm&quot; is the meaning of 
&quot;previous RPC's.&quot;</p>
<ol>
	<li><font color="#FF00FF">The search begins by selecting alpha contacts from 
	the non-empty k-bucket closest to the bucket appropriate to the key being 
	searched on. If there are fewer than alpha contacts in that bucket, contacts 
	are selected from other buckets. The contact closest to the target key, 
	closestNode, is noted.</font></li>
	<li><font color="#FF00FF">The first alpha contacts selected are used to 
	create a shortlist for the search.</font></li>
	<li><font color="#FF00FF">The node then sends parallel, asynchronous FIND_* 
	RPCs to the alpha contacts in the shortlist. Each contact, if it is live, 
	should normally return k triples. If any of the alpha contacts fails to 
	reply, it is removed from the shortlist, at least temporarily.</font></li>
	<li><font color="#FF00FF">The node then fills the shortlist with contacts 
	from the replies received. These are those closest to the target. From the 
	shortlist it selects another alpha contacts. The only condition for this 
	selection is that they have not already been contacted. Once again a FIND_* 
	RPC is sent to each in parallel.</font></li>
	<li><font color="#FF00FF">Each such parallel search updates closestNode, the 
	closest node seen so far.</font></li>
	<li><font color="#FF00FF">The sequence of parallel searches is continued 
	until either no node in the sets returned is closer than the closest node 
	already seen or the initiating node has accumulated k probed and known to be 
	active contacts.</font></li>
	<li><font color="#FF00FF">If a cycle doesn't find a closer node, if 
	closestNode is unchanged, then the initiating node sends a FIND_* RPC to 
	each of the k closest nodes that it has not already queried.&nbsp; </font>I 
	find this statement ambiguous -- do we use the alpha list of un-contacted 
	nodes, or the full list of closest nodes returned by the original &quot;find 
	closest nodes&quot; call?&nbsp; The implementations I've looked at use the list 
	of contacts that were accumulated starting from the original alpha contacts.</li>
	<li><font color="#FF00FF">At the end of this process, the node will have 
	accumulated a set of k active contacts or (if the RPC was FIND_VALUE) may 
	have found a data value. Either a set of triples or the value is returned to 
	the caller.</font></li>
</ol>
<p>All of this is implemented (not necessarily very elegantly) in two methods.&nbsp; 
The outer method performs the looping after initializing the short list:</p>
<pre>public List&lt;Contact&gt; NodeLookup(ID id, Node ourNode)
{
  BucketList bucketList = ourNode.BucketList;

  // Take alpha close contacts, excluding ourselves (we should never be in our own bucket list anyways.)
  // The first alpha contacts selected are used to create a shortlist for the search.
  List&lt;Contact&gt; shortList = bucketList.GetCloseContacts(id, ourNode.OurContact.NodeID).Take(Constants.ALPHA).ToList();
  List&lt;Contact&gt; allContacts = new List&lt;Contact&gt;(shortList);

  // Some work to do?
  if (shortList.Count &gt; 0)
  {
    List&lt;Contact&gt; successfulContacts = new List&lt;Contact&gt;();
    bool hasNewCloseContact = false;
    ID distance;
    distance = shortList[0].NodeID ^ id;
    List&lt;Contact&gt; workingShortList = new List&lt;Contact&gt;(shortList);

    do
    {
      List&lt;Contact&gt; newContacts = LookupCloserContacts(id, ourNode, workingShortList, successfulContacts);
      allContacts.AddRangeDistinct(newContacts, (a, b) =&gt; a.NodeID == b.NodeID);

      // The node then fills the shortlist with contacts from the replies received. 
      shortList.AddRangeDistinct(newContacts, (a, b) =&gt; a.NodeID == b.NodeID);
      shortList = shortList.OrderBy(c =&gt; c.NodeID ^ id).ToList();

      // From the shortlist it selects another alpha contacts.
      workingShortList = new List&lt;Contact&gt;(shortList);

      // The only condition for this selection is that they have not already been contacted.
      workingShortList.RemoveRange(successfulContacts, (a, b) =&gt; a.NodeID == b.NodeID);
      workingShortList = workingShortList.OrderBy(c =&gt; c.NodeID ^ id).Take(Constants.ALPHA).ToList(); // sort by distance!

      // Each such parallel search updates closestNode, the closest node seen so far.
      // TODO: Make this parallel!
      hasNewCloseContact = (shortList[0].NodeID ^ id) &lt; distance;

      if (hasNewCloseContact)
      {
        distance = shortList[0].NodeID ^ id;
      }
      else
      {
        // If a cycle doesn't find a closer node, if closestNode is unchanged, 
        // then the initiating node sends a FIND_* RPC to each of the k closest nodes that it has not already queried.
        workingShortList = new List&lt;Contact&gt;(allContacts);
        workingShortList.RemoveRange(successfulContacts);
        workingShortList = workingShortList.Take(Constants.K).ToList();
      }

      // Once again a FIND_* RPC is sent to each in parallel.

      // The sequence of parallel searches is continued until either no node in the sets returned is closer 
      // than the closest node already seen or the initiating node has accumulated k probed 
      // and known to be active contacts.
    } while ((!hasNewCloseContact || shortList.Count &lt; Constants.K) &amp;&amp; workingShortList.Count &gt; 0);
  }

  // Return at most k contacts.
  return shortList.Take(Constants.K).ToList();
}</pre>
<p>and the inner method handles the <code>FindNode</code> call results to the recipient 
nodes:</p>
<pre>protected List&lt;Contact&gt; LookupCloserContacts(ID id, Node ourNode, List&lt;Contact&gt; workingShortList, List&lt;Contact&gt; successfulContacts)
{
  List&lt;Contact&gt; unsucessfulContacts = new List&lt;Contact&gt;();

  // The known closest node is the first entry.
  List&lt;Contact&gt; newContacts = new List&lt;Contact&gt;();

  // The node then sends parallel, asynchronous FIND_* RPCs to the alpha contacts in the shortlist. 
  // Each contact, if it is live, should normally return k triples. 
  // If any of the alpha contacts fails to reply, it is removed from the shortlist, at least temporarily.
  workingShortList.ForEach(c =&gt;
  {
    List&lt;Contact&gt; targetContacts = ourNode.OurContact.Address.FindNode(ourNode.OurContact, c.Address, ID.RandomID(), id);

    // Let's assume that failure to contact a node results in a null.
    if (targetContacts != null)
    {
      successfulContacts.Add(c);

      // Add the nodes it returns to the new contacts list.
      newContacts.AddRangeDistinct(targetContacts, (a, b) =&gt; a.NodeID == b.NodeID);
    }
    else
    {
      unsucessfulContacts.Add(c);
    }
  });

  // If any of the alpha contacts fails to reply, it is removed from the shortlist, at least temporarily.
  workingShortList.RemoveRange(unsucessfulContacts); // These are our references

  return newContacts;
}</pre>
<h4>Unit Testing Node Lookup</h4>
<p>Writing a unit test for this is an interesting exercise in testing the 
algorithm in a controlled manner.&nbsp; We can start with a node that has a 
bucket list with <i>k</i> nodes, but only the first node knows about the other 
nodes.&nbsp; We also want to control the ID's so that the test results are 100% 
reproducible and in such a way that the distance metric is easily worked with.&nbsp; 
For that, we'll create <i>k</i> nodes where the node id is 2<sup>^n</sup>:
</p>
<pre>/// &lt;summary&gt;
/// Create nodes with known ID's from 1 to 2^n
/// &lt;/summary&gt;
private List&lt;Node&gt; CreateNodes(int n)
{
  List&lt;Node&gt; nodes = new List&lt;Node&gt;();
  ID id = ID.OneID();
  Node node;

  n.ForEach(() =&gt;
  {
    var address = new InMemoryNodeAddress();
    nodes.Add(node = new Node(address, id));
    address.RecipientNode = node;
    id &lt;&lt;= 1;
  });

  return nodes;
}</pre>
<h4>Simple One Node Unit Test</h4>
<p>Now we can write a simple test in which 20 nodes are created, but only the 
first node knows of the remaining 19.&nbsp; This helps us test the case where 
the closer contacts return nothing, so all the work is being done by the 
<code>NodeLookup</code> method, and while the <code>LookupCloserContacts</code> method is called, it does 
nothing.&nbsp; This test verifies that the first node returned is indeed the 
closest non-self node to ID 0 and ID(max).&nbsp; Because there's nothing to do, 
the resulting contact list has only alpha nodes.</p>
<pre>[TestMethod]
public void SimpleOneNodeTest()
{
  // Create k nodes and register nodes 1 through k-1 onto node 0.
  List&lt;Node&gt; nodes = CreateNodes(Constants.K);
  nodes.Skip(1).ForEach(n =&gt; nodes[0].SimpleRegistration(n.OurContact));
  Router router = new Router();
  List&lt;Contact&gt; contacts;

  contacts = router.NodeLookup(ID.ZeroID(), nodes[0]);
  Assert.IsTrue(contacts.Count == 3, &quot;Expected alpha items&quot;);
  // Don't forget, we exclude ourselves!
  Assert.IsTrue(contacts[0] == nodes[1].OurContact, &quot;Expected contact 0 to be returned.&quot;);

  contacts = router.NodeLookup(ID.MaxID(), nodes[0]);
  Assert.IsTrue(contacts.Count == 3, &quot;Expected alpha items&quot;);
  Assert.IsTrue(contacts[0] == nodes[19].OurContact, &quot;Expected contact 0 to be returned.&quot;);
}</pre>
<p>Next, we'd like to create a test that forces the maximum number of traversals 
-- every node returns a closer contact.&nbsp; We can set this up as a linear 
(that is, not circular) chain:</p>
<ul>
	<li>node 0 knows only about node 1</li>
	<li>node 1 knows about node 0 and node 2</li>
	<li>node 2 knows about node 1 and node 3</li>
	<li>etc.</li>
	<li>node 19 knows only about node 18</li>
</ul>
<p>Therefore, if we ask node 0 for ID(max), it must traverse to node 19 to find 
that closest node.&nbsp; If we ask node 19 for ID(0), it must traverse to node 0 
to find the closest match.&nbsp; Note how we get a list of <i>k</i> visited 
nodes.</p>
<p>Also, we can circularize the list to test that the routine exits when the no 
nodes closer can the current one exists.&nbsp; Note how we get a list of alpha 
visited nodes.&nbsp; These tests use the following helpers:</p>
<pre>private void CreateLinearChain(List&lt;Node&gt; nodes)
{
  int count = nodes.Count;

  // edge cases:
  nodes[0].SimpleRegistration(nodes[1].OurContact);
  nodes[count - 1].SimpleRegistration(nodes[count - 2].OurContact);

  // The rest:
  for (int i = 1; i &lt; count - 1; i++)
  {
    nodes[i].SimpleRegistration(nodes[i - 1].OurContact);
    nodes[i].SimpleRegistration(nodes[i + 1].OurContact);
  }
}

private void CreateCircularChain(List&lt;Node&gt; nodes)
{
  int count = nodes.Count;

  nodes.ForEachWithIndex((n, i) =&gt;
  {
    nodes[i].SimpleRegistration(nodes[(i - 1).Mod(count)].OurContact);
    nodes[i].SimpleRegistration(nodes[(i + 1).Mod(count)].OurContact);
  });
}</pre>
<p>And because <code>-1 % 20</code> according to C#/C++ is -1 rather than 19, we 
have this extension method to do the modulus operation correctly:</p>
<pre>public static int Mod(this int a, int b)
{
  return(a % b + b) % b;
}</pre>
<h4>Linear Chain Forward Crawl Unit Test</h4>
<pre>[TestMethod]
public void LinearChainForwardCrawlTest()
{
  Router router = new Router();
  List&lt;Contact&gt; contacts;

  List&lt;Node&gt; nodes = CreateNodes(Constants.K);
  CreateLinearChain(nodes);

  // forward crawl...
  contacts = router.NodeLookup(ID.MaxID(), nodes[0]);
  // Note that after the node lookup, the kbuckets have been updated with the requestors.

  Assert.IsTrue(contacts.Count == Constants.K - 1, &quot;Expected alpha items&quot;);
  Assert.IsTrue(contacts[0] == nodes[Constants.K - 1].OurContact, &quot;Expected contact 0 to be returned.&quot;);
}</pre>
<h4>Linear Reverse Crawl Unit Test</h4>
<pre>[TestMethod]
public void LinearChainBackwardCrawlTest()
{
  Router router = new Router();
  List&lt;Contact&gt; contacts;

  List&lt;Node&gt; nodes = CreateNodes(Constants.K);
  CreateLinearChain(nodes);

  // backward crawl...
  contacts = router.NodeLookup(ID.ZeroID(), nodes[Constants.K - 1]);
  // Note that after the node lookup, the kbuckets have been updated with the requestors.

  Assert.IsTrue(contacts.Count == Constants.K - 1, &quot;Expected alpha items&quot;);
  Assert.IsTrue(contacts[0] == nodes[0].OurContact, &quot;Expected contact 0 to be returned.&quot;);
}</pre>
<h4>Circular Chain Forward Crawl Unit Test</h4>
<p>This test, and the next one, excersises the branch in the code that handles 
&quot;If a cycle doesn't find a closer node, if closestNode is unchanged, then the 
initiating node sends a FIND_* RPC to each of the k closest nodes that it has 
not already queried.&quot;&nbsp; In the previous tests, there are no remaining 
contacts to test.&nbsp; In this test and the next one, there are.</p>
<pre>[TestMethod]
public void CircularChainForwardCrawlTest()
{
  Router router = new Router();
  List&lt;Contact&gt; contacts;

  List&lt;Node&gt; nodes = CreateNodes(Constants.K);
  CreateCircularChain(nodes);

  // forward crawl...
  contacts = router.NodeLookup(ID.MaxID(), nodes[0]);
  // Note that after the node lookup, the kbuckets have been updated with the requestors.

  Assert.IsTrue(contacts.Count == Constants.K - 1, &quot;Expected alpha items&quot;);
  Assert.IsTrue(contacts[0] == nodes[Constants.K - 1].OurContact, &quot;Expected contact 0 to be returned.&quot;);
}</pre>
<h4>Circular Chain Reverse Crawl Unit Test</h4>
<pre>[TestMethod]
public void CircularChainBackwardCrawlTest()
{
  Router router = new Router();
  List&lt;Contact&gt; contacts;

  List&lt;Node&gt; nodes = CreateNodes(Constants.K);
  CreateCircularChain(nodes);

  // backward crawl...
  contacts = router.NodeLookup(ID.ZeroID(), nodes[Constants.K - 1]);
  // Note that after the node lookup, the kbuckets have been updated with the requestors.

  Assert.IsTrue(contacts.Count == Constants.K - 1, &quot;Expected alpha items&quot;);
  Assert.IsTrue(contacts[0] == nodes[0].OurContact, &quot;Expected contact 0 to be returned.&quot;);
}</pre>
<h4>Automatic Discovery Unit Tests</h4>
<p>The node lookup algorithm has the interesting (and intended) affect that 
nodes discover other nodes when a node gets a request from a node that is not in 
its list of known nodes.&nbsp; We'll use this helper method for exploring node 
buckets:</p>
<pre>/// &lt;summary&gt;
/// For unit testing...
/// &lt;/summary&gt;
/// &lt;returns&gt;A list of tuples representing the bucket index and the count of contacts in each bucket.&lt;/returns&gt;
public List&lt;(int idx, int count)&gt; GetBucketContactCounts()
{
  return buckets.
    Select(b =&gt; new { bucket = b, idx = b.Index }).
    Where(b =&gt; b.bucket.Contacts.Count &gt; 0).
    Select(b =&gt; (b.idx, b.bucket.Contacts.Count)).ToList();
}</pre>
<p>A simple unit test illustrates this.&nbsp; Node 1 knows about node 2, but 
node 2 doesn't know anything else.&nbsp; After a node lookup (or any other RPC 
actually to node 2), node 2 also knows about node 1:</p>
<pre>[TestMethod]
public void SimpleDiscoveryTest()
{
  Node node1 = CreateNode(ID.OneID());
  Node node2 = CreateNode(ID.OneID() &lt;&lt; 1);
  node1.SimpleRegistration(node2.OurContact);

  // Initial state:
  Assert.IsTrue(node1.BucketList.GetBucketContactCounts().Count == 1, &quot;Expected only one contact.&quot;);
  Assert.IsTrue(node2.BucketList.GetBucketContactCounts().Count == 0, &quot;Expected no contacts.&quot;);

  new Router().NodeLookup(ID.ZeroID(), node1);

  // Final state:
  Assert.IsTrue(node1.BucketList.GetBucketContactCounts().Count == 1, &quot;Expected only one contact.&quot;);
  Assert.IsTrue(node2.BucketList.GetBucketContactCounts().Count == 1, &quot;Expected one contact.&quot;);
  Assert.IsTrue(node2.BucketList.GetBucketContactCounts().First().idx == 1, &quot;Expected contact in bucket 1&quot;);
}</pre>
<p>What happens in the linear chain, where we start with node 1 and discover 
that node 19 is the closest node?&nbsp; Because of this condition in the 
discovery routine:</p>
<pre>else
{
  // If a cycle doesn't find a closer node, if closestNode is unchanged, 
  // then the initiating node sends a FIND_* RPC to each of the k closest nodes that it has not already queried.
  workingShortList = new List&lt;Contact&gt;(allContacts);
  workingShortList.RemoveRange(successfulContacts);
  workingShortList = workingShortList.Take(Constants.K).ToList();
}</pre>
<p>even nodes that are not closer are explored.&nbsp; This results in each node 
discovering all the other nodes (up to <i>k</i> nodes).&nbsp; Initially, this is 
the state of known nodes:</p>
<p><img border="0" src="initialKnown.png" width="477" height="203"></p>
<p>The green nodes know only their neighbor orange nodes.&nbsp; Node 0 knows 
about node 1, node 1 knows about nodes 0 and 2, etc.</p>
<ul>
	<li>When we search forward for MaxID, the node performing the search 
	iteratively tests the next node to the right (as it's distance is shorter to 
	MaxID) and therefore starts adding contacts that it didn't know about.</li>
<li>When we search for ID==1, the code branch above is executed because we have 
a path toward the right (where the distance is greater than ID==1) that hasn't 
been explored.</li>
	<li>Remember that we're always sorting the working short list by distance! 
</li>
</ul>
<p>Therefore, regardless of how the node is found, any untested contact is 
checked, regardless of whether it is farther in distance, until we've acquired
<i>k</i> closest nodes or there are no remaining unchecked nodes.&nbsp; The result is that 
each node knowing about the other nodes in decreasing count:</p>
<p><img border="0" src="finalKnown.png" width="477" height="296"></p>
<ul>
	<li>Node 0 knows 19 other contactss</li>
	<li>Node 1 knows 19 other contacts (all the forward contacts plus node 0 
	which it originally knew)</li>
	<li>Node 2 knows 18 other contacts (all the forward contacts plus node 1 
	which it originally knew)</li>
	ietc.</li>
</ul>
<p>We can write a unit test to verify this:</p>
<pre>[[TestMethod]
public void LinearChainDiscoveryTest()
{  Router router = new Router();
  List&lt;Node&gt; nodes = CreateNodes(Constants.K);
  CreateLinearChain(nodes);

  nodes.ForEach(n =&gt; router.NodeLookup(ID.OneID(), n));

  // Final state::
  nodes.ForEachWithIndex((n, idx) =&gt;
  {
    // First two nodes know K-1 contacts.
    int expectedContacts = Constants.K - 1 - (idx &gt; 1 ? idx - 1 : 0);
    Assert.IsTrue(n.BucketList.GetBucketContactCounts().Count == expectedContacts, &quot;Expected &quot; + expectedContacts + &quot; contact(s).&quot;);
  });
}</pre>
<h2>Implementing the DHT Wrapper</h2>
<p>We have enough pieces now to implement the DHT wrapper that incorporates some 
higher level functionality.&nbsp; Each DHT is associated with a node.&nbsp; 
</p>
<h3>Storing Values</h3>
<p>According to the spec: <font color="#FF00FF">To store a (key,value) pair, a 
participant locates the k closest nodes to the key and sends them STORE RPCS</font>.&nbsp; 
It's not clear what we do if there are no participants.&nbsp; Do we store the 
key-value ourselves?&nbsp; I would assume so!&nbsp; The zencoders implementation 
always stores the key-value on our own node before storing it on other nodes.&nbsp; 
However, the node's STORE is supposed to be a primitive operation, but zencoders 
implementation is iterative (it also stores to close nodes).</p>
<p>Our implementation starts with:</p>
<pre>public class Dht
{
  protected Node node;

  public Dht(Node node)
  {
    this.node = node;
  }

  public void Store(string key, string val)
  {
    ID keyID = ID.FromString(key);
    node.Store(node.OurContact, key, val); // we're storing to ourselves as well as k contacts.
    List&lt;Contact&gt; contacts = node.FindNode(node.OurContact, keyID);
    contacts.ForEach(c =&gt; c.Address.Store(node.OurContact, c.Address, ID.RandomID(), key, val));
  }
}</pre>
<h4>Store Unit Test</h4>
<p>We can create <i>k*2</i> (40) chained nodes and verify that the value has been 
stored in <i>k+1</i> (21) of them (20 for k, 1 for our own node):</p>
<pre>[TestMethod]
public void StoreTest()
{
  List&lt;Node&gt; nodes = RouterTests.CreateNodes(Constants.K * 2);
  RouterTests.CreateLinearChain(nodes);
  RouterTests.CreateStorage(nodes);
  Dht dht = new Dht(nodes[0]);
  dht.Store(&quot;A&quot;, &quot;1&quot;);   // steak sauce.
  int stores = nodes.Sum(n =&gt; n.Storage.Entries());
  Assert.IsTrue(stores == 21, &quot;Expected 21 storage locations (ourself plus k more)&quot;);
}</pre>
<h3>Getting Values</h3>
<p>We actually haven't implemented this yet.</p>
<p><font color="#FF00FF">FIND_VALUE behaves like FIND_NODE—returning (IP 
address, UDP port, Node ID) triples—with one exception. If the RPC recipient has 
received a STORE RPC for the key, it just returns the stored value.</font></p>
<p>We need to refactor the <code>FindValue</code> stub in the <code>Node</code> class to this:</p>
<pre>/// &lt;summary&gt;
/// Returns either a list of close contacts or a the value, if the node's storage contains the value for the key.
/// &lt;/summary&gt;
public (List&lt;Contact&gt; nodes, string val) FindValue(Contact sender, ID keyID)
{
  List&lt;Contact&gt; contacts = null;
  string val = null;

  bucketList.HaveContact(OurContact.NodeID, sender, (_) =&gt; false);

  if (!Storage.TryGetValue(keyID.ToString(), out val))
  {
    contacts = bucketList.GetCloseContacts(keyID, sender.NodeID);
  }

  return (contacts, val);
}</pre>
<p>In the router, the <code>LookupCloserContacts</code> method hardcodes the FindValue call:</p>
<pre>List&lt;Contact&gt; targetContacts = ourNode.OurContact.Address.FindNode(ourNode.OurContact, c.Address, ID.RandomID(), id);</pre>
<p>We want to refactor this into an inversion of control pattern, where we pass 
in the function that should be called:</p>
<pre>(List&lt;Contact&gt; contacts, string val) cval = finder(ourNode.OurContact.Address, ourNode.OurContact, c.Address, ID.RandomID(), id);</pre>
<p>This requires refactoring a bunch of other methods, interfaces, and unit 
tests because we now pass in one of the two finder methods defined in the 
<code>Dht</code> class:</p>
<pre>public static (List&lt;Contact&gt; contacts, string val) NodeLookup(IAddress ourAddr, Contact us, IAddress theirAddr, ID rID, ID keyID)
{
  return ourAddr.FindNode(us, theirAddr, rID, keyID);
}

public static (List&lt;Contact&gt; contacts, string val) ValueLookup(IAddress ourAddr, Contact us, IAddress theirAddr, ID rID, ID keyID)
{
  return ourAddr.FindValue(us, theirAddr, rID, keyID);
}
</pre>
<p>In the end, the <code>Dht</code> class' <code>FindValue</code> method looks 
like this:</p>
<pre>public (bool found, string val) FindValue(string key)
{
  string ourval;

  // If we have it, return with our value.
  if (node.Storage.TryGetValue(key, out ourval))
  {
    return (true, ourval);
  }

  ID keyID = ID.FromString(key);
  Router router = new Router();

  (List&lt;Contact&gt; contacts, string val) = router.Lookup(keyID, node, ValueLookup);

  return (contacts == null, val);
}</pre>
<p>The <code>Dht</code>'s <code>Store</code> method has been refactored 
similarly, but uses <code>NodeLookup</code> instead of <code>ValueLookup</code>:</p>
<pre>public void Store(string key, string val)
{
  Router router = new Router();
  ID keyID = ID.FromString(key);
  node.Store(node.OurContact, keyID, val); // we're storing to ourselves as well as k contacts.
  List&lt;Contact&gt; contacts = router.Lookup(keyID, node, NodeLookup).contacts;
  contacts.ForEach(c =&gt; c.Address.Store(node.OurContact, c.Address, ID.RandomID(), keyID, val));
}</pre>
<h4>FindValue Unit Test</h4>
<p>So now let's write a unit test that stores the value as we did above, but 
then asks a node in the chain that we know doesn't have the value to find the 
value for the given key:</p>
<pre>[TestMethod]
public void FindValueTest()
{
  List&lt;Node&gt; nodes = RouterTests.CreateNodes(Constants.K * 2);
  RouterTests.CreateLinearChain(nodes);
  RouterTests.CreateStorage(nodes);
  Dht dht = new Dht(nodes[0]);
  dht.Store(&quot;A&quot;, &quot;1&quot;); // steak sauce

  Node emptyNode = nodes.First(n =&gt; n.Storage.Entries() == 0);
  // Create a DHT associated with this node.
  Dht dht2 = new Dht(emptyNode);
  var result = dht2.FindValue(&quot;A&quot;);

  Assert.IsTrue(result.found, &quot;Expected value to be found&quot;);
  Assert.IsTrue(result.val == &quot;1&quot;, &quot;Expected A1 steak sauce.&quot;);
}</pre>
<h2>Review So Far</h2>
<p>At this point we have implemented all the core pieces of the Kademlia 
specification, using virtual nodes and in-memory store for the underlying 
transport and storage systems, and all unit tests verifying the various 
components of the system pass:</p>
<p><img border="0" src="unittests.png" width="218" height="393"></p>
<p>At this point, we have a few but very important things left to do:</p>
<ol>
	<li>Make the process thread safe.</li>
	<li>Implement a TCP server with a subnet field, so we can use a single port 
	for testing (avoids having to deal with &quot;so-and-so wants access to port 
	blah&quot; pop-ups that Windows thinks makes you safer) and do testing with 
	actual over-the-wire communication.&nbsp; This also includes timeout 
	handling / failure to communicate.</li>
	<li>Review the remaining details of the specification.</li>
	<li>Implement parallel node finding to improve performance.</li>
	<li>Finish the &quot;discard head&quot; implementation.</li>
	<li>Key republishing (section 2.5)</li>
	<li>Bucket splitting (section 2.4)</li>
</ol>
<h2>Bucket Splitting</h2>
<p>A word about these statements in the specification:</p>
<p><font color="#FF00FF">Initially, a node u’s routing tree has a single node— 
one k-bucket covering the entire ID space. When u learns of a new contact, it 
attempts to insert the contact in the appropriate k-bucket. If that bucket is 
not full, the new contact is simply inserted. Otherwise, if the fe-bucket’s 
range includes u’s own node ID, then the bucket is split into two new buckets, 
the old contents divided between the two, and the insertion attempt repeated.</font></p>
<p>This seems to contradict a statement earlier in the spec:
<font color="#FF00FF">For each 0 &lt; i &lt; 160, every node keeps a list of 
(IP address, UDP port, Node ID) triples for nodes of distance between 2<sup>i</sup> and 
2<sup>i+1</sup> from itself. We call these lists k-buckets. </font></p>
<p>So which is it?&nbsp; A tree, or contiguous list of 160 k-buckets?&nbsp; 
Let's look at a distribution of adding 160 * k (3200) nodes to a single node.&nbsp; 
Here's the unit test (which doesn't assert anything):</p>
<pre>public const string CRLF = &quot;\r\n&quot;;

[TestMethod]
public void DistributionMidpointTest()
{
  Node node = RouterTests.CreateNode(ID.OneID() &lt;&lt; 80);
  (Constants.ID_LENGTH_BITS * Constants.K).ForEach(() =&gt; node.SimpleRegistration(new Contact() { NodeID = ID.RandomID() }));
  var bucketCounts = node.BucketList.GetBucketContactCounts();
  Write(&quot;countsMidpoint.txt&quot;, bucketCounts);
}

public static void Write(string fn, List&lt;(int idx, int count)&gt; bucketCounts)
{
  File.Delete(fn);
  StringBuilder sb = new StringBuilder();
  bucketCounts.ForEach(bc =&gt; sb.Append(bc.idx + &quot;,&quot; + bc.count + CRLF));
  File.WriteAllText(fn, sb.ToString());
}</pre>
<p>And the results, created in Excel:</p>
<p><img border="0" src="bucketCounts.png" width="481" height="289"></p>
<p>That's big FAIL.&nbsp; </p>
<h3>Two Different Specifications</h3>
<p>After some digging, I discovered that
<a href="https://www.mail-archive.com/p2p-hackers@lists.zooko.com/msg00039.html">
Jim Dixon</a> is the author of the specs on SourceForge.&nbsp; He points out 
&quot;There are at least two versions of this paper on the Web with the same authors 
and title.&quot;&nbsp; The shorter paper can be found
<a href="http://www.cs.rice.edu/Conferences/IPTPS02/109.pdf">here</a> and makes 
no mention of bucket splitting.&nbsp; This paper states &quot;Because node IDs are 
randomly chosen, it follows that highly non-uniform distributions are unlikely.&quot;&nbsp; 
But that's not what I'm seeing here, so either my bucket indexing:</p>
<pre>public int GetBucketIndex()
{
  return (Constants.ID_LENGTH_BITS - id.Bits().TakeWhile(b =&gt; !b).Count() - 1).Max(0);
}</pre>
<p>is wrong, or bucket splitting is needed, or something else is very wrong 
(hint, it's the last case.)&nbsp; I note that the Python 
code implements bucket splitting, but I can't find this in zencoders C# code.&nbsp; 
In fact, as coded so far, I used zencoders initialization of the bucket list:</p>
<pre>public BucketList(ID ourID)
{
  this.ourID = ourID;
  buckets = new List&lt;List&lt;Contact&gt;&gt;(NUM_BUCKETS);
  accessTimes = new List&lt;DateTime&gt;();

  // Set up each bucket
  for(int i = 0; i &lt; NUM_BUCKETS; i++) 
  {
    buckets.Add(new List&lt;Contact&gt;(BUCKET_SIZE));
    accessTimes.Add(default(DateTime));
  }
}</pre>
<p>So I think I can conclusively state that zencoders' implementation does not 
employ bucket splitting, which ends up creating significant problems. </p>
<p>Let's look at zencoders' implementation:</p>
<pre>public int DifferingBit(ID other)
{
  ID differingBits = this ^ other;
  int differAt = 8 * ID_LENGTH - 1;

  // Subtract 8 for every zero byte from the right
  int i = ID_LENGTH - 1;
  while(i &gt;= 0 &amp;&amp; differingBits.data[i] == 0) 
  {
    differAt -= 8;
    i--;
  }

  // Subtract 1 for every zero bit from the right
  int j = 0;
  // 1 &lt;&lt; j = pow(2, j)
  while(j &lt; 8 &amp;&amp; (differingBits.data[i] &amp; (1 &lt;&lt; j)) == 0) 
  {
    j++;
    differAt--;
  }

  return differAt;
}</pre>
<p>This is used once:</p>
<pre>/// &lt;summary&gt;
/// Returns what bucket an ID maps to.
/// PRECONDITION: ourID not passed.
/// &lt;/summary&gt;
/// &lt;param name=&quot;id&quot;&gt;The id to check&lt;/param&gt;
/// &lt;returns&gt;The bucket number&lt;/returns&gt;
private int BucketFor(ID id) 
{
  return(ourID.DifferingBit(id));
}</pre>
<p>Let's try that in the <code>HaveContact</code> method:</p>
<pre>int bucketIdx = ourId.DifferingBit(contact.NodeID); // distance.GetBucketIndex();</pre>
<p><img border="0" src="bucketCounts2.png" width="481" height="289"></p>
<p>Nope, we get very similar results.</p>
<p>Next, we need to ask, are the node ID's distributed uniformly?&nbsp; You may 
have already realized the problem -- while the random ID's as <i>numbers</i> 
may be distributed uniformly, what we need instead is a uniform distribution of 
an ID falling into a particular bucket.&nbsp; Because each bucket 
from 0 &lt; i &lt; 160 holds a different range of values 2<sup>i</sup> through 2<sup>i+1</sup>-1, 
we can clearly see that a simple random number generation of the bytes for the 
ID does not result in uniform distribution of ID's within the bucket <i>ranges.</i>&nbsp; 
This explains zencoders' <code>RandomizeBeyond</code> method:</p>
<pre>public ID RandomizeBeyond(int bit)
{
  byte[] randomized = new byte[ID_LENGTH];
  this.data.CopyTo(randomized, 0);

  FlipBit(randomized, bit); // Invert pivot bit

  // And randomly flip the rest
  for(int i = bit + 1; i &lt; 8 * ID_LENGTH; i++) 
  {
    if(rnd.NextDouble() &lt; 0.5) 
    {
      FlipBit(randomized, i);
    }
  }

  return new ID(randomized);
}</pre>
<p>Our random ID generator was borrowed from zencoders:</p>
<pre>public static ID RandomID()
{
  byte[] data = new byte[ID_LENGTH];
  rnd.NextBytes(data);
  return new ID(data);
}</pre>
<p>This, pointed out above, generates a uniform distribution of <i>numbers, not 
of buckets that ID fits in.</i>&nbsp; It needs to do this instead:</p>
<pre>public static ID RandomID()
{
  byte[] data = new byte[Constants.ID_LENGTH_BYTES];
  ID id = new ID(data);
  // Uniform random bucket index.
  int idx = rnd.Next(Constants.ID_LENGTH_BITS);
  // 0 &lt;= idx &lt;= 159
  // Remaining bits are randomized to get unique ID.
  id.SetBit(idx);
  id = id.RandomizeBeyond(idx);
  Validate.IsTrue(id.GetBucketIndex() == idx, &quot;Error with RandomID.&quot;);

  return id;
}</pre>
<p>Note the validation, and also how we're randomizing the <i>number of MSB bits </i>that should be 0.&nbsp; This results in a better, but still wrong, distribution:</p>
<p><img border="0" src="bucketCounts3.png" width="481" height="289"></p>
<p>It's interesting that almost all of the nodes are half-way to the right of 
the mid point.&nbsp; Gee, I wonder why.&nbsp; Maybe it has something to do with 
this in our unit test:</p>
<pre>Node node = RouterTests.CreateNode(ID.OneID() &lt;&lt; 80);</pre>
<p>and this:</p>
<pre>var distance = ourId ^ contact.NodeID;</pre>
<p>Because we selected a midpoint ID for the node, we know that 1/2 the 
distances (ID's 1 through 2^<sup>80</sup> - 1) will be greater than 2<sup>80</sup> 
because the bit at 2<sup>80</sup> is set by our test node ID.&nbsp;&nbsp; The only distances 
that will be less than 80 are 2^80 itself (we seem to have encountered 12 random 
values between 0 and 159 came out as 80 , and from 2<sup>81</sup> through 2<sup>159</sup> 
the distances again will be greater than 2<sup>80</sup> because (well duh) 
numbers 2<sup>81</sup> 
through 2<sup>159</sup> are greater than 2<sup>80</sup>!&nbsp; So this means 
that the unit test is wrong.&nbsp; The unit test should always use <code>ID.ZeroID()</code> 
for the starting node ID to ensure a proper distribution:</p>
<pre>Node node = RouterTests.CreateNode(ID.ZeroID());</pre>
<p>and viola!</p>
<p><img border="0" src="buckets4.png" width="632" height="297"></p>
<p>So we have discovered a critical flaw in zencoders' random ID generation as 
well as a bug in our unit test.&nbsp; Incidentally, of the 3200 node add 
attempts, 2872 succeeded, the remainder (328) did not get added because the 
k-bucket was full.&nbsp; This also points out critical it is, for any 
participant in the Kademlia network, to create a uniformly distributed random 
node ID for the host node.&nbsp; Again, zencoders implementation for the host ID 
is wrong:</p>
<pre>return ID.Hash(app + user + machine + macs);</pre>
<p>This in no way will generate a uniformly distributed ID for host.</p>
<h3>A Flaw in the Kademlia XOR Distance Metric or in the Specification?</h3>
<p>Does this point to a flaw in using XOR logic for a distance metric?&nbsp; 
Let's look at the bucket distribution for a node with an ID where bit 2<sup>159</sup> is set:</p>
<p>The results are what you'd expect, I don't even have to create a graph:</p>
<table border="0" cellpadding="0" cellspacing="0" width="128" style="border-collapse:
 collapse;width:96pt">
	<colgroup>
		<col width="64" span="2" style="width:48pt">
	</colgroup>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="center" width="64" style="height: 15.0pt; width: 48pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		Bucket #</td>
		<td align="center" width="64" style="width: 48pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		Count</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" width="64" style="height: 15.0pt; width: 48pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		156</td>
		<td align="right" width="64" style="width: 48pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		2</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		157</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		4</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		158</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		12</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		159</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		20</td>
	</tr>
</table>
<p>So, let's revisit zencoders use of <code>DifferingBit</code> to get the 
bucket index, now that we've fixed other problems.&nbsp; At this point it's 
pretty clear that using the distance computation to insert the new node in the 
appropriate bucket is wrong!</p>
<table border="0" cellpadding="0" cellspacing="0" width="128" style="border-collapse:
 collapse;width:96pt">
	<colgroup>
		<col width="64" span="2" style="width:48pt">
	</colgroup>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="center" width="64" style="height: 15.0pt; width: 48pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		Bucket #</td>
		<td align="center" width="64" style="width: 48pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		Count</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" width="64" style="height: 15.0pt; width: 48pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		148</td>
		<td align="right" width="64" style="width: 48pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		1</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		149</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		3</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		150</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		3</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		151</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		5</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		152</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		8</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		153</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		20</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		154</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		20</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		155</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		20</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		156</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		20</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		157</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		20</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		158</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		20</td>
	</tr>
	<tr height="20" style="height:15.0pt">
		<td height="20" align="right" style="height: 15.0pt; color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		159</td>
		<td align="right" style="color: black; font-size: 11.0pt; font-weight: 400; font-style: normal; text-decoration: none; font-family: Calibri, sans-serif; text-align: general; vertical-align: bottom; white-space: nowrap; border: medium none; padding-left: 1px; padding-right: 1px; padding-top: 1px">
		20</td>
	</tr>
</table>
<p>Nope.&nbsp; So that doesn't solve the problem, which looks like another 
significant flaw with zencoders implementation.&nbsp; The problem is actually 
easily solved - the bucket index that the contact goes into is determined solely 
by the contact's node ID, not its distance from our node:</p>
<pre>public void HaveContact(ID ourId, Contact contact, Func&lt;Contact, bool&gt; discardHead)
{
  // A node must never put its own node ID into a bucket as a contact.
  if (ourId != contact.NodeID)
  {
    <font color="#FF0000">int bucketIdx = contact.NodeID.GetBucketIndex();</font>
    buckets[bucketIdx].HaveContact(contact, discardHead);
  }
} </pre>
<p>Now it doesn't matter what our node ID is.&nbsp; Incidentally, this is 
exactly what Brian Muller's Python implementation does:</p>
<pre>def getBucketFor(self, node):
  &quot;&quot;&quot;
  Get the index of the bucket that the given node would fall into.
  &quot;&quot;&quot;
  for index, bucket in enumerate(self.buckets):
    if node.long_id &lt; bucket.range[1]:
      return index</pre>
<p>Ultimately, <b>I think the specification is wrong</b>: <font color="#FF00FF">For 
each 0 &lt; i &lt; 160, every node keeps a list of (IP address, UDP port, Node ID) 
triples for nodes of distance between 2<sup>i</sup> and 2<sup>i+1</sup> from 
itself</font>.&nbsp; Wrong!&nbsp; Nodes should not keep a list of other nodes based on the 
XOR distance from itself!</p>
<p>Even Jim Dixon's explanation is wrong:</p>
<p><font color="#FF00FF">The buckets are organized by the distance between the 
node and the contacts in the bucket. Specifically, for bucket j, where 0 &lt;= j &lt; 
k, we are guaranteed that 2<sup>j</sup> &lt;= distance(node, contact) &lt; 2<sup>(j+1)
</sup></font>where distance is the XOR operation.&nbsp; It is simply not 
possible, with an XOR operation, for a distance to be less than the most 
significant non-zero bit after the XOR.&nbsp; If a node's ID has a &quot;high&quot; msb 
set, most contacts will have a smaller ID and as the data above shows, the 
&quot;high&quot; msb will rule in terms of determining distance.</p>
<p>As an aside, I'm impressed that Python easily handles 2<sup>160</sup>:</p>
<pre>&gt;&gt;&gt; 2 ** 160
1461501637330902918203684832716283019655932542976L</pre>
<p>In C#, we'd have to use the BigInteger class:</p>
<pre>BigInteger bi = BigInteger.Parse(&quot;1461501637330902918203684832716283019655932542976&quot;);</pre>
<p>Now we just have to fix a couple broken unit tests:</p>
<p><img border="0" src="broken.png" width="193" height="61"></p>
<p>Maybe.</p>
<h3>Pass 2 - Is the Specification Really Wrong?</h3>
<p>The <a href="http://www.cs.rice.edu/Conferences/IPTPS02/109.pdf">shorter version of the specification</a> (I would assume this was the 
original specification?&nbsp; I wish people would date their documents) doesn't 
mention bucket splitting.&nbsp; Heck, it doesn't even mention a binary tree of 
buckets.&nbsp; In fact, the first part of Section 2 appears to be completely 
rewritten in the longer specification. &nbsp; Bucket splitting 
solves two problems:</p>
<ol>
	<li>My implementation currently handles only 3200 other contacts.&nbsp; In a 
	massive network, this seems, well, wrong, but then again, just how large 
	(and time consuming to search) should the tree become, especially if we use 
	a brute force algorithm to search closest nodes by an XOR distance?</li>
	<li>The problem of a node with high msb's set in its ID's sort of goes away 
	with splitting, but as larger specification points out, this can lead to 
	very unbalanced trees.</li>
</ol>
<p>And a question: If buckets are constantly split, when does the code for 
ejecting a non-responding node ever get executed?</p>
<p>Brian Muller's Python code implements a simple midpoint split:</p>
<pre>def split(self):
  midpoint = (self.range[0] + self.range[1]) / 2
  one = KBucket(self.range[0], midpoint, self.ksize)
  two = KBucket(midpoint + 1, self.range[1], self.ksize)
  for node in self.nodes.values():
    bucket = one if node.long_id &lt;= midpoint else two
    bucket.nodes[node.id] = node
  return (one, two)</pre>
<p>and (as part of the <code>addContact</code> function:</p>
<pre># this will succeed unless the bucket is full
if bucket.addNode(node):
  return

# Per section 4.2 of paper, split if the bucket has the node in its range
# or if the depth is not congruent to 0 mod 5
if bucket.hasInRange(self.node) or bucket.depth() % 5 != 0:
  self.splitBucket(index)
  self.addContact(node)
else:
  self.protocol.callPing(bucket.head())</pre>
<p>Note that the bucket is split only when the bucket contains the host node ID!&nbsp; 
Let's read what <a href="https://github.com/mikedeboer/node-k-bucket">Mike de 
Boer</a> says about this:</p>
<p><font color="#FF00FF">KBucket starts off as a single k-bucket with capacity 
of k. As contacts are added, once the k+1 contact is added, the k-bucket is 
split into two k-buckets. The split happens according to the first bit of the 
contact node id. The k-bucket that would contain the local node id is the &quot;near&quot; 
k-bucket, and the other one is the &quot;far&quot; k-bucket. The &quot;far&quot; k-bucket is marked 
as don't split in order to prevent further splitting. The contact nodes that 
existed are then redistributed along the two new k-buckets and the old k-bucket 
becomes an inner node within a tree data structure.<br>
<br>
As even more contacts are added to the &quot;near&quot; k-bucket, the &quot;near&quot; k-bucket will 
split again as it becomes full. However, this time it is split along the second 
bit of the contact node id. Again, the two newly created k-buckets are marked 
&quot;near&quot; and &quot;far&quot; and the &quot;far&quot; k-bucket is marked as don't split. Again, the 
contact nodes that existed in the old bucket are redistributed. This continues 
as long as nodes are being added to the &quot;near&quot; k-bucket, until the number of 
splits reaches the length of the local node id.<br>
<br>
As more contacts are added to the &quot;far&quot; k-bucket and it reaches its capacity, it 
does not split. Instead, the k-bucket emits a &quot;ping&quot; event...</font></p>
<p>OK, that answers my question above.&nbsp; As for the &quot;far k-bucket is marked 
as don't split&quot; - in the Python code, this behavior occurs naturally because the 
host node's ID is not in the range of the far bucket.&nbsp; Also, the Python code 
effectively implements the above algorithm of &quot;split along the first bit, the 
split along the second bit, etc.&quot; always splitting the bucket along its 
midpoint.</p>
<p>What is <code>bucket.depth() % 5 != 0</code> about?&nbsp; Let's look at the 
longer specification, section 4.2:</p>
<p><font color="#FF00FF">Section 2.4 describes how a Kademlia node splits a 
k-bucket when the bucket is full and its range includes the node’s own ID. The 
implementation, however, also splits ranges not containing the node’s ID, up to 
b - 1 levels. If b = 2, for instance, the half of the ID space not containing 
the node’s ID gets split once (into two ranges); if b = 3, it gets split at two 
levels into a maximum of four ranges, etc. The general splitting rule is that a 
node splits a full k-bucket if the bucket’s range contains the node’s own ID or 
the depth d of the k-bucket in the routing tree satisfies [d mod b != 0]. (The 
depth is just the length of the prefix shared by all nodes in the k-bucket’s 
range.) The current implementation uses b = 5.</font></p>
<p>The effect of the depth computation means that the original bucket 
(containing the entire range of ID's) is split immediately (since depth == 1) 
and so forth, to a depth of 5, upon which it will only be split if it is full (<i>k</i>) 
and contains the host's node ID.&nbsp; Unfortunately, Jim Dixon's discussion 
doesn't mention bucket splitting (it's based on the shorter specification, I 
believe) and again,&nbsp; zencoders' implementation doesn't appear to implement this 
behavior.</p>
<h3>Time For Reworking The Bucket List</h3>
<p>All of this means that I need to rework how bucket the bucket list and the 
k-buckets are managed, so that the algorithm implements a tree.&nbsp; I note 
that in the 
Python code, the tree is actually a contiguous list:</p>
<pre>def splitBucket(self, index):
  one, two = self.buckets[index].split()
  self.buckets[index] = one
  self.buckets.insert(index + 1, two)</pre>
<p>That certainly makes it easier to locate a bucket (no tree traversal) but I 
really don't want to use C#'s <code>BigInteger</code>, so we'll deal with this slightly 
differently.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>Other info:
<a href="https://stackoverflow.com/questions/32129978/highly-unbalanced-kademlia-routing-table">
https://stackoverflow.com/questions/32129978/highly-unbalanced-kademlia-routing-table</a></p>
<p>And the search: https://www.google.com/search?q=kademlia+bucket+splitting&amp;rlz=1C1NHXL_enUS721US721&amp;oq=kademlia+bucket+splitting&amp;aqs=chrome..69i57.4407j0j7&amp;sourceid=chrome&amp;ie=UTF-8</p>
<h2>Asynchronous Behavior</h2>
<p>So far, I haven't dealt at all with the issue of simultaneous RPC calls nor 
performance improvements, particularly in the node lookup algorithm, that can be 
achieved by processes responses as soon as they come in.&nbsp; The
<a href="https://github.com/zencoders/sambatyon/tree/master/Kademlia">C# 
zencoders</a> implementation is very nicely asynchronous, particularly with 
regards to the node lookup algorithm.&nbsp; </p>
<p>Parallelization</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>
<font color="#FF00FF">To locate nodes near a particular ID, Kademlia uses a single routing algorithm 
from start to finish. </font></p>
<p>&nbsp;</p>
<p>What is this:</p>

<p><font color="#FF00FF">If there are empty branches in the tree, there might be more 
than one leaf with the longest common prefix. In that case, the closest leaf to 
x will be the closest leaf to ID x produced by flipping the bits in x 
corresponding to the empty branches of the tree.</font></p>

</body>

</html>